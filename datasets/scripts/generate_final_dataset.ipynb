{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2cd5c0-0f46-468e-95b5-da8622b46c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 2,692  |  Columnas canónicas: 33\n",
      "\n",
      "Top 20 columnas con más missing (%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:105: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>has_github</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>has_reddit</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>has_telegram</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ico_start_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>max_investment_raw</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>min_investment_raw</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>team_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>website_available</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>whitelist</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>whitepaper_available</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>min_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tokens_for_sale</td>\n",
       "      <td>float64</td>\n",
       "      <td>97.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>accepts</td>\n",
       "      <td>object</td>\n",
       "      <td>97.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>token_price_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>96.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_tokens</td>\n",
       "      <td>float64</td>\n",
       "      <td>96.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amount_raised_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>93.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>interest</td>\n",
       "      <td>object</td>\n",
       "      <td>92.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ico_end_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column           dtype  missing_%\n",
       "21            has_github         float64     100.00\n",
       "23            has_reddit         float64     100.00\n",
       "22          has_telegram         float64     100.00\n",
       "2         ico_start_date  datetime64[ns]     100.00\n",
       "32    max_investment_raw         float64     100.00\n",
       "31    min_investment_raw         float64     100.00\n",
       "26                rating         float64     100.00\n",
       "25             team_size         float64     100.00\n",
       "24     website_available         float64     100.00\n",
       "17             whitelist         float64     100.00\n",
       "30  whitepaper_available         float64     100.00\n",
       "14    max_investment_usd         float64      99.48\n",
       "13    min_investment_usd         float64      99.48\n",
       "12       tokens_for_sale         float64      97.62\n",
       "20               accepts          object      97.36\n",
       "10       token_price_usd         float64      96.99\n",
       "11          total_tokens         float64      96.69\n",
       "6      amount_raised_usd         float64      93.65\n",
       "27              interest          object      92.61\n",
       "3           ico_end_date  datetime64[ns]      92.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Guardado canónico: ico_union_canonical.csv\n",
      "CPU times: total: 906 ms\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd, numpy as np, re\n",
    "from datetime import datetime\n",
    "\n",
    "IN_PATH  = \"../join/ico_union_wide.csv\"\n",
    "OUT_PATH = \"ico_union_canonical.csv\"\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_csv(IN_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# --- Suffix config (prioridad de fuentes) ---\n",
    "SUFFIXES = [\"_zenodo\", \"_icpsr\", \"_yan\"]  # prioridad por orden\n",
    "\n",
    "# --- Utilities ---\n",
    "def split_base_and_suffix(col: str):\n",
    "    for s in SUFFIXES:\n",
    "        if col.endswith(s):\n",
    "            return col[:-len(s)], s\n",
    "    return col, \"\"  # columnas sin sufijo\n",
    "\n",
    "# agrupar columnas por \"base\"\n",
    "base_to_cols = {}\n",
    "for c in df.columns:\n",
    "    b, s = split_base_and_suffix(c)\n",
    "    base_to_cols.setdefault(b, []).append(c)\n",
    "\n",
    "def _first_nonnull(series_list):\n",
    "    \"\"\"coalesce: primera serie con dato no nulo por fila.\"\"\"\n",
    "    if not series_list:\n",
    "        return pd.Series([np.nan]*len(df))\n",
    "    out = pd.Series([np.nan]*len(df))\n",
    "    for s in series_list:\n",
    "        if s is None: \n",
    "            continue\n",
    "        if isinstance(s, str) and s in df.columns:\n",
    "            v = df[s]\n",
    "        elif isinstance(s, pd.Series):\n",
    "            v = s\n",
    "        else:\n",
    "            continue\n",
    "        out = out.where(~out.isna(), v)\n",
    "    return out\n",
    "\n",
    "def choose_cols_by_priority(base_name, prefer_numeric=False, regex=False):\n",
    "    \"\"\"\n",
    "    Devuelve lista de columnas (nombres) para un base_name, ordenadas por prioridad de dataset.\n",
    "    - Si regex=True, base_name es un patrón y trae todas las bases que 'matchean'.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    # matching de base exacto o por regex\n",
    "    bases = []\n",
    "    if regex:\n",
    "        pat = re.compile(base_name, flags=re.IGNORECASE)\n",
    "        bases = [b for b in base_to_cols.keys() if pat.search(b)]\n",
    "    else:\n",
    "        if base_name in base_to_cols:\n",
    "            bases = [base_name]\n",
    "        else:\n",
    "            # fallback: probar case-insensitive\n",
    "            for b in base_to_cols:\n",
    "                if b.lower() == base_name.lower():\n",
    "                    bases = [b]; break\n",
    "    # por cada base, ordenar por prioridad de sufijo\n",
    "    for b in bases:\n",
    "        cols = base_to_cols[b]\n",
    "        # separar con sufijo y sin sufijo\n",
    "        with_suf = [c for c in cols if any(c.endswith(s) for s in SUFFIXES)]\n",
    "        no_suf   = [c for c in cols if c not in with_suf]\n",
    "        # ordenar los con sufijo por prioridad\n",
    "        ordered = []\n",
    "        for s in SUFFIXES:\n",
    "            ordered += [c for c in with_suf if c.endswith(s)]\n",
    "        ordered += no_suf  # al final, sin sufijo\n",
    "        # ordenar numéricos antes si se pide\n",
    "        if prefer_numeric:\n",
    "            numeric_first = [c for c in ordered if pd.api.types.is_numeric_dtype(df[c])]\n",
    "            non_numeric   = [c for c in ordered if not pd.api.types.is_numeric_dtype(df[c])]\n",
    "            ordered = numeric_first + non_numeric\n",
    "        candidates += ordered\n",
    "    return candidates\n",
    "\n",
    "def parse_money_like(s):\n",
    "    \"\"\"intenta homogenizar strings de montos a float.\"\"\"\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip().lower().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        mult = 1\n",
    "        if \"billion\" in x or (re.search(r\"\\d\", x) and x.endswith(\"b\")): mult = 1_000_000_000\n",
    "        elif \"million\" in x or (re.search(r\"\\d\", x) and x.endswith(\"m\")): mult = 1_000_000\n",
    "        elif re.search(r\"\\d\", x) and x.endswith(\"k\"): mult = 1_000\n",
    "        nums = re.findall(r\"[\\d.]+\", x)\n",
    "        return float(nums[0]) * mult if nums else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_date_like(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip()\n",
    "    x = re.sub(r\"^(ended|end|finished|finalized)\\s*:?\\s*\", \"\", x, flags=re.IGNORECASE)\n",
    "    x = x.replace(\"—\",\"-\").replace(\"–\",\"-\")\n",
    "    return x\n",
    "\n",
    "def parse_date_series(series, formats=(\"%d %b %Y\", \"%Y-%m-%d\", \"%d/%m/%Y\", \"%b %d, %Y\")):\n",
    "    \"\"\"intenta parsear fechas a Timestamp, probando varios formatos.\"\"\"\n",
    "    out = pd.to_datetime(series, errors=\"coerce\", dayfirst=True)\n",
    "    # si sigue muy NaT y hay strings, intentar otros formatos\n",
    "    if out.isna().any():\n",
    "        s = series.astype(str)\n",
    "        for fmt in formats:\n",
    "            mask = out.isna()\n",
    "            try:\n",
    "                out.loc[mask] = pd.to_datetime(s[mask], format=fmt, errors=\"coerce\", dayfirst=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "def boolify(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)) and not pd.isna(x):\n",
    "        return int(float(x) != 0)\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"sí\"}: return 1\n",
    "    if s in {\"0\",\"false\",\"no\",\"n\"}: return 0\n",
    "    return np.nan\n",
    "\n",
    "def extract_min_max(s):\n",
    "    \"\"\"parsea ranges tipo '0.1-10 ETH' -> (min, max) (en unidades sin conversión de divisa).\"\"\"\n",
    "    if pd.isna(s): return (np.nan, np.nan)\n",
    "    x = str(s).lower()\n",
    "    nums = re.findall(r\"[\\d.]+\", x)\n",
    "    if not nums: return (np.nan, np.nan)\n",
    "    if len(nums) == 1:\n",
    "        v = float(nums[0]); return (v, v)\n",
    "    return (float(nums[0]), float(nums[1]))\n",
    "\n",
    "# --- Canonical schema (muy amplio) ---\n",
    "CANON = {\n",
    "    # Identidad\n",
    "    \"name_std\":           [[\"name_std\"]],\n",
    "    \"symbol_std\":         [[\"symbol_std\"]],\n",
    "\n",
    "    # Fechas (start/end)\n",
    "    \"ico_start_date\":     [[\"start_date\",\"start\",\"ico_start\",\"sale_start\",\"preico_start\",\"token_sale_start\"],\n",
    "                           [r\"start_end_date_coin_sell\", r\"date_range\", r\"ico_dates\"]],  # tomaremos el extremo izquierdo si viene rango\n",
    "    \"ico_end_date\":       [[\"end_date_parsed\",\"end_date\",\"end\",\"ico_end\",\"sale_end\",\"token_sale_end\"],\n",
    "                           [r\"start_end_date_coin_sell\", r\"date_range\", r\"ico_dates\"]],  # tomaremos el extremo derecho si viene rango\n",
    "\n",
    "    # Recaudación y objetivos\n",
    "    \"goal_usd\":           [[\"fundraising_goal\",\"goal\",\"soft_cap\",\"softcap\",\"target\"]],\n",
    "    \"hard_cap_usd\":       [[\"hard_cap\",\"hardcap\",\"max_cap\",\"maximum_cap\"]],\n",
    "    \"amount_raised_usd\":  [[\"received_money\",\"amount_raised\",\"raised\",\"raised_usd\",\"received_money.1\"]],  # variantes\n",
    "    \"ico_successful\":     [[\"ico_successful\",\"success\",\"successful\"]],\n",
    "\n",
    "    # Tokenomics\n",
    "    \"token_price_usd\":    [[\"ico_token_price\",\"token_price\"]],\n",
    "    \"total_tokens\":       [[\"total_tokens\",\"supply_total\",\"token_supply_total\"]],\n",
    "    \"tokens_for_sale\":    [[\"available_for_token_sale\",\"token_sale_amount\",\"for_sale\"]],\n",
    "    \"min_investment_raw\": [[\"min_investment\",\"min_max_personal_cap\",\"minimum_investment\"]],\n",
    "    \"max_investment_raw\": [[\"max_investment\",\"min_max_personal_cap\",\"maximum_investment\"]],\n",
    "    \"token_type\":         [[\"token_type\",\"type\"]],\n",
    "    \"role_of_token\":      [[\"role_of_token\",\"role\"]],\n",
    "\n",
    "    # Acceso / Compliance / Jurisdicción\n",
    "    \"whitelist\":          [[\"whitelist\"]],\n",
    "    \"kyc\":                [[\"kyc\"]],\n",
    "    \"jurisdiction\":       [[\"jurisdiction\",\"country\"]],\n",
    "    \"accepts\":            [[\"accepts\",\"currencies_accepted\"]],\n",
    "\n",
    "    # Señales de ejecución / presencia\n",
    "    \"has_github\":         [[\"has_github\",\"github\",\"github_available\"]],\n",
    "    \"has_telegram\":       [[\"has_telegram\",\"telegram\"]],\n",
    "    \"has_reddit\":         [[\"has_reddit\",\"reddit\"]],\n",
    "    \"website_available\":  [[\"website_available\",\"website\",\"site\"]],\n",
    "\n",
    "    # Equipo / rating / interés / docs\n",
    "    \"team_size\":          [[\"team_size\",\"teamsize\"]],\n",
    "    \"rating\":             [[\"rating\",\"score\",\"ico_rating\"]],\n",
    "    \"interest\":           [[\"interest\"]],\n",
    "    \"discount_max_pct\":   [[\"crowdsale max. discount\",\"max_discount\",\"discount\"]],\n",
    "    \"roadmap_available\":  [[\"development road map available\",\"roadmap_available\",\"has_roadmap\"]],\n",
    "    \"whitepaper_available\":[[\"whitepaper_available\",\"whitepaper\",\"has_whitepaper\"]],\n",
    "}\n",
    "\n",
    "# --- Resolver columnas por base + prioridad fuente ---\n",
    "def resolve_base_to_series(base_tokens):\n",
    "    \"\"\"\n",
    "    base_tokens: lista de bases (strings exactos) o patrones regex (si empiezan con '^' o contienen '.*')\n",
    "    Devuelve lista de columnas reales en orden de prioridad de fuente.\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for bt in base_tokens:\n",
    "        if re.search(r\"[\\^\\$\\.\\*\\+\\|\\(\\)\\[\\]\\?]\", bt, flags=re.I):  # patrón regex\n",
    "            cols += choose_cols_by_priority(bt, regex=True)\n",
    "        else:\n",
    "            cols += choose_cols_by_priority(bt, regex=False)\n",
    "    # quitar duplicados manteniendo orden\n",
    "    seen = set(); cols_unique = []\n",
    "    for c in cols:\n",
    "        if c not in seen and c in df.columns:\n",
    "            seen.add(c); cols_unique.append(c)\n",
    "    return cols_unique\n",
    "\n",
    "# --- Construcción del DataFrame canónico ---\n",
    "out = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Identidad directa\n",
    "for canon, groups in CANON.items():\n",
    "    if canon in [\"name_std\",\"symbol_std\"]:\n",
    "        cols = resolve_base_to_series(groups[0])\n",
    "        out[canon] = _first_nonnull(cols)\n",
    "    else:\n",
    "        out[canon] = np.nan  # inicializamos\n",
    "\n",
    "# Fechas: start/end con soporte de rango\n",
    "def pick_date_left_right():\n",
    "    # Start: primero intentamos columnas de inicio directas\n",
    "    start_cols = resolve_base_to_series(CANON[\"ico_start_date\"][0])\n",
    "    start_series = _first_nonnull(start_cols)\n",
    "    # Si todo NaT, intentamos rango (tomar izquierda del rango)\n",
    "    if start_series.isna().all() and len(CANON[\"ico_start_date\"])>1:\n",
    "        rng_cols = resolve_base_to_series(CANON[\"ico_start_date\"][1])\n",
    "        if rng_cols:\n",
    "            left = df[rng_cols[0]].astype(str).str.extract(r\"^\\s*([^-–—|to]+)\", expand=False).map(clean_date_like)\n",
    "            start_series = left\n",
    "    start_series = parse_date_series(start_series)\n",
    "\n",
    "    # End: primero columnas de fin directas\n",
    "    end_cols = resolve_base_to_series(CANON[\"ico_end_date\"][0])\n",
    "    end_series = _first_nonnull(end_cols)\n",
    "    # si NaT, intentar derecha del rango\n",
    "    if end_series.isna().all() and len(CANON[\"ico_end_date\"])>1:\n",
    "        rng_cols = resolve_base_to_series(CANON[\"ico_end_date\"][1])\n",
    "        if rng_cols:\n",
    "            right = df[rng_cols[0]].astype(str).str.extract(r\"[-–—|to]\\s*(.*)$\", expand=False).map(clean_date_like)\n",
    "            end_series = right\n",
    "    end_series = parse_date_series(end_series)\n",
    "    return start_series, end_series\n",
    "\n",
    "out[\"ico_start_date\"], out[\"ico_end_date\"] = pick_date_left_right()\n",
    "\n",
    "# Numéricos principales (coalesce con preferencia de columnas numéricas)\n",
    "def coalesce_numeric(cand_groups):\n",
    "    cols = []\n",
    "    for g in cand_groups:\n",
    "        cols += resolve_base_to_series(g)\n",
    "    # ordenar numeric dtype primero por cada grupo de prioridad\n",
    "    numeric_first = [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    others = [c for c in cols if c not in numeric_first]\n",
    "    cols_ordered = numeric_first + others\n",
    "    ser = _first_nonnull(cols_ordered)\n",
    "    # intentar parseo para strings tipo \"3M\"\n",
    "    ser = ser.apply(parse_money_like)\n",
    "    return ser\n",
    "\n",
    "out[\"goal_usd\"]          = coalesce_numeric(CANON[\"goal_usd\"])\n",
    "out[\"hard_cap_usd\"]      = coalesce_numeric(CANON[\"hard_cap_usd\"])\n",
    "out[\"amount_raised_usd\"] = coalesce_numeric(CANON[\"amount_raised_usd\"])\n",
    "\n",
    "# Etiqueta de éxito: si hay varias, priorizamos por fuentes (implícito en union_wide)\n",
    "succ_cols = resolve_base_to_series(CANON[\"ico_successful\"][0])\n",
    "succ_series = _first_nonnull(succ_cols)\n",
    "out[\"ico_successful\"] = succ_series.map(boolify)\n",
    "\n",
    "# Tokenomics\n",
    "out[\"token_price_usd\"] = coalesce_numeric(CANON[\"token_price_usd\"])\n",
    "out[\"total_tokens\"]    = coalesce_numeric(CANON[\"total_tokens\"])\n",
    "out[\"tokens_for_sale\"] = coalesce_numeric(CANON[\"tokens_for_sale\"])\n",
    "\n",
    "# Min/Max investment: si no hay columnas directas, intentar parsear min_max_personal_cap\n",
    "min_cols = resolve_base_to_series(CANON[\"min_investment_raw\"][0])\n",
    "max_cols = resolve_base_to_series(CANON[\"max_investment_raw\"][0])\n",
    "\n",
    "if not min_cols and not max_cols:\n",
    "    # buscar cualquier base que contenga 'min_max_personal_cap'\n",
    "    mm = choose_cols_by_priority(r\"min[_\\- ]?max[_\\- ]?personal[_\\- ]?cap\", regex=True)\n",
    "    if mm:\n",
    "        mn, mx = zip(*df[mm[0]].map(extract_min_max))\n",
    "        out[\"min_investment_usd\"] = pd.to_numeric(mn, errors=\"coerce\")\n",
    "        out[\"max_investment_usd\"] = pd.to_numeric(mx, errors=\"coerce\")\n",
    "else:\n",
    "    if min_cols:\n",
    "        out[\"min_investment_usd\"] = coalesce_numeric([min_cols])\n",
    "    if max_cols:\n",
    "        out[\"max_investment_usd\"] = coalesce_numeric([max_cols])\n",
    "\n",
    "# Categóricas / flags\n",
    "for canon in [\"token_type\",\"role_of_token\",\"jurisdiction\",\"accepts\",\"interest\",\"rating\"]:\n",
    "    cols = []\n",
    "    for g in CANON[canon]:\n",
    "        cols += resolve_base_to_series(g)\n",
    "    out[canon] = _first_nonnull(cols)\n",
    "\n",
    "for canon in [\"whitelist\",\"kyc\",\"has_github\",\"has_telegram\",\"has_reddit\",\"website_available\",\n",
    "              \"roadmap_available\",\"whitepaper_available\"]:\n",
    "    cols = []\n",
    "    for g in CANON[canon]:\n",
    "        cols += resolve_base_to_series(g)\n",
    "    out[canon] = _first_nonnull(cols).map(boolify)\n",
    "\n",
    "# Descuento crowd-sale\n",
    "disc_cols = []\n",
    "for g in CANON[\"discount_max_pct\"]:\n",
    "    disc_cols += resolve_base_to_series(g)\n",
    "disc = _first_nonnull(disc_cols)\n",
    "disc = disc.astype(str).str.extract(r\"([\\d.]+)\", expand=False)\n",
    "out[\"discount_max_pct\"] = pd.to_numeric(disc, errors=\"coerce\")\n",
    "\n",
    "# Reglas derivadas\n",
    "out[\"hit_softcap\"] = ((out[\"amount_raised_usd\"] >= out[\"goal_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"goal_usd\"].notna()).astype(\"Int64\")\n",
    "out[\"hit_hardcap\"] = ((out[\"amount_raised_usd\"] >= out[\"hard_cap_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"hard_cap_usd\"].notna()).astype(\"Int64\")\n",
    "\n",
    "# Orden de columnas final (identidad -> fechas -> funding -> tokenomics -> acceso -> señales -> equipo/rating/docs)\n",
    "ordered_cols = [\n",
    "    \"name_std\",\"symbol_std\",\n",
    "    \"ico_start_date\",\"ico_end_date\",\n",
    "    \"goal_usd\",\"hard_cap_usd\",\"amount_raised_usd\",\"ico_successful\",\"hit_softcap\",\"hit_hardcap\",\n",
    "    \"token_price_usd\",\"total_tokens\",\"tokens_for_sale\",\"min_investment_usd\",\"max_investment_usd\",\n",
    "    \"token_type\",\"role_of_token\",\"whitelist\",\"kyc\",\"jurisdiction\",\"accepts\",\n",
    "    \"has_github\",\"has_telegram\",\"has_reddit\",\"website_available\",\n",
    "    \"team_size\",\"rating\",\"interest\",\"discount_max_pct\",\"roadmap_available\",\"whitepaper_available\",\n",
    "]\n",
    "# añade cualquier columna canónica que haya quedado fuera por no existir\n",
    "ordered_cols = [c for c in ordered_cols if c in out.columns] + [c for c in out.columns if c not in ordered_cols]\n",
    "\n",
    "out = out[ordered_cols].copy()\n",
    "\n",
    "# --- Diagnostics ---\n",
    "def missing_pct(s): \n",
    "    return round(100*s.isna().mean(), 2)\n",
    "\n",
    "report = pd.DataFrame({\n",
    "    \"column\": out.columns,\n",
    "    \"dtype\": [str(out[c].dtype) for c in out.columns],\n",
    "    \"missing_%\": [missing_pct(out[c]) for c in out.columns]\n",
    "}).sort_values([\"missing_%\",\"column\"], ascending=[False, True])\n",
    "\n",
    "print(f\"Filas: {len(out):,}  |  Columnas canónicas: {out.shape[1]}\")\n",
    "print(\"\\nTop 20 columnas con más missing (%):\")\n",
    "display(report.head(20))\n",
    "\n",
    "# --- Guardar ---\n",
    "out.to_csv(OUT_PATH, index=False)\n",
    "print(f\"\\n✅ Guardado canónico: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea9e7fa-b310-4af6-be66-abb88066df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:227: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['nan' 'nan' 'nan' ... 'nan' 'nan' 'nan']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "<timed exec>:228: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "<timed exec>:149: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 2,692  |  Columnas canónicas: 35\n",
      "\n",
      "Top 25 columnas con más missing (%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>has_reddit</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>has_telegram</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ico_length_actual_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ico_length_planned_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ico_start_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ico_successful</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>website_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>min_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tokens_for_sale</td>\n",
       "      <td>float64</td>\n",
       "      <td>97.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>accepts</td>\n",
       "      <td>object</td>\n",
       "      <td>97.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_tokens</td>\n",
       "      <td>float64</td>\n",
       "      <td>96.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>interest</td>\n",
       "      <td>object</td>\n",
       "      <td>92.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ico_end_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>role_of_token</td>\n",
       "      <td>object</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>team_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>discount_max_pct</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>whitepaper_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>89.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>has_github</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>roadmap_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>whitelist</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>token_price_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>86.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>is_tax_regulated</td>\n",
       "      <td>Int64</td>\n",
       "      <td>45.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>goal_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>30.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column           dtype  missing_%\n",
       "25               has_reddit           Int64     100.00\n",
       "24             has_telegram           Int64     100.00\n",
       "4    ico_length_actual_days         float64     100.00\n",
       "5   ico_length_planned_days         float64     100.00\n",
       "2            ico_start_date  datetime64[ns]     100.00\n",
       "9            ico_successful         float64     100.00\n",
       "28                   rating         float64     100.00\n",
       "26        website_available           Int64     100.00\n",
       "16       max_investment_usd         float64      99.48\n",
       "15       min_investment_usd         float64      99.48\n",
       "14          tokens_for_sale         float64      97.62\n",
       "22                  accepts          object      97.36\n",
       "13             total_tokens         float64      96.69\n",
       "29                 interest          object      92.61\n",
       "3              ico_end_date  datetime64[ns]      92.57\n",
       "18            role_of_token          object      92.57\n",
       "27                team_size         float64      89.52\n",
       "30         discount_max_pct         float64      89.23\n",
       "32     whitepaper_available           Int64      89.04\n",
       "23               has_github           Int64      88.63\n",
       "31        roadmap_available           Int64      88.63\n",
       "19                whitelist           Int64      88.63\n",
       "12          token_price_usd         float64      86.11\n",
       "34         is_tax_regulated           Int64      45.77\n",
       "6                  goal_usd         float64      30.61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Guardado canónico: final/ico_union_canonical.csv\n",
      "CPU times: total: 562 ms\n",
      "Wall time: 581 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd, numpy as np, re\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "IN_PATH  = \"../join/ico_union_wide.csv\"\n",
    "OUT_PATH = \"ico_union_canonical.csv\"   # cambialo si querés\n",
    "\n",
    "# ------------------ Load --------------------\n",
    "df = pd.read_csv(IN_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# prioridad de fuentes (izq→der)\n",
    "SUFFIXES = [\"_zenodo\", \"_icpsr\", \"_yan\"]\n",
    "\n",
    "def split_base_and_suffix(col: str):\n",
    "    for s in SUFFIXES:\n",
    "        if col.endswith(s):\n",
    "            return col[:-len(s)], s\n",
    "    return col, \"\"   # sin sufijo\n",
    "\n",
    "# indexar base -> columnas\n",
    "base_to_cols = {}\n",
    "for c in df.columns:\n",
    "    b, s = split_base_and_suffix(c)\n",
    "    base_to_cols.setdefault(b, []).append(c)\n",
    "\n",
    "# ------------------ Helpers -----------------\n",
    "def money_like_to_float(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip().lower().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        mult = 1\n",
    "        if \"billion\" in x or (re.search(r\"\\d\", x) and x.endswith(\"b\")): mult = 1_000_000_000\n",
    "        elif \"million\" in x or (re.search(r\"\\d\", x) and x.endswith(\"m\")): mult = 1_000_000\n",
    "        elif re.search(r\"\\d\", x) and x.endswith(\"k\"): mult = 1_000\n",
    "        nums = re.findall(r\"[\\d.]+\", x)\n",
    "        return float(nums[0]) * mult if nums else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_date_like(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip()\n",
    "    x = re.sub(r\"^(ended|end|finished|finalized)\\s*:?\\s*\", \"\", x, flags=re.IGNORECASE)\n",
    "    x = x.replace(\"—\",\"-\").replace(\"–\",\"-\")\n",
    "    return x\n",
    "\n",
    "def boolify(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)) and not pd.isna(x):\n",
    "        return int(float(x) != 0)\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"sí\",\"present\",\"available\",\"ok\"}: return 1\n",
    "    if s in {\"0\",\"false\",\"no\",\"n\",\"absent\",\"unavailable\",\"none\"}: return 0\n",
    "    return np.nan\n",
    "\n",
    "def _first_nonnull(series_list):\n",
    "    \"\"\"Coalesce alineando SIEMPRE contra df.index.\"\"\"\n",
    "    out = pd.Series(np.nan, index=df.index)\n",
    "    for s in series_list or []:\n",
    "        if s is None: \n",
    "            continue\n",
    "        if isinstance(s, str):\n",
    "            if s in df.columns: v = df[s]\n",
    "            else:               continue\n",
    "        elif isinstance(s, pd.Series):\n",
    "            v = s\n",
    "        else:\n",
    "            continue\n",
    "        v = pd.Series(v).reindex(out.index)  # <- clave para evitar shape mismatch\n",
    "        out = out.where(~out.isna(), v)\n",
    "    return out\n",
    "\n",
    "def order_by_priority(cols):\n",
    "    \"\"\"*_zenodo > *_icpsr > *_yan > sin sufijo, deduplicado y existentes.\"\"\"\n",
    "    with_suf = [c for c in cols if any(c.endswith(s) for s in SUFFIXES)]\n",
    "    no_suf   = [c for c in cols if c not in with_suf]\n",
    "    ordered = []\n",
    "    for s in SUFFIXES:\n",
    "        ordered += [c for c in with_suf if c.endswith(s)]\n",
    "    ordered += no_suf\n",
    "    seen, uniq = set(), []\n",
    "    for c in ordered:\n",
    "        if c in df.columns and c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "def find_cols_by_regex(patterns):\n",
    "    \"\"\"patterns: lista de regex; devuelve columnas reales (con sufijos) ordenadas por prioridad.\"\"\"\n",
    "    cols = []\n",
    "    for pat in patterns:\n",
    "        r = re.compile(pat, flags=re.IGNORECASE)\n",
    "        for base in base_to_cols.keys():\n",
    "            if r.search(base):\n",
    "                cols += base_to_cols[base]\n",
    "    return order_by_priority(cols)\n",
    "\n",
    "def coalesce_numeric_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    ser = _first_nonnull(cols)\n",
    "    # intentar convertir directo\n",
    "    ser_num = pd.to_numeric(ser, errors=\"coerce\")\n",
    "    # si hay demasiados NaN, probar parseo tipo \"3M\"\n",
    "    if ser_num.notna().sum() < 0.2 * len(ser_num):\n",
    "        ser_num = ser.apply(money_like_to_float)\n",
    "    return ser_num\n",
    "\n",
    "def coalesce_text_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    ser = _first_nonnull(cols).astype(str).replace({\"nan\": np.nan})\n",
    "    return ser\n",
    "\n",
    "def coalesce_bool_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(pd.array([pd.NA]*len(df), dtype=\"Int64\"), index=df.index)\n",
    "    ser = _first_nonnull(cols).map(boolify).astype(\"Int64\")\n",
    "    return ser\n",
    "\n",
    "def extract_min_max(s):\n",
    "    if pd.isna(s): return (np.nan, np.nan)\n",
    "    x = str(s).lower()\n",
    "    nums = re.findall(r\"[\\d.]+\", x)\n",
    "    if not nums: return (np.nan, np.nan)\n",
    "    if len(nums) == 1:\n",
    "        v = float(nums[0]); return (v, v)\n",
    "    return (float(nums[0]), float(nums[1]))\n",
    "\n",
    "def parse_dates_robust(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parsea fechas con intentos explícitos (sin warnings) y luego fallback.\"\"\"\n",
    "    s = pd.Series(s, index=df.index)\n",
    "    parsed = pd.to_datetime(s, format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d/%m/%Y\", \"%b %d, %Y\"):\n",
    "        need = parsed.isna()\n",
    "        if need.any():\n",
    "            parsed.loc[need] = pd.to_datetime(s[need], format=fmt, errors=\"coerce\", dayfirst=True)\n",
    "    need = parsed.isna()\n",
    "    if need.any():\n",
    "        parsed.loc[need] = pd.to_datetime(s[need], errors=\"coerce\", dayfirst=True)\n",
    "    return parsed\n",
    "\n",
    "# ------------------ Aliases (regex) -----------------\n",
    "ALIASES = {\n",
    "    # Identidad\n",
    "    \"name_std\":   [[r\"^name_std$\"]],\n",
    "    \"symbol_std\": [[r\"^symbol_std$\"]],\n",
    "\n",
    "    # Fechas\n",
    "    \"start_direct\": [[r\"^start_date\", r\"\\bico_start\\b\", r\"sale_start\", r\"preico_start\"]],\n",
    "    \"end_direct\":   [[r\"^end_date_parsed$\", r\"^end_date\\b\", r\"\\bico_end\\b\", r\"sale_end\", r\"token_sale_end\"]],\n",
    "    \"date_range\":   [[r\"start_end_date_coin_sell\", r\"ico_dates\", r\"date_range\"]],\n",
    "\n",
    "    # Recaudación / objetivos\n",
    "    \"goal_usd\":           [[r\"fundraising[_ ]?goal\", r\"^goal$\", r\"soft[_ ]?cap\", r\"softcap\", r\"target\"]],\n",
    "    \"hard_cap_usd\":       [[r\"hard[_ ]?cap\", r\"max[_ ]?cap\", r\"maximum[_ ]?cap\"]],\n",
    "    \"amount_raised_usd\":  [[r\"received[_ ]?money(\\.1)?$\", r\"amount[_ ]?raised(_usd)?$\", r\"^raised(_usd)?$\"]],\n",
    "\n",
    "    # Etiqueta éxito\n",
    "    \"ico_successful\":     [[r\"ico[_ ]?success(ful)?$\", r\"^success$\", r\"^successful$\"]],\n",
    "\n",
    "    # Tokenomics\n",
    "    \"token_price_usd\":    [[r\"ico[_ ]?token[_ ]?price\", r\"token[_ ]?price\"]],\n",
    "    \"total_tokens\":       [[r\"total[_ ]?tokens\", r\"token[_ ]?supply[_ ]?total\"]],\n",
    "    \"tokens_for_sale\":    [[r\"available[_ ]?for[_ ]?token[_ ]?sale\", r\"tokens?[_ ]?for[_ ]?sale\", r\"tokensfsale\"]],\n",
    "    \"min_investment\":     [[r\"min[_ ]?investment\", r\"minimum[_ ]?investment\", r\"min[_ ]?max[_ ]?personal[_ ]?cap\"]],\n",
    "    \"max_investment\":     [[r\"max[_ ]?investment\", r\"maximum[_ ]?investment\", r\"min[_ ]?max[_ ]?personal[_ ]?cap\"]],\n",
    "    \"token_type\":         [[r\"token[_ ]?type\", r\"utility[_ ]?token[_ ]?enables\", r\"role[_ ]?of[_ ]?token\", r\"\\btype\\b\"]],\n",
    "    \"role_of_token\":      [[r\"role[_ ]?of[_ ]?token\", r\"\\brole\\b\"]],\n",
    "\n",
    "    # Acceso / Compliance / Jurisdicción\n",
    "    \"whitelist\":          [[r\"whitelist\", r\"qualified[_ ]?investors[_ ]?only\", r\"us[_ ]?retail[_ ]?investors[_ ]?excluded\"]],\n",
    "    \"kyc\":                [[r\"\\bkyc\\b\", r\"regulkyc\", r\"reg[_ ]?kyc\"]],\n",
    "    \"jurisdiction\":       [[r\"jurisdiction\", r\"country\", r\"legal[_ ]?(form|entity)\", r\"registered[_ ]?in[_ ]?offshore\"]],\n",
    "    \"accepts\":            [[r\"\\baccepts\\b\", r\"currencies[_ ]?accepted\"]],\n",
    "\n",
    "    # Señales de ejecución / presencia\n",
    "    \"has_github\":         [[r\"project[_ ]?code[_ ]?available\", r\"smart[_ ]?contract[_ ]?code[_ ]?available\", r\"github\", r\"code[_ ]?available\"]],\n",
    "    \"has_telegram\":       [[r\"telegram\"]],\n",
    "    \"has_reddit\":         [[r\"reddit\"]],\n",
    "    \"website_available\":  [[r\"website[_ ]?available\", r\"\\bwebsite\\b\", r\"\\bsite\\b\"]],\n",
    "\n",
    "    # Equipo / rating / interés / docs\n",
    "    \"team_size\":          [[r\"team[_ ]?size\", r\"teamsize\"]],\n",
    "    \"rating\":             [[r\"rating\", r\"ico[_ ]?rating\", r\"score\"]],\n",
    "    \"interest\":           [[r\"interest\"]],\n",
    "    \"discount_max_pct\":   [[r\"crowdsale[_ ]?max\\.?[_ ]?discount\", r\"presale[_ ]?discount\", r\"max[_ ]?discount\"]],\n",
    "    \"roadmap_available\":  [[r\"development[_ ]?road[_ ]?map[_ ]?available\", r\"roadmap[_ ]?available\", r\"has[_ ]?roadmap\"]],\n",
    "    \"whitepaper_available\":[[r\"whitepaper[_ ]?available\", r\"whitepaper[_ ]?page\", r\"white[_ ]?paper\"]],\n",
    "\n",
    "    # Duraciones / IEO / RegTax\n",
    "    \"ico_length_actual\":  [[r\"length[_ ]?of[_ ]?ico.*\\(calendar days, actual\\)\", r\"ico[_ ]?length[_ ]?actual\"]],\n",
    "    \"ico_length_planned\": [[r\"length[_ ]?of[_ ]?ico.*\\(calendar days, planned\\)\", r\"ico[_ ]?length[_ ]?planned\"]],\n",
    "    \"ieo\":                [[r\"\\bieo\\b\", r\"initial[_ ]?exchange[_ ]?offering\", r\"used[_ ]?an[_ ]?exchange\"]],\n",
    "    \"regtax\":             [[r\"reg[_ ]?tax\", r\"tax[_ ]?reg(ulation)?\", r\"regulation[_ ]?on[_ ]?transfer\"]],\n",
    "}\n",
    "\n",
    "# ------------------ Build canónico ------------------\n",
    "out = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Identidad (si existen en union_wide)\n",
    "out[\"name_std\"]   = _first_nonnull(order_by_priority(find_cols_by_regex(ALIASES[\"name_std\"][0])))\n",
    "out[\"symbol_std\"] = _first_nonnull(order_by_priority(find_cols_by_regex(ALIASES[\"symbol_std\"][0])))\n",
    "\n",
    "# ---- Fechas (FIX robusto) ----\n",
    "start_direct = coalesce_text_from_patterns(ALIASES[\"start_direct\"])\n",
    "end_direct   = coalesce_text_from_patterns(ALIASES[\"end_direct\"])\n",
    "date_range   = coalesce_text_from_patterns(ALIASES[\"date_range\"])\n",
    "\n",
    "start_direct = pd.Series(start_direct, index=df.index)\n",
    "end_direct   = pd.Series(end_direct,   index=df.index)\n",
    "date_range   = pd.Series(date_range,   index=df.index)\n",
    "\n",
    "left_from_range  = pd.Series(np.nan, index=df.index)\n",
    "right_from_range = pd.Series(np.nan, index=df.index)\n",
    "lr = date_range.astype(str).str.extract(r\"^\\s*([^-–—|to]+)\", expand=False)\n",
    "rr = date_range.astype(str).str.extract(r\"[-–—|to]\\s*(.*)$\",   expand=False)\n",
    "left_from_range.loc[lr.index]  = lr\n",
    "right_from_range.loc[rr.index] = rr\n",
    "\n",
    "def _clean_date_series(s):\n",
    "    s = pd.Series(s, index=df.index)\n",
    "    return s.astype(str).map(clean_date_like).replace({\"nan\": np.nan})\n",
    "\n",
    "start_txt = start_direct.copy()\n",
    "start_txt = start_txt.mask(start_txt.notna(), start_txt).mask(start_txt.isna(), _clean_date_series(left_from_range))\n",
    "\n",
    "end_txt = end_direct.copy()\n",
    "end_txt = end_txt.mask(end_txt.notna(), end_txt).mask(end_txt.isna(), _clean_date_series(right_from_range))\n",
    "\n",
    "out[\"ico_start_date\"] = parse_dates_robust(start_txt)\n",
    "out[\"ico_end_date\"]   = parse_dates_robust(end_txt)\n",
    "\n",
    "# ---- Recaudación / objetivos ----\n",
    "out[\"goal_usd\"]          = coalesce_numeric_from_patterns(ALIASES[\"goal_usd\"])\n",
    "out[\"hard_cap_usd\"]      = coalesce_numeric_from_patterns(ALIASES[\"hard_cap_usd\"])\n",
    "out[\"amount_raised_usd\"] = coalesce_numeric_from_patterns(ALIASES[\"amount_raised_usd\"])\n",
    "\n",
    "# ---- Éxito ----\n",
    "succ = coalesce_text_from_patterns(ALIASES[\"ico_successful\"])\n",
    "out[\"ico_successful\"] = succ.map(boolify)\n",
    "\n",
    "# ---- Tokenomics ----\n",
    "out[\"token_price_usd\"] = coalesce_numeric_from_patterns(ALIASES[\"token_price_usd\"])\n",
    "out[\"total_tokens\"]    = coalesce_numeric_from_patterns(ALIASES[\"total_tokens\"])\n",
    "out[\"tokens_for_sale\"] = coalesce_numeric_from_patterns(ALIASES[\"tokens_for_sale\"])\n",
    "\n",
    "# ---- Min/Max investment ----\n",
    "mininv_raw = coalesce_text_from_patterns(ALIASES[\"min_investment\"])\n",
    "maxinv_raw = coalesce_text_from_patterns(ALIASES[\"max_investment\"])\n",
    "mn, mx  = zip(*mininv_raw.map(extract_min_max))\n",
    "mn2, mx2 = zip(*maxinv_raw.map(extract_min_max))\n",
    "mx_final = pd.Series(mx, index=df.index).where(pd.notna(pd.Series(mx, index=df.index)), pd.Series(mx2, index=df.index))\n",
    "out[\"min_investment_usd\"] = pd.to_numeric(pd.Series(mn, index=df.index), errors=\"coerce\")\n",
    "out[\"max_investment_usd\"] = pd.to_numeric(mx_final, errors=\"coerce\")\n",
    "\n",
    "# ---- Categóricas / flags ----\n",
    "out[\"token_type\"]    = coalesce_text_from_patterns(ALIASES[\"token_type\"])\n",
    "out[\"role_of_token\"] = coalesce_text_from_patterns(ALIASES[\"role_of_token\"])\n",
    "out[\"whitelist\"]     = coalesce_bool_from_patterns(ALIASES[\"whitelist\"])\n",
    "out[\"kyc\"]           = coalesce_bool_from_patterns(ALIASES[\"kyc\"])\n",
    "out[\"jurisdiction\"]  = coalesce_text_from_patterns(ALIASES[\"jurisdiction\"])\n",
    "out[\"accepts\"]       = coalesce_text_from_patterns(ALIASES[\"accepts\"])\n",
    "\n",
    "# ---- Señales de ejecución / presencia ----\n",
    "out[\"has_github\"]        = coalesce_bool_from_patterns(ALIASES[\"has_github\"])\n",
    "out[\"has_telegram\"]      = coalesce_bool_from_patterns(ALIASES[\"has_telegram\"])\n",
    "out[\"has_reddit\"]        = coalesce_bool_from_patterns(ALIASES[\"has_reddit\"])\n",
    "out[\"website_available\"] = coalesce_bool_from_patterns(ALIASES[\"website_available\"])\n",
    "\n",
    "# ---- Equipo / rating / interés / docs ----\n",
    "out[\"team_size\"] = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"team_size\"]), errors=\"coerce\")\n",
    "out[\"rating\"]    = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"rating\"]), errors=\"coerce\")\n",
    "out[\"interest\"]  = coalesce_text_from_patterns(ALIASES[\"interest\"])\n",
    "\n",
    "disc = coalesce_text_from_patterns(ALIASES[\"discount_max_pct\"]).astype(str).str.extract(r\"([\\d.]+)\", expand=False)\n",
    "out[\"discount_max_pct\"] = pd.to_numeric(disc, errors=\"coerce\")\n",
    "\n",
    "out[\"roadmap_available\"] = coalesce_bool_from_patterns(ALIASES[\"roadmap_available\"])\n",
    "wp = coalesce_text_from_patterns(ALIASES[\"whitepaper_available\"])\n",
    "wp_num = pd.to_numeric(wp, errors=\"coerce\")\n",
    "out[\"whitepaper_available\"] = pd.Series(\n",
    "    np.where(wp_num.notna() & (wp_num>0), 1, np.where(wp.notna(), wp.map(boolify), np.nan)),\n",
    "    dtype=\"Int64\", index=df.index\n",
    ")\n",
    "\n",
    "# ---- Duraciones / IEO / RegTax ----\n",
    "out[\"ico_length_actual_days\"]  = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"ico_length_actual\"]), errors=\"coerce\")\n",
    "out[\"ico_length_planned_days\"] = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"ico_length_planned\"]), errors=\"coerce\")\n",
    "out[\"is_ieo\"]           = coalesce_bool_from_patterns(ALIASES[\"ieo\"])\n",
    "out[\"is_tax_regulated\"] = coalesce_bool_from_patterns(ALIASES[\"regtax\"])\n",
    "\n",
    "# ---- Flags derivados ----\n",
    "out[\"hit_softcap\"] = ((out[\"amount_raised_usd\"] >= out[\"goal_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"goal_usd\"].notna()).astype(\"Int64\")\n",
    "out[\"hit_hardcap\"] = ((out[\"amount_raised_usd\"] >= out[\"hard_cap_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"hard_cap_usd\"].notna()).astype(\"Int64\")\n",
    "\n",
    "# ---- Orden final ----\n",
    "ordered = [\n",
    "    \"name_std\",\"symbol_std\",\n",
    "    \"ico_start_date\",\"ico_end_date\",\"ico_length_actual_days\",\"ico_length_planned_days\",\n",
    "    \"goal_usd\",\"hard_cap_usd\",\"amount_raised_usd\",\"ico_successful\",\"hit_softcap\",\"hit_hardcap\",\n",
    "    \"token_price_usd\",\"total_tokens\",\"tokens_for_sale\",\"min_investment_usd\",\"max_investment_usd\",\n",
    "    \"token_type\",\"role_of_token\",\"whitelist\",\"kyc\",\"jurisdiction\",\"accepts\",\n",
    "    \"has_github\",\"has_telegram\",\"has_reddit\",\"website_available\",\n",
    "    \"team_size\",\"rating\",\"interest\",\"discount_max_pct\",\"roadmap_available\",\"whitepaper_available\",\n",
    "    \"is_ieo\",\"is_tax_regulated\",\n",
    "]\n",
    "ordered = [c for c in ordered if c in out.columns] + [c for c in out.columns if c not in ordered]\n",
    "out = out[ordered].copy()\n",
    "\n",
    "# ------------------ Reporte -----------------\n",
    "def missing_pct(s): \n",
    "    return round(100*s.isna().mean(), 2)\n",
    "\n",
    "report = pd.DataFrame({\n",
    "    \"column\": out.columns,\n",
    "    \"dtype\": [str(out[c].dtype) for c in out.columns],\n",
    "    \"missing_%\": [missing_pct(out[c]) for c in out.columns]\n",
    "}).sort_values([\"missing_%\",\"column\"], ascending=[False, True])\n",
    "\n",
    "print(f\"Filas: {len(out):,}  |  Columnas canónicas: {out.shape[1]}\")\n",
    "print(\"\\nTop 25 columnas con más missing (%):\")\n",
    "try:\n",
    "    display(report.head(25))\n",
    "except Exception:\n",
    "    print(report.head(25).to_string(index=False))\n",
    "\n",
    "# ------------------ Save --------------------\n",
    "out.to_csv(OUT_PATH, index=False)\n",
    "print(f\"\\n✅ Guardado canónico: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6d05e2-806e-44c8-806e-8163890aff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__key__', 'name_std', 'symbol_std', 'name_other', 'name_cmc', 'ticker_symbol_cmc', 'ico_successful', 'soft_cap', 'hard_cap', 'cap_unit', 'cap_includes_presale', 'token_type', 'number_of_contributors', 'crowdsale_tokens_sold', 'total_number_of_tokens', 'token_standard', 'additional_token_emissions', 'crowdsale_token_price_min', 'crowdsale_token_price_max', 'crowdsale_actual_token_price_max', 'crowdsale is auction', 'has a presale', 'presale_tokens_sold', 'presale_token_price_min', 'presale_token_price_max', 'development road map available', 'whitepaper page count', 'product or prototype developed', 'product can be tried out', 'years since foundation', 'issuer has customers for product', 'business model available', 'utility token enables decentralization', 'smart contract code available', 'project code available', 'use of proceeds mentioned', 'use of proceeds disclosed in detail', 'token share team (ex ante)', 'token share crowdsale investors (ex ante)', 'token share presale investors (ex ante)', 'token share producers/miners (ex ante)', \"unsold tokens 'burnt' or proportional allocation\", 'unsold tokens kept by issuer', 'unsold tokens locked up', 'lock up period unsold tokens (years)', 'team lockup period (weighted avg.)', 'presale lockup period (weighted avg.)', 'vc_support_general', 'vc_support_blockchain_specialist', 'investors have governance rights', 'team size', 'experienced team', 'team member with business background', 'advisor_quality', 'legal_structure', 'registration_country', 'address', 'independent custodian for ico funds', 'portfolio_converted_into_fiat', 'funding milestones', 'qualified investors only', 'simple agreement for future tokens (saft)', 'kyc/aml procedure', 'us retail investors excluded', 'investors from other (non-us) jurisdictions excluded', 'legal advisor disclosed', 'financial advisor disclosed', 'air_drop_after_ico', 'industry', 'ethereum_contract_address', 'ico_start_date', 'ico_end_date_planned', 'ico_end_date_actual', 'amount raised in presale (usdm)', 'amount raised in crowdsale (usdm)', 'total amount raised (usdm)', 'total amount raised (usdm).1', 'btc_ret_ico_period', 'presale discount (%)', \"fundraiser has maximum ('hard cap')\", \"fundraiser has minimum ('soft cap')\", 'soft_cap_unit', 'hard_cap_unit', 'percentage of hard cap raised (%)', 'pct_of_crowdsale_target_raised', 'price_presale_avg', 'price_presale', 'price_crowdsale_avg', 'price_crowdsale', 'crowdsale max. discount (%)', 'us_qualified_only', 'team business background missing', 'team experience missing', 'average_discount', 'team tokens locked up', 'presale tokens locked up', 'issued_on_other_platf', 'legal form and jurisdiction known', 'postal address known', 'registered in offshore financial center', 'switzerland', 'is_ethereum', 'is cryptographic token', 'has vc backing', 'has_generalist_vc', 'has_specialist_vc', 'unknown or low quality advisors', 'high quality advisory team', 'token supply is fixed', 'token share crowdsale investors (ex post)', 'post_money_val_crowdsale', 'celebrity endorsement', 'is a security', 'is a utility token', 'token_is_cryptocurrency', 'token_is_new_blockchain', 'is currency or general purpose blockchain', 'decentralised platform', 'legal entity is foundation', 'legal entity is corporation', 'legal entity is llc', 'legal entity is corporation or llc', 'length of crowdsale (calendar days, actual)', 'length of crowdsale (calendar days, planned)', 'lock_up_period_team_ep', 'presale_transparent', 'industry.1', '(first) date', 'time to listing (calendar days)', 'soft_cap_usd', 'hard_cap_usd', 'independent custodian for ico funds_usd', '__source__', 'web adress', 'name', 'ticker', 'ico success', 'industry_icpsr', 'platform', 'ieo', 'mininvest', 'country', 'kyc', 'wlist', 'regulkyc', 'regtax', 'restusa', 'restchina', 'tokens f sale', 'accepting', 'eth', 'btc', 'fiat', 'ltc', 'dash', 'xrp', 'zec', 'neo', 'eos', 'other', 'protocol type', 'distributed in ico', 'softcap', 'hardcap', 'amount raised', 'circsupply', 'price mkt', 'price pre ico', 'price ico', 'regulkyc dates', 'pre ico starts', 'pre ico ends', 'total days', 'ico starts', 'ico ends', 'total days.1', 'artificial intelligence', 'art', 'banking', 'big data', 'business services', 'charity', 'communication', 'cryptocurrency', 'education', 'electronics', 'energy', 'enterntainment', 'health', 'infrastructre', 'internet', 'investment', 'legal', 'manufacturing', 'media', 'platform.1', 'real estate', 'retail', 'smart contract', 'software', 'sports', 'tourism', 'virtual reality', 'other.1', 'name_std_icpsr', 'symbol_std_icpsr', 'softcap_usd', 'hardcap_usd', 'amount raised_usd', 'ico_successful_icpsr', 'regulkyc dates_parsed', '__source___icpsr', 'coin_ticker', 'received_money', 'sold_coins', 'role_of_token', 'category', 'goal', 'total_tokens', 'interest', 'fundraising_goal', 'start_end_date_coin_sell', 'ico_token_price', 'received_money.1', 'end_date', 'token_type_yan', 'available_for_token_sale', 'min_max_personal_cap', 'whitelist', 'accepts', 'token_issue', 'cant_participate', 'end_date_clean', 'end_date_parsed', 'ico_successful_yan', 'name_std_yan', 'symbol_resolved', 'symbol_resolved_source', 'symbol_std_yan', '__source___yan']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284f317b-d596-4f69-a53b-a4a699b3c0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 2,692  |  Columnas canónicas: 35\n",
      "\n",
      "Top 25 columnas con más missing (%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:231: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['nan' 'nan' 'nan' ... 'nan' 'nan' 'nan']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "<timed exec>:232: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan nan nan ... nan nan nan]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "<timed exec>:149: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>has_reddit</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>has_telegram</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>website_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>interest</td>\n",
       "      <td>object</td>\n",
       "      <td>92.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>role_of_token</td>\n",
       "      <td>object</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>team_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>discount_max_pct</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ico_length_planned_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>88.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>has_github</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ico_length_actual_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>roadmap_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_tokens</td>\n",
       "      <td>float64</td>\n",
       "      <td>51.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>is_tax_regulated</td>\n",
       "      <td>Int64</td>\n",
       "      <td>45.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>accepts</td>\n",
       "      <td>object</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>23.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>min_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>23.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hard_cap_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tokens_for_sale</td>\n",
       "      <td>float64</td>\n",
       "      <td>21.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>is_ieo</td>\n",
       "      <td>Int64</td>\n",
       "      <td>18.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>whitelist</td>\n",
       "      <td>Int64</td>\n",
       "      <td>18.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>goal_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>14.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>token_price_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kyc</td>\n",
       "      <td>Int64</td>\n",
       "      <td>11.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>token_type</td>\n",
       "      <td>object</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column    dtype  missing_%\n",
       "25               has_reddit    Int64     100.00\n",
       "24             has_telegram    Int64     100.00\n",
       "28                   rating  float64     100.00\n",
       "26        website_available    Int64     100.00\n",
       "29                 interest   object      92.61\n",
       "18            role_of_token   object      92.57\n",
       "27                team_size  float64      89.52\n",
       "30         discount_max_pct  float64      89.23\n",
       "5   ico_length_planned_days  float64      88.74\n",
       "23               has_github    Int64      88.63\n",
       "4    ico_length_actual_days  float64      88.63\n",
       "31        roadmap_available    Int64      88.63\n",
       "13             total_tokens  float64      51.34\n",
       "34         is_tax_regulated    Int64      45.77\n",
       "22                  accepts   object      24.00\n",
       "16       max_investment_usd  float64      23.66\n",
       "15       min_investment_usd  float64      23.66\n",
       "7              hard_cap_usd  float64      22.47\n",
       "14          tokens_for_sale  float64      21.69\n",
       "33                   is_ieo    Int64      18.80\n",
       "19                whitelist    Int64      18.16\n",
       "6                  goal_usd  float64      14.60\n",
       "12          token_price_usd  float64      12.37\n",
       "20                      kyc    Int64      11.66\n",
       "17               token_type   object       8.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Guardado canónico: ico_union_canonical_v3.csv\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd, numpy as np, re\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "IN_PATH  = \"../join/ico_union_wide.csv\"\n",
    "OUT_PATH = \"ico_union_canonical_v3.csv\"\n",
    "\n",
    "# ------------------ Load --------------------\n",
    "df = pd.read_csv(IN_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# prioridad de fuentes (izq→der)\n",
    "SUFFIXES = [\"_zenodo\", \"_icpsr\", \"_yan\"]\n",
    "\n",
    "def split_base_and_suffix(col: str):\n",
    "    for s in SUFFIXES:\n",
    "        if col.endswith(s):\n",
    "            return col[:-len(s)], s\n",
    "    return col, \"\"   # sin sufijo\n",
    "\n",
    "# indexar base -> columnas\n",
    "base_to_cols = {}\n",
    "for c in df.columns:\n",
    "    b, s = split_base_and_suffix(c)\n",
    "    base_to_cols.setdefault(b, []).append(c)\n",
    "\n",
    "# ------------------ Helpers -----------------\n",
    "def money_like_to_float(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip().lower().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        mult = 1\n",
    "        if \"billion\" in x or (re.search(r\"\\d\", x) and x.endswith(\"b\")): mult = 1_000_000_000\n",
    "        elif \"million\" in x or (re.search(r\"\\d\", x) and x.endswith(\"m\")): mult = 1_000_000\n",
    "        elif re.search(r\"\\d\", x) and x.endswith(\"k\"): mult = 1_000\n",
    "        nums = re.findall(r\"[\\d.]+\", x)\n",
    "        return float(nums[0]) * mult if nums else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_date_like(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip()\n",
    "    x = re.sub(r\"^(ended|end|finished|finalized)\\s*:?\\s*\", \"\", x, flags=re.IGNORECASE)\n",
    "    x = x.replace(\"—\",\"-\").replace(\"–\",\"-\")\n",
    "    return x\n",
    "\n",
    "def boolify(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)) and not pd.isna(x):\n",
    "        return int(float(x) != 0)\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"sí\",\"present\",\"available\",\"ok\"}: return 1\n",
    "    if s in {\"0\",\"false\",\"no\",\"n\",\"absent\",\"unavailable\",\"none\"}: return 0\n",
    "    return np.nan\n",
    "\n",
    "def _first_nonnull(series_list):\n",
    "    \"\"\"Coalesce alineando SIEMPRE contra df.index.\"\"\"\n",
    "    out = pd.Series(np.nan, index=df.index)\n",
    "    for s in series_list or []:\n",
    "        if s is None: \n",
    "            continue\n",
    "        if isinstance(s, str):\n",
    "            if s in df.columns: v = df[s]\n",
    "            else:               continue\n",
    "        elif isinstance(s, pd.Series):\n",
    "            v = s\n",
    "        else:\n",
    "            continue\n",
    "        v = pd.Series(v).reindex(out.index)  # <- clave para evitar shape mismatch\n",
    "        out = out.where(~out.isna(), v)\n",
    "    return out\n",
    "\n",
    "def order_by_priority(cols):\n",
    "    \"\"\"*_zenodo > *_icpsr > *_yan > sin sufijo, deduplicado y existentes.\"\"\"\n",
    "    with_suf = [c for c in cols if any(c.endswith(s) for s in SUFFIXES)]\n",
    "    no_suf   = [c for c in cols if c not in with_suf]\n",
    "    ordered = []\n",
    "    for s in SUFFIXES:\n",
    "        ordered += [c for c in with_suf if c.endswith(s)]\n",
    "    ordered += no_suf\n",
    "    seen, uniq = set(), []\n",
    "    for c in ordered:\n",
    "        if c in df.columns and c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "def find_cols_by_regex(patterns):\n",
    "    \"\"\"patterns: lista de regex; devuelve columnas reales (con sufijos) ordenadas por prioridad.\"\"\"\n",
    "    cols = []\n",
    "    for pat in patterns:\n",
    "        r = re.compile(pat, flags=re.IGNORECASE)\n",
    "        for base in base_to_cols.keys():\n",
    "            if r.search(base):\n",
    "                cols += base_to_cols[base]\n",
    "    return order_by_priority(cols)\n",
    "\n",
    "def coalesce_numeric_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    ser = _first_nonnull(cols)\n",
    "    # intentar convertir directo\n",
    "    ser_num = pd.to_numeric(ser, errors=\"coerce\")\n",
    "    # si hay demasiados NaN, probar parseo tipo \"3M\"\n",
    "    if ser_num.notna().sum() < 0.2 * len(ser_num):\n",
    "        ser_num = ser.apply(money_like_to_float)\n",
    "    return ser_num\n",
    "\n",
    "def coalesce_text_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    ser = _first_nonnull(cols).astype(str).replace({\"nan\": np.nan})\n",
    "    return ser\n",
    "\n",
    "def coalesce_bool_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(pd.array([pd.NA]*len(df), dtype=\"Int64\"), index=df.index)\n",
    "    ser = _first_nonnull(cols).map(boolify).astype(\"Int64\")\n",
    "    return ser\n",
    "\n",
    "def extract_min_max(s):\n",
    "    if pd.isna(s): return (np.nan, np.nan)\n",
    "    x = str(s).lower()\n",
    "    nums = re.findall(r\"[\\d.]+\", x)\n",
    "    if not nums: return (np.nan, np.nan)\n",
    "    if len(nums) == 1:\n",
    "        v = float(nums[0]); return (v, v)\n",
    "    return (float(nums[0]), float(nums[1]))\n",
    "\n",
    "def parse_dates_robust(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parsea fechas con intentos explícitos (sin warnings) y luego fallback.\"\"\"\n",
    "    s = pd.Series(s, index=df.index)\n",
    "    parsed = pd.to_datetime(s, format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d/%m/%Y\", \"%b %d, %Y\"):\n",
    "        need = parsed.isna()\n",
    "        if need.any():\n",
    "            parsed.loc[need] = pd.to_datetime(s[need], format=fmt, errors=\"coerce\", dayfirst=True)\n",
    "    need = parsed.isna()\n",
    "    if need.any():\n",
    "        parsed.loc[need] = pd.to_datetime(s[need], errors=\"coerce\", dayfirst=True)\n",
    "    return parsed\n",
    "\n",
    "# ------------------ Aliases (regex) -----------------\n",
    "# Basado en los nombres reales que pasaste de cada dataset\n",
    "ALIASES = {\n",
    "    # Identidad\n",
    "    \"name_std\":   [[r\"^name_std$\"]],\n",
    "    \"symbol_std\": [[r\"^symbol_std$\"]],\n",
    "\n",
    "    # Fechas (Zenodo + ICPSR + Yan)\n",
    "    \"start_direct\": [[r\"^ico_start_date$\", r\"^ico starts$\", r\"\\bico_start\\b\", r\"sale_start\", r\"preico_start\"]],\n",
    "    \"end_direct\":   [[r\"^ico_end_date_actual$\", r\"^ico_end_date_planned$\", r\"^ico ends$\", r\"^end_date_parsed$\", r\"^end_date\\b\", r\"\\bico_end\\b\", r\"sale_end\", r\"token_sale_end\"]],\n",
    "    \"date_range\":   [[r\"^start_end_date_coin_sell$\", r\"ico_dates\", r\"date_range\"]],\n",
    "\n",
    "    # Recaudación / objetivos\n",
    "    \"goal_usd\":           [[r\"^soft_cap_usd$\", r\"^soft_cap$\", r\"^softcap_usd$\", r\"^softcap$\", r\"^fundraising_goal$\", r\"^goal$\"]],\n",
    "    \"hard_cap_usd\":       [[r\"^hard_cap_usd$\", r\"^hard_cap$\", r\"^hardcap_usd$\", r\"^hardcap$\"]],\n",
    "    \"amount_raised_usd\":  [[r\"^total amount raised \\(usdm\\)$\", r\"^total amount raised \\(usdm\\)\\.1$\", r\"^amount raised_usd$\", r\"^amount raised$\", r\"^received_money(\\.1)?$\"]],\n",
    "\n",
    "    # Éxito (ICPSR/Zenodo/Yan)\n",
    "    \"ico_successful\":     [[r\"^ico_successful$\", r\"^ico success$\", r\"^success$\", r\"^successful$\"]],\n",
    "\n",
    "    # Tokenomics\n",
    "    \"token_price_usd\":    [[r\"^crowdsale_actual_token_price_max$\", r\"^price ico$\", r\"^ico_token_price$\"]],\n",
    "    \"total_tokens\":       [[r\"^total_number_of_tokens$\", r\"^circsupply$\", r\"^total_tokens$\"]],\n",
    "    \"tokens_for_sale\":    [[r\"^crowdsale_tokens_sold$\", r\"^tokens f sale$\", r\"^available_for_token_sale$\"]],\n",
    "\n",
    "    # Min/Max inversión\n",
    "    \"min_investment\":     [[r\"^mininvest$\", r\"min[_ ]?investment\", r\"minimum[_ ]?investment\", r\"min[_ ]?max[_ ]?personal[_ ]?cap\"]],\n",
    "    \"max_investment\":     [[r\"^mininvest$\", r\"max[_ ]?investment\", r\"maximum[_ ]?investment\", r\"min[_ ]?max[_ ]?personal[_ ]?cap\"]],  # Yan no trae max explícito\n",
    "\n",
    "    # Tipo/rol token\n",
    "    \"token_type\":         [[r\"^token_type$\", r\"^protocol type$\", r\"utility token enables decentralization\", r\"\\btype\\b\"]],\n",
    "    \"role_of_token\":      [[r\"^role_of_token$\", r\"\\brole\\b\"]],\n",
    "\n",
    "    # Compliance / Jurisdicción\n",
    "    \"whitelist\":          [[r\"^qualified investors only$\", r\"^us retail investors excluded$\", r\"^wlist$\", r\"^whitelist$\"]],\n",
    "    \"kyc\":                [[r\"^kyc/aml procedure$\", r\"^kyc$\", r\"^regulkyc$\"]],\n",
    "    \"jurisdiction\":       [[r\"^registration_country$\", r\"^country$\", r\"^legal_structure$\"]],\n",
    "    \"accepts\":            [[r\"^accepting$\", r\"\\baccepts\\b\", r\"currencies[_ ]?accepted\"]],\n",
    "\n",
    "    # Señales de ejecución / presencia (GitHub/Website)\n",
    "    \"has_github\":         [[r\"^project code available$\", r\"^smart contract code available$\", r\"github\", r\"code[_ ]?available\"]],\n",
    "    \"website_available\":  [[r\"website[_ ]?available\", r\"\\bwebsite\\b\", r\"\\bsite\\b\"]],\n",
    "\n",
    "    # Equipo / rating / interés / docs\n",
    "    \"team_size\":          [[r\"^team size$\", r\"^team_size$\", r\"teamsize\"]],\n",
    "    \"rating\":             [[r\"^rating$\", r\"^ico[_ ]?rating$\", r\"^score$\"]],\n",
    "    \"interest\":           [[r\"^interest$\"]],\n",
    "    \"discount_max_pct\":   [[r\"^crowdsale max\\. discount \\(%\\)$\", r\"^presale discount \\(%\\)$\", r\"max[_ ]?discount\"]],\n",
    "    \"roadmap_available\":  [[r\"^development road map available$\", r\"roadmap[_ ]?available\", r\"has[_ ]?roadmap\"]],\n",
    "    \"whitepaper_available\":[[r\"whitepaper[_ ]?available\", r\"white[_ ]?paper\"]],\n",
    "    \"whitepaper_page_count\": [[r\"^whitepaper page count$\"]],\n",
    "\n",
    "    # Duraciones / IEO / RegTax\n",
    "    \"ico_length_actual\":  [[r\"^length of crowdsale \\(calendar days, actual\\)$\", r\"ico[_ ]?length[_ ]?actual\"]],\n",
    "    \"ico_length_planned\": [[r\"^length of crowdsale \\(calendar days, planned\\)$\", r\"ico[_ ]?length[_ ]?planned\"]],\n",
    "    \"ieo\":                [[r\"^ieo$\", r\"initial[_ ]?exchange[_ ]?offering\", r\"used[_ ]?an[_ ]?exchange\"]],\n",
    "    \"regtax\":             [[r\"^regtax$\", r\"reg[_ ]?tax\", r\"tax[_ ]?reg(ulation)?\", r\"regulation[_ ]?on[_ ]?transfer\"]],\n",
    "}\n",
    "\n",
    "# ------------------ Build canónico ------------------\n",
    "out = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Identidad (si existen en union_wide)\n",
    "out[\"name_std\"]   = _first_nonnull(order_by_priority(find_cols_by_regex(ALIASES[\"name_std\"][0])))\n",
    "out[\"symbol_std\"] = _first_nonnull(order_by_priority(find_cols_by_regex(ALIASES[\"symbol_std\"][0])))\n",
    "\n",
    "# ---- Fechas (robusto) ----\n",
    "start_direct = coalesce_text_from_patterns(ALIASES[\"start_direct\"])\n",
    "end_direct   = coalesce_text_from_patterns(ALIASES[\"end_direct\"])\n",
    "date_range   = coalesce_text_from_patterns(ALIASES[\"date_range\"])\n",
    "\n",
    "start_direct = pd.Series(start_direct, index=df.index)\n",
    "end_direct   = pd.Series(end_direct,   index=df.index)\n",
    "date_range   = pd.Series(date_range,   index=df.index)\n",
    "\n",
    "left_from_range  = pd.Series(np.nan, index=df.index)\n",
    "right_from_range = pd.Series(np.nan, index=df.index)\n",
    "lr = date_range.astype(str).str.extract(r\"^\\s*([^-–—|to]+)\", expand=False)\n",
    "rr = date_range.astype(str).str.extract(r\"[-–—|to]\\s*(.*)$\",   expand=False)\n",
    "left_from_range.loc[lr.index]  = lr\n",
    "right_from_range.loc[rr.index] = rr\n",
    "\n",
    "def _clean_date_series(s):\n",
    "    s = pd.Series(s, index=df.index)\n",
    "    return s.astype(str).map(clean_date_like).replace({\"nan\": np.nan})\n",
    "\n",
    "start_txt = start_direct.copy()\n",
    "start_txt = start_txt.mask(start_txt.isna(), _clean_date_series(left_from_range))\n",
    "\n",
    "end_txt = end_direct.copy()\n",
    "end_txt = end_txt.mask(end_txt.isna(), _clean_date_series(right_from_range))\n",
    "\n",
    "out[\"ico_start_date\"] = parse_dates_robust(start_txt)\n",
    "out[\"ico_end_date\"]   = parse_dates_robust(end_txt)\n",
    "\n",
    "# ---- Recaudación / objetivos ----\n",
    "out[\"goal_usd\"]          = coalesce_numeric_from_patterns(ALIASES[\"goal_usd\"])\n",
    "out[\"hard_cap_usd\"]      = coalesce_numeric_from_patterns(ALIASES[\"hard_cap_usd\"])\n",
    "out[\"amount_raised_usd\"] = coalesce_numeric_from_patterns(ALIASES[\"amount_raised_usd\"])\n",
    "\n",
    "# ---- Éxito (ICPSR > Zenodo > Yan) ----\n",
    "succ = coalesce_text_from_patterns(ALIASES[\"ico_successful\"])\n",
    "out[\"ico_successful\"] = succ.map(boolify)\n",
    "\n",
    "# ---- Tokenomics ----\n",
    "out[\"token_price_usd\"] = coalesce_numeric_from_patterns(ALIASES[\"token_price_usd\"])\n",
    "out[\"total_tokens\"]    = coalesce_numeric_from_patterns(ALIASES[\"total_tokens\"])\n",
    "out[\"tokens_for_sale\"] = coalesce_numeric_from_patterns(ALIASES[\"tokens_for_sale\"])\n",
    "\n",
    "# ---- Min/Max investment ----\n",
    "mininv_raw = coalesce_text_from_patterns(ALIASES[\"min_investment\"])\n",
    "maxinv_raw = coalesce_text_from_patterns(ALIASES[\"max_investment\"])\n",
    "mn, mx  = zip(*mininv_raw.map(extract_min_max))\n",
    "mn2, mx2 = zip(*maxinv_raw.map(extract_min_max))\n",
    "mx_final = pd.Series(mx, index=df.index).where(pd.notna(pd.Series(mx, index=df.index)), pd.Series(mx2, index=df.index))\n",
    "out[\"min_investment_usd\"] = pd.to_numeric(pd.Series(mn, index=df.index), errors=\"coerce\")\n",
    "out[\"max_investment_usd\"] = pd.to_numeric(mx_final, errors=\"coerce\")\n",
    "\n",
    "# ---- Categóricas / flags ----\n",
    "out[\"token_type\"]    = coalesce_text_from_patterns(ALIASES[\"token_type\"])\n",
    "out[\"role_of_token\"] = coalesce_text_from_patterns(ALIASES[\"role_of_token\"])\n",
    "out[\"whitelist\"]     = coalesce_bool_from_patterns(ALIASES[\"whitelist\"])\n",
    "out[\"kyc\"]           = coalesce_bool_from_patterns(ALIASES[\"kyc\"])\n",
    "out[\"jurisdiction\"]  = coalesce_text_from_patterns(ALIASES[\"jurisdiction\"])\n",
    "out[\"accepts\"]       = coalesce_text_from_patterns(ALIASES[\"accepts\"])\n",
    "\n",
    "# ---- Señales de ejecución / presencia ----\n",
    "out[\"has_github\"]        = coalesce_bool_from_patterns(ALIASES[\"has_github\"])\n",
    "# (Telegram/Reddit casi no existen en estos tres; si aparecen en el futuro, se capturan por regex)\n",
    "out[\"has_telegram\"]      = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "out[\"has_reddit\"]        = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "out[\"website_available\"] = coalesce_bool_from_patterns(ALIASES[\"website_available\"])\n",
    "\n",
    "# ---- Equipo / rating / interés / docs ----\n",
    "out[\"team_size\"] = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"team_size\"]), errors=\"coerce\")\n",
    "out[\"rating\"]    = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"rating\"]), errors=\"coerce\")\n",
    "out[\"interest\"]  = coalesce_text_from_patterns(ALIASES[\"interest\"])\n",
    "\n",
    "disc = coalesce_text_from_patterns(ALIASES[\"discount_max_pct\"]).astype(str).str.extract(r\"([\\d.]+)\", expand=False)\n",
    "out[\"discount_max_pct\"] = pd.to_numeric(disc, errors=\"coerce\")\n",
    "\n",
    "out[\"roadmap_available\"] = coalesce_bool_from_patterns(ALIASES[\"roadmap_available\"])\n",
    "\n",
    "# --- Whitepaper availability por \"page count\" + flags ---\n",
    "wp_count = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"whitepaper_page_count\"]), errors=\"coerce\")\n",
    "wp_flag  = (wp_count > 0).astype(\"Int64\")\n",
    "wp_other = coalesce_bool_from_patterns(ALIASES[\"whitepaper_available\"])\n",
    "out[\"whitepaper_available\"] = wp_flag.where(wp_flag.notna(), wp_other)\n",
    "\n",
    "# ---- Duraciones / IEO / RegTax ----\n",
    "out[\"ico_length_actual_days\"]  = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"ico_length_actual\"]), errors=\"coerce\")\n",
    "out[\"ico_length_planned_days\"] = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"ico_length_planned\"]), errors=\"coerce\")\n",
    "out[\"is_ieo\"]           = coalesce_bool_from_patterns(ALIASES[\"ieo\"])\n",
    "out[\"is_tax_regulated\"] = coalesce_bool_from_patterns(ALIASES[\"regtax\"])\n",
    "\n",
    "# ---- Flags derivados ----\n",
    "out[\"hit_softcap\"] = ((out[\"amount_raised_usd\"] >= out[\"goal_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"goal_usd\"].notna()).astype(\"Int64\")\n",
    "out[\"hit_hardcap\"] = ((out[\"amount_raised_usd\"] >= out[\"hard_cap_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"hard_cap_usd\"].notna()).astype(\"Int64\")\n",
    "\n",
    "# ---- Backfills mínimos para modelar ya ----\n",
    "# A) si ico_successful está vacío, usar hit_softcap como proxy\n",
    "if \"ico_successful\" in out.columns and \"hit_softcap\" in out.columns:\n",
    "    mask_empty = out[\"ico_successful\"].isna()\n",
    "    out.loc[mask_empty, \"ico_successful\"] = out.loc[mask_empty, \"hit_softcap\"]\n",
    "\n",
    "# B) si goal_usd es NaN y hard_cap_usd no, usar hardcap como proxy (opcional)\n",
    "mask_goal_missing = out[\"goal_usd\"].isna() & out[\"hard_cap_usd\"].notna()\n",
    "out.loc[mask_goal_missing, \"goal_usd\"] = out.loc[mask_goal_missing, \"hard_cap_usd\"]\n",
    "\n",
    "# ---- Orden final ----\n",
    "ordered = [\n",
    "    \"name_std\",\"symbol_std\",\n",
    "    \"ico_start_date\",\"ico_end_date\",\"ico_length_actual_days\",\"ico_length_planned_days\",\n",
    "    \"goal_usd\",\"hard_cap_usd\",\"amount_raised_usd\",\"ico_successful\",\"hit_softcap\",\"hit_hardcap\",\n",
    "    \"token_price_usd\",\"total_tokens\",\"tokens_for_sale\",\"min_investment_usd\",\"max_investment_usd\",\n",
    "    \"token_type\",\"role_of_token\",\"whitelist\",\"kyc\",\"jurisdiction\",\"accepts\",\n",
    "    \"has_github\",\"has_telegram\",\"has_reddit\",\"website_available\",\n",
    "    \"team_size\",\"rating\",\"interest\",\"discount_max_pct\",\"roadmap_available\",\"whitepaper_available\",\n",
    "    \"is_ieo\",\"is_tax_regulated\",\n",
    "]\n",
    "ordered = [c for c in ordered if c in out.columns] + [c for c in out.columns if c not in ordered]\n",
    "out = out[ordered].copy()\n",
    "\n",
    "# ------------------ Reporte -----------------\n",
    "def missing_pct(s): \n",
    "    return round(100*s.isna().mean(), 2)\n",
    "\n",
    "report = pd.DataFrame({\n",
    "    \"column\": out.columns,\n",
    "    \"dtype\": [str(out[c].dtype) for c in out.columns],\n",
    "    \"missing_%\": [missing_pct(out[c]) for c in out.columns]\n",
    "}).sort_values([\"missing_%\",\"column\"], ascending=[False, True])\n",
    "\n",
    "print(f\"Filas: {len(out):,}  |  Columnas canónicas: {out.shape[1]}\")\n",
    "print(\"\\nTop 25 columnas con más missing (%):\")\n",
    "try:\n",
    "    display(report.head(25))\n",
    "except Exception:\n",
    "    print(report.head(25).to_string(index=False))\n",
    "\n",
    "# ------------------ Save --------------------\n",
    "out.to_csv(OUT_PATH, index=False)\n",
    "print(f\"\\n✅ Guardado canónico: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f50ea4-ac69-4095-b494-d5a592798032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method IndexOpsMixin.tolist of Index(['name_std', 'symbol_std', 'ico_start_date', 'ico_end_date',\n",
      "       'ico_length_actual_days', 'ico_length_planned_days', 'goal_usd',\n",
      "       'hard_cap_usd', 'amount_raised_usd', 'ico_successful', 'hit_softcap',\n",
      "       'hit_hardcap', 'token_price_usd', 'total_tokens', 'tokens_for_sale',\n",
      "       'min_investment_usd', 'max_investment_usd', 'token_type',\n",
      "       'role_of_token', 'whitelist', 'kyc', 'jurisdiction', 'accepts',\n",
      "       'has_github', 'has_telegram', 'has_reddit', 'website_available',\n",
      "       'team_size', 'rating', 'interest', 'discount_max_pct',\n",
      "       'roadmap_available', 'whitepaper_available', 'is_ieo',\n",
      "       'is_tax_regulated'],\n",
      "      dtype='object')>\n"
     ]
    }
   ],
   "source": [
    "print(out.columns.tolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2134d5-4a2c-4662-b190-f4a826780d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas dataset inicial: ['__key__', 'name_std', 'symbol_std', 'name_other', 'name_cmc', 'ticker_symbol_cmc', 'ico_successful', 'soft_cap', 'hard_cap', 'cap_unit', 'cap_includes_presale', 'token_type', 'number_of_contributors', 'crowdsale_tokens_sold', 'total_number_of_tokens', 'token_standard', 'additional_token_emissions', 'crowdsale_token_price_min', 'crowdsale_token_price_max', 'crowdsale_actual_token_price_max', 'crowdsale is auction', 'has a presale', 'presale_tokens_sold', 'presale_token_price_min', 'presale_token_price_max', 'development road map available', 'whitepaper page count', 'product or prototype developed', 'product can be tried out', 'years since foundation', 'issuer has customers for product', 'business model available', 'utility token enables decentralization', 'smart contract code available', 'project code available', 'use of proceeds mentioned', 'use of proceeds disclosed in detail', 'token share team (ex ante)', 'token share crowdsale investors (ex ante)', 'token share presale investors (ex ante)', 'token share producers/miners (ex ante)', \"unsold tokens 'burnt' or proportional allocation\", 'unsold tokens kept by issuer', 'unsold tokens locked up', 'lock up period unsold tokens (years)', 'team lockup period (weighted avg.)', 'presale lockup period (weighted avg.)', 'vc_support_general', 'vc_support_blockchain_specialist', 'investors have governance rights', 'team size', 'experienced team', 'team member with business background', 'advisor_quality', 'legal_structure', 'registration_country', 'address', 'independent custodian for ico funds', 'portfolio_converted_into_fiat', 'funding milestones', 'qualified investors only', 'simple agreement for future tokens (saft)', 'kyc/aml procedure', 'us retail investors excluded', 'investors from other (non-us) jurisdictions excluded', 'legal advisor disclosed', 'financial advisor disclosed', 'air_drop_after_ico', 'industry', 'ethereum_contract_address', 'ico_start_date', 'ico_end_date_planned', 'ico_end_date_actual', 'amount raised in presale (usdm)', 'amount raised in crowdsale (usdm)', 'total amount raised (usdm)', 'total amount raised (usdm).1', 'btc_ret_ico_period', 'presale discount (%)', \"fundraiser has maximum ('hard cap')\", \"fundraiser has minimum ('soft cap')\", 'soft_cap_unit', 'hard_cap_unit', 'percentage of hard cap raised (%)', 'pct_of_crowdsale_target_raised', 'price_presale_avg', 'price_presale', 'price_crowdsale_avg', 'price_crowdsale', 'crowdsale max. discount (%)', 'us_qualified_only', 'team business background missing', 'team experience missing', 'average_discount', 'team tokens locked up', 'presale tokens locked up', 'issued_on_other_platf', 'legal form and jurisdiction known', 'postal address known', 'registered in offshore financial center', 'switzerland', 'is_ethereum', 'is cryptographic token', 'has vc backing', 'has_generalist_vc', 'has_specialist_vc', 'unknown or low quality advisors', 'high quality advisory team', 'token supply is fixed', 'token share crowdsale investors (ex post)', 'post_money_val_crowdsale', 'celebrity endorsement', 'is a security', 'is a utility token', 'token_is_cryptocurrency', 'token_is_new_blockchain', 'is currency or general purpose blockchain', 'decentralised platform', 'legal entity is foundation', 'legal entity is corporation', 'legal entity is llc', 'legal entity is corporation or llc', 'length of crowdsale (calendar days, actual)', 'length of crowdsale (calendar days, planned)', 'lock_up_period_team_ep', 'presale_transparent', 'industry.1', '(first) date', 'time to listing (calendar days)', 'soft_cap_usd', 'hard_cap_usd', 'independent custodian for ico funds_usd', '__source__', 'web adress', 'name', 'ticker', 'ico success', 'industry_icpsr', 'platform', 'ieo', 'mininvest', 'country', 'kyc', 'wlist', 'regulkyc', 'regtax', 'restusa', 'restchina', 'tokens f sale', 'accepting', 'eth', 'btc', 'fiat', 'ltc', 'dash', 'xrp', 'zec', 'neo', 'eos', 'other', 'protocol type', 'distributed in ico', 'softcap', 'hardcap', 'amount raised', 'circsupply', 'price mkt', 'price pre ico', 'price ico', 'regulkyc dates', 'pre ico starts', 'pre ico ends', 'total days', 'ico starts', 'ico ends', 'total days.1', 'artificial intelligence', 'art', 'banking', 'big data', 'business services', 'charity', 'communication', 'cryptocurrency', 'education', 'electronics', 'energy', 'enterntainment', 'health', 'infrastructre', 'internet', 'investment', 'legal', 'manufacturing', 'media', 'platform.1', 'real estate', 'retail', 'smart contract', 'software', 'sports', 'tourism', 'virtual reality', 'other.1', 'name_std_icpsr', 'symbol_std_icpsr', 'softcap_usd', 'hardcap_usd', 'amount raised_usd', 'ico_successful_icpsr', 'regulkyc dates_parsed', '__source___icpsr', 'coin_ticker', 'received_money', 'sold_coins', 'role_of_token', 'category', 'goal', 'total_tokens', 'interest', 'fundraising_goal', 'start_end_date_coin_sell', 'ico_token_price', 'received_money.1', 'end_date', 'token_type_yan', 'available_for_token_sale', 'min_max_personal_cap', 'whitelist', 'accepts', 'token_issue', 'cant_participate', 'end_date_clean', 'end_date_parsed', 'ico_successful_yan', 'name_std_yan', 'symbol_resolved', 'symbol_resolved_source', 'symbol_std_yan', '__source___yan']\n",
      "Columnas dataset finaaal: ['name_std', 'symbol_std', 'ico_start_date', 'ico_end_date', 'ico_length_actual_days', 'ico_length_planned_days', 'goal_usd', 'hard_cap_usd', 'amount_raised_usd', 'ico_successful', 'hit_softcap', 'hit_hardcap', 'token_price_usd', 'total_tokens', 'tokens_for_sale', 'min_investment_usd', 'max_investment_usd', 'industry', 'token_type', 'role_of_token', 'whitelist', 'kyc', 'jurisdiction', 'accepts', 'has_github', 'has_telegram', 'has_reddit', 'website_available', 'team_size', 'rating', 'interest', 'discount_max_pct', 'roadmap_available', 'whitepaper_available', 'is_ieo', 'is_tax_regulated']\n",
      "Diferencia de columnas: ['lock_up_period_team_ep', 'unsold tokens locked up', 'legal entity is foundation', 'amount raised in presale (usdm)', 'price_crowdsale_avg', 'enterntainment', 'experienced team', 'received_money.1', 'name_std_yan', 'crowdsale_token_price_min', 'industry_icpsr', 'price pre ico', 'ethereum_contract_address', 'crowdsale_tokens_sold', 'product or prototype developed', 'portfolio_converted_into_fiat', 'regulkyc dates_parsed', 'investors have governance rights', 'total days', 'end_date_parsed', 'financial advisor disclosed', 'internet', 'legal', 'token share producers/miners (ex ante)', 'tourism', 'art', 'ico_successful_icpsr', 'price ico', 'use of proceeds disclosed in detail', 'amount raised_usd', 'length of crowdsale (calendar days, planned)', 'soft_cap_usd', 'utility token enables decentralization', 'token share crowdsale investors (ex ante)', 'us retail investors excluded', 'xrp', 'energy', 'symbol_resolved_source', 'crowdsale_actual_token_price_max', 'business services', 'end_date', 'hardcap', \"unsold tokens 'burnt' or proportional allocation\", 'hard_cap_unit', 'presale discount (%)', 'us_qualified_only', 'vc_support_blockchain_specialist', 'has vc backing', 'symbol_resolved', 'available_for_token_sale', 'qualified investors only', 'distributed in ico', 'regulkyc', 'token supply is fixed', 'presale_tokens_sold', 'name', 'pre ico starts', 'cryptocurrency', 'end_date_clean', 'industry.1', 'dash', 'coin_ticker', 'presale_token_price_min', 'pre ico ends', 'other.1', 'decentralised platform', 'independent custodian for ico funds_usd', 'total amount raised (usdm).1', 'circsupply', 'protocol type', 'air_drop_after_ico', 'is cryptographic token', 'legal_structure', 'cap_unit', 'banking', 'team business background missing', 'presale_token_price_max', 'unknown or low quality advisors', 'sports', 'years since foundation', 'token share team (ex ante)', 'registered in offshore financial center', 'regulkyc dates', 'other', 'token_type_yan', 'price_presale_avg', 'start_end_date_coin_sell', 'education', 'presale lockup period (weighted avg.)', 'btc', 'time to listing (calendar days)', 'postal address known', 'restusa', 'vc_support_general', 'crowdsale_token_price_max', '(first) date', 'ticker_symbol_cmc', 'manufacturing', 'electronics', 'real estate', 'celebrity endorsement', 'team member with business background', 'project code available', 'category', 'pct_of_crowdsale_target_raised', 'ico_end_date_planned', 'ico_end_date_actual', 'percentage of hard cap raised (%)', 'big data', 'amount raised in crowdsale (usdm)', '__source___yan', 'legal entity is corporation', 'legal entity is llc', 'symbol_std_yan', 'regtax', 'lock up period unsold tokens (years)', 'team tokens locked up', 'legal entity is corporation or llc', 'legal advisor disclosed', 'platform', 'sold_coins', 'infrastructre', 'restchina', 'ico_token_price', 'amount raised', 'independent custodian for ico funds', 'symbol_std_icpsr', 'ticker', 'price mkt', 'received_money', 'advisor_quality', 'team lockup period (weighted avg.)', 'development road map available', 'total amount raised (usdm)', 'use of proceeds mentioned', 'accepting', 'investors from other (non-us) jurisdictions excluded', 'fundraising_goal', 'neo', 'cap_includes_presale', 'crowdsale max. discount (%)', 'kyc/aml procedure', \"fundraiser has minimum ('soft cap')\", 'hardcap_usd', 'address', 'product can be tried out', 'platform.1', 'cant_participate', 'token share presale investors (ex ante)', 'additional_token_emissions', 'health', 'wlist', 'legal form and jurisdiction known', '__source__', 'software', 'is currency or general purpose blockchain', 'charity', 'total days.1', 'ltc', 'average_discount', 'ieo', 'business model available', 'is_ethereum', 'is a utility token', 'has_generalist_vc', 'price_presale', 'token_standard', 'presale tokens locked up', 'whitepaper page count', 'btc_ret_ico_period', 'token_is_cryptocurrency', 'media', 'ico ends', 'virtual reality', 'ico success', '__source___icpsr', \"fundraiser has maximum ('hard cap')\", '__key__', 'total_number_of_tokens', 'soft_cap_unit', 'post_money_val_crowdsale', 'simple agreement for future tokens (saft)', 'token_is_new_blockchain', 'is a security', 'length of crowdsale (calendar days, actual)', 'retail', 'ico_successful_yan', 'number_of_contributors', 'has_specialist_vc', 'fiat', 'mininvest', 'smart contract', 'unsold tokens kept by issuer', 'issuer has customers for product', 'web adress', 'team size', 'name_std_icpsr', 'high quality advisory team', 'tokens f sale', 'soft_cap', 'registration_country', 'team experience missing', 'presale_transparent', 'hard_cap', 'goal', 'funding milestones', 'artificial intelligence', 'crowdsale is auction', 'country', 'eth', 'eos', 'smart contract code available', 'name_cmc', 'price_crowdsale', 'name_other', 'switzerland', 'softcap', 'token share crowdsale investors (ex post)', 'zec', 'communication', 'investment', 'has a presale', 'min_max_personal_cap', 'softcap_usd', 'token_issue', 'issued_on_other_platf', 'ico starts']\n",
      "[ALL] Filas: 2,690  |  Columnas: 36\n",
      "\n",
      "Top 20 columnas con más missing (%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:144: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>has_reddit</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>has_telegram</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>website_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>interest</td>\n",
       "      <td>object</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>role_of_token</td>\n",
       "      <td>object</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>team_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>discount_max_pct</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ico_length_planned_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>88.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>has_github</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ico_length_actual_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>88.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>roadmap_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_tokens</td>\n",
       "      <td>float64</td>\n",
       "      <td>51.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>is_tax_regulated</td>\n",
       "      <td>Int64</td>\n",
       "      <td>45.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jurisdiction</td>\n",
       "      <td>object</td>\n",
       "      <td>31.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>accepts</td>\n",
       "      <td>object</td>\n",
       "      <td>24.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>23.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>min_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>23.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hard_cap_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tokens_for_sale</td>\n",
       "      <td>float64</td>\n",
       "      <td>21.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column    dtype  missing_%\n",
       "26               has_reddit    Int64     100.00\n",
       "25             has_telegram    Int64     100.00\n",
       "29                   rating  float64     100.00\n",
       "27        website_available    Int64     100.00\n",
       "30                 interest   object      92.60\n",
       "19            role_of_token   object      92.57\n",
       "28                team_size  float64      89.52\n",
       "31         discount_max_pct  float64      89.22\n",
       "5   ico_length_planned_days  float64      88.74\n",
       "24               has_github    Int64      88.62\n",
       "4    ico_length_actual_days  float64      88.62\n",
       "32        roadmap_available    Int64      88.62\n",
       "13             total_tokens  float64      51.34\n",
       "35         is_tax_regulated    Int64      45.76\n",
       "22             jurisdiction   object      31.64\n",
       "23                  accepts   object      24.01\n",
       "16       max_investment_usd  float64      23.68\n",
       "15       min_investment_usd  float64      23.68\n",
       "7              hard_cap_usd  float64      22.45\n",
       "14          tokens_for_sale  float64      21.71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EX-ANTE] Columnas removidas por leakage: ['amount_raised_usd', 'hit_hardcap', 'hit_softcap', 'ico_end_date', 'ico_length_actual_days']\n",
      "[EX-ANTE] Filas: 2,690  |  Columnas: 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>has_reddit</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>has_telegram</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>website_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>interest</td>\n",
       "      <td>object</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>role_of_token</td>\n",
       "      <td>object</td>\n",
       "      <td>92.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>team_size</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>discount_max_pct</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ico_length_planned_days</td>\n",
       "      <td>float64</td>\n",
       "      <td>88.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>has_github</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>roadmap_available</td>\n",
       "      <td>Int64</td>\n",
       "      <td>88.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_tokens</td>\n",
       "      <td>float64</td>\n",
       "      <td>51.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>is_tax_regulated</td>\n",
       "      <td>Int64</td>\n",
       "      <td>45.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jurisdiction</td>\n",
       "      <td>object</td>\n",
       "      <td>31.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>accepts</td>\n",
       "      <td>object</td>\n",
       "      <td>24.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>23.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>min_investment_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>23.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard_cap_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tokens_for_sale</td>\n",
       "      <td>float64</td>\n",
       "      <td>21.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>is_ieo</td>\n",
       "      <td>Int64</td>\n",
       "      <td>18.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column    dtype  missing_%\n",
       "21               has_reddit    Int64     100.00\n",
       "20             has_telegram    Int64     100.00\n",
       "24                   rating  float64     100.00\n",
       "22        website_available    Int64     100.00\n",
       "25                 interest   object      92.60\n",
       "14            role_of_token   object      92.57\n",
       "23                team_size  float64      89.52\n",
       "26         discount_max_pct  float64      89.22\n",
       "3   ico_length_planned_days  float64      88.74\n",
       "19               has_github    Int64      88.62\n",
       "27        roadmap_available    Int64      88.62\n",
       "8              total_tokens  float64      51.34\n",
       "30         is_tax_regulated    Int64      45.76\n",
       "17             jurisdiction   object      31.64\n",
       "18                  accepts   object      24.01\n",
       "11       max_investment_usd  float64      23.68\n",
       "10       min_investment_usd  float64      23.68\n",
       "5              hard_cap_usd  float64      22.45\n",
       "9           tokens_for_sale  float64      21.71\n",
       "29                   is_ieo    Int64      18.81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Guardados:\n",
      " - Canónico: ../join/ico_union_canonical_v6.csv\n",
      " - Ex-ante:  ../join/ico_exante_features_v3.csv\n",
      "\n",
      "Columnas en el dataset final ex-ante: ['name_std', 'symbol_std', 'ico_start_date', 'ico_length_planned_days', 'soft_cap', 'hard_cap', 'ico_successful', 'token_price_usd', 'total_tokens', 'tokens_for_sale', 'min_investment_usd', 'max_investment_usd', 'industry', 'token_type', 'role_of_token', 'whitelist', 'kyc', 'jurisdiction', 'accepts', 'has_github', 'has_telegram', 'has_reddit', 'website_available', 'team_size', 'rating', 'interest', 'discount_max_pct', 'roadmap_available', 'whitepaper_available', 'is_ieo', 'is_tax_regulated']\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd, numpy as np, re\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "IN_PATH   = \"../join/ico_union_wide.csv\"\n",
    "OUT_ALL   = \"../join/ico_union_canonical_v6.csv\"         # dataset canónico (todo)\n",
    "OUT_EXANT = \"../join/ico_exante_features_v3.csv\"         # solo features pre-ICO + y\n",
    "\n",
    "# ------------------ Load --------------------\n",
    "df = pd.read_csv(IN_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# prioridad de fuentes (izq→der)\n",
    "SUFFIXES = [\"_zenodo\", \"_icpsr\", \"_yan\"]\n",
    "\n",
    "def split_base_and_suffix(col: str):\n",
    "    for s in SUFFIXES:\n",
    "        if col.endswith(s):\n",
    "            return col[:-len(s)], s\n",
    "    return col, \"\"\n",
    "\n",
    "# indexar base -> columnas\n",
    "base_to_cols = {}\n",
    "for c in df.columns:\n",
    "    b, s = split_base_and_suffix(c)\n",
    "    base_to_cols.setdefault(b, []).append(c)\n",
    "\n",
    "# ------------------ Helpers -----------------\n",
    "def money_like_to_float(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip().lower().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        mult = 1\n",
    "        if \"billion\" in x or (re.search(r\"\\d\", x) and x.endswith(\"b\")): mult = 1_000_000_000\n",
    "        elif \"million\" in x or (re.search(r\"\\d\", x) and x.endswith(\"m\")): mult = 1_000_000\n",
    "        elif re.search(r\"\\d\", x) and x.endswith(\"k\"): mult = 1_000\n",
    "        nums = re.findall(r\"[\\d.]+\", x)\n",
    "        return float(nums[0]) * mult if nums else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_date_like(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    x = str(s).strip()\n",
    "    x = re.sub(r\"^(ended|end|finished|finalized)\\s*:?\\s*\", \"\", x, flags=re.IGNORECASE)\n",
    "    x = x.replace(\"—\",\"-\").replace(\"–\",\"-\")\n",
    "    return x\n",
    "\n",
    "def boolify(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)) and not pd.isna(x):\n",
    "        return int(float(x) != 0)\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"sí\",\"present\",\"available\",\"ok\"}: return 1\n",
    "    if s in {\"0\",\"false\",\"no\",\"n\",\"absent\",\"unavailable\",\"none\"}: return 0\n",
    "    return np.nan\n",
    "\n",
    "def _first_nonnull(series_list):\n",
    "    out = pd.Series(np.nan, index=df.index)\n",
    "    for s in series_list or []:\n",
    "        if s is None: \n",
    "            continue\n",
    "        if isinstance(s, str):\n",
    "            if s in df.columns: v = df[s]\n",
    "            else:               continue\n",
    "        elif isinstance(s, pd.Series):\n",
    "            v = s\n",
    "        else:\n",
    "            continue\n",
    "        v = pd.Series(v).reindex(out.index)\n",
    "        out = out.where(~out.isna(), v)\n",
    "    return out\n",
    "\n",
    "def order_by_priority(cols):\n",
    "    with_suf = [c for c in cols if any(c.endswith(s) for s in SUFFIXES)]\n",
    "    no_suf   = [c for c in cols if c not in with_suf]\n",
    "    ordered = []\n",
    "    for s in SUFFIXES:\n",
    "        ordered += [c for c in with_suf if c.endswith(s)]\n",
    "    ordered += no_suf\n",
    "    seen, uniq = set(), []\n",
    "    for c in ordered:\n",
    "        if c in df.columns and c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "def find_cols_by_regex(patterns):\n",
    "    cols = []\n",
    "    for pat in patterns:\n",
    "        r = re.compile(pat, flags=re.IGNORECASE)\n",
    "        for base in base_to_cols.keys():\n",
    "            if r.search(base):\n",
    "                cols += base_to_cols[base]\n",
    "    return order_by_priority(cols)\n",
    "\n",
    "def coalesce_numeric_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    ser = _first_nonnull(cols)\n",
    "    ser_num = pd.to_numeric(ser, errors=\"coerce\")\n",
    "    if ser_num.notna().sum() < 0.2 * len(ser_num):\n",
    "        ser_num = ser.apply(money_like_to_float)\n",
    "    return ser_num\n",
    "\n",
    "def coalesce_text_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    ser = _first_nonnull(cols).astype(str).replace({\"nan\": np.nan})\n",
    "    return ser\n",
    "\n",
    "def coalesce_bool_from_patterns(pattern_groups):\n",
    "    cols = []\n",
    "    for group in pattern_groups:\n",
    "        cols += find_cols_by_regex(group)\n",
    "    if not cols:\n",
    "        return pd.Series(pd.array([pd.NA]*len(df), dtype=\"Int64\"), index=df.index)\n",
    "    ser = _first_nonnull(cols).map(boolify).astype(\"Int64\")\n",
    "    return ser\n",
    "\n",
    "def extract_min_max(s):\n",
    "    if pd.isna(s): return (np.nan, np.nan)\n",
    "    x = str(s).lower()\n",
    "    nums = re.findall(r\"[\\d.]+\", x)\n",
    "    if not nums: return (np.nan, np.nan)\n",
    "    if len(nums) == 1:\n",
    "        v = float(nums[0]); return (v, v)\n",
    "    return (float(nums[0]), float(nums[1]))\n",
    "\n",
    "def parse_dates_robust(s: pd.Series) -> pd.Series:\n",
    "    s = pd.Series(s, index=df.index)\n",
    "    parsed = pd.to_datetime(s, format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d/%m/%Y\", \"%b %d, %Y\"):\n",
    "        need = parsed.isna()\n",
    "        if need.any():\n",
    "            parsed.loc[need] = pd.to_datetime(s[need], format=fmt, errors=\"coerce\", dayfirst=True)\n",
    "    need = parsed.isna()\n",
    "    if need.any():\n",
    "        parsed.loc[need] = pd.to_datetime(s[need], errors=\"coerce\", dayfirst=True)\n",
    "    return parsed\n",
    "\n",
    "# ------------------ Aliases (regex) -----------------\n",
    "ALIASES = {\n",
    "    # Identidad\n",
    "    \"name_std\":   [[r\"^name_std$\"]],\n",
    "    \"symbol_std\": [[r\"^symbol_std$\"]],\n",
    "\n",
    "    # Fechas\n",
    "    \"start_direct\": [[r\"^ico_start_date$\", r\"^ico starts$\", r\"\\bico_start\\b\", r\"sale_start\", r\"preico_start\"]],\n",
    "    \"end_direct\":   [[r\"^ico_end_date_actual$\", r\"^ico_end_date_planned$\", r\"^ico ends$\", r\"^end_date_parsed$\", r\"^end_date\\b\", r\"\\bico_end\\b\", r\"sale_end\", r\"token_sale_end\"]],\n",
    "    \"date_range\":   [[r\"^start_end_date_coin_sell$\", r\"ico_dates\", r\"date_range\"]],\n",
    "\n",
    "    # Recaudación / objetivos\n",
    "    \"goal_usd\":           [[r\"^soft_cap_usd$\", r\"^soft_cap$\", r\"^softcap_usd$\", r\"^softcap$\", r\"^fundraising_goal$\", r\"^goal$\"]],\n",
    "    \"hard_cap_usd\":       [[r\"^hard_cap_usd$\", r\"^hard_cap$\", r\"^hardcap_usd$\", r\"^hardcap$\"]],\n",
    "    \"amount_raised_usd\":  [[r\"^total amount raised \\(usdm\\)$\", r\"^total amount raised \\(usdm\\)\\.1$\", r\"^amount raised_usd$\", r\"^amount raised$\", r\"^received_money(\\.1)?$\"]],\n",
    "\n",
    "    # Éxito\n",
    "    \"ico_successful\":     [[r\"^ico_successful$\", r\"^ico success$\", r\"^success$\", r\"^successful$\"]],\n",
    "\n",
    "    # Tokenomics\n",
    "    \"token_price_usd\":    [[r\"^crowdsale_actual_token_price_max$\", r\"^price ico$\", r\"^ico_token_price$\"]],\n",
    "    \"total_tokens\":       [[r\"^total_number_of_tokens$\", r\"^circsupply$\", r\"^total_tokens$\"]],\n",
    "    \"tokens_for_sale\":    [[r\"^crowdsale_tokens_sold$\", r\"^tokens f sale$\", r\"^available_for_token_sale$\"]],\n",
    "\n",
    "    # Min/Max inversión\n",
    "    \"min_investment\":     [[r\"^mininvest$\", r\"min[_ ]?investment\", r\"minimum[_ ]?investment\", r\"min[_ ]?max[_ ]?personal[_ ]?cap\"]],\n",
    "    \"max_investment\":     [[r\"^mininvest$\", r\"max[_ ]?investment\", r\"maximum[_ ]?investment\", r\"min[_ ]?max[_ ]?personal[_ ]?cap\"]],\n",
    "\n",
    "    # Tipo/rol token\n",
    "    \"token_type\":         [[r\"^token_type$\", r\"^protocol type$\", r\"utility token enables decentralization\", r\"\\btype\\b\"]],\n",
    "    \"role_of_token\":      [[r\"^role_of_token$\", r\"\\brole\\b\"]],\n",
    "    \"industry\":           [[r\"^industry$\"],[r\"^category$\"]],\n",
    "\n",
    "    # Compliance / Jurisdicción\n",
    "    \"whitelist\":          [[r\"^qualified investors only$\", r\"^us retail investors excluded$\", r\"^wlist$\", r\"^whitelist$\"]],\n",
    "    \"kyc\":                [[r\"^kyc/aml procedure$\", r\"^kyc$\", r\"^regulkyc$\"]],\n",
    "    \"jurisdiction\":       [[r\"^registration_country$\", r\"^country$\", r\"^legal_structure$\"]],\n",
    "    \"accepts\":            [[r\"^accepting$\", r\"\\baccepts\\b\", r\"currencies[_ ]?accepted\"]],\n",
    "\n",
    "    # Señales de ejecución / presencia\n",
    "    \"has_github\":         [[r\"^project code available$\", r\"^smart contract code available$\", r\"github\", r\"code[_ ]?available\"]],\n",
    "    \"website_available\":  [[r\"website[_ ]?available\", r\"\\bwebsite\\b\", r\"\\bsite\\b\"]],\n",
    "\n",
    "    # Equipo / rating / interés / docs\n",
    "    \"team_size\":          [[r\"^team size$\", r\"^team_size$\", r\"teamsize\"]],\n",
    "    \"rating\":             [[r\"^rating$\", r\"^ico[_ ]?rating$\", r\"^score$\"]],\n",
    "    \"interest\":           [[r\"^interest$\"]],\n",
    "    \"discount_max_pct\":   [[r\"^crowdsale max\\. discount \\(%\\)$\", r\"^presale discount \\(%\\)$\", r\"max[_ ]?discount\"]],\n",
    "    \"roadmap_available\":  [[r\"^development road map available$\", r\"roadmap[_ ]?available\", r\"has[_ ]?roadmap\"]],\n",
    "    \"whitepaper_available\":[[r\"whitepaper[_ ]?available\", r\"white[_ ]?paper\"]],\n",
    "    \"whitepaper_page_count\": [[r\"^whitepaper page count$\"]],\n",
    "\n",
    "    # Duraciones / IEO / RegTax\n",
    "    \"ico_length_actual\":  [[r\"^length of crowdsale \\(calendar days, actual\\)$\", r\"ico[_ ]?length[_ ]?actual\"]],\n",
    "    \"ico_length_planned\": [[r\"^length of crowdsale \\(calendar days, planned\\)$\", r\"ico[_ ]?length[_ ]?planned\"]],\n",
    "    \"ieo\":                [[r\"^ieo$\", r\"initial[_ ]?exchange[_ ]?offering\", r\"used[_ ]?an[_ ]?exchange\"]],\n",
    "    \"regtax\":             [[r\"^regtax$\", r\"reg[_ ]?tax\", r\"tax[_ ]?reg(ulation)?\", r\"regulation[_ ]?on[_ ]?transfer\"]],\n",
    "}\n",
    "\n",
    "# ------------------ Build canónico ------------------\n",
    "out = pd.DataFrame(index=df.index)\n",
    "\n",
    "# Identidad\n",
    "out[\"name_std\"]   = _first_nonnull(order_by_priority(find_cols_by_regex(ALIASES[\"name_std\"][0])))\n",
    "out[\"symbol_std\"] = _first_nonnull(order_by_priority(find_cols_by_regex(ALIASES[\"symbol_std\"][0])))\n",
    "\n",
    "# Fechas\n",
    "start_direct = coalesce_text_from_patterns(ALIASES[\"start_direct\"])\n",
    "end_direct   = coalesce_text_from_patterns(ALIASES[\"end_direct\"])\n",
    "date_range   = coalesce_text_from_patterns(ALIASES[\"date_range\"])\n",
    "\n",
    "left_from_range  = date_range.astype(str).str.extract(r\"^\\s*([^-–—|to]+)\", expand=False)\n",
    "right_from_range = date_range.astype(str).str.extract(r\"[-–—|to]\\s*(.*)$\",   expand=False)\n",
    "\n",
    "def _clean_date_series(s):\n",
    "    return s.astype(str).map(clean_date_like).replace({\"nan\": np.nan})\n",
    "\n",
    "start_txt = start_direct.copy()\n",
    "start_txt = start_txt.mask(start_txt.notna(), start_txt).mask(start_txt.isna(), _clean_date_series(left_from_range))\n",
    "end_txt   = end_direct.copy()\n",
    "end_txt   = end_txt.mask(end_txt.notna(), end_txt).mask(end_txt.isna(), _clean_date_series(right_from_range))\n",
    "\n",
    "out[\"ico_start_date\"] = parse_dates_robust(start_txt)\n",
    "out[\"ico_end_date\"]   = parse_dates_robust(end_txt)\n",
    "\n",
    "# Recaudación / objetivos\n",
    "out[\"goal_usd\"]          = coalesce_numeric_from_patterns(ALIASES[\"goal_usd\"])\n",
    "out[\"hard_cap_usd\"]      = coalesce_numeric_from_patterns(ALIASES[\"hard_cap_usd\"])\n",
    "out[\"amount_raised_usd\"] = coalesce_numeric_from_patterns(ALIASES[\"amount_raised_usd\"])\n",
    "\n",
    "# Éxito (target)\n",
    "succ = coalesce_text_from_patterns(ALIASES[\"ico_successful\"])\n",
    "out[\"ico_successful\"] = succ.map(boolify)\n",
    "\n",
    "# Tokenomics\n",
    "out[\"token_price_usd\"] = coalesce_numeric_from_patterns(ALIASES[\"token_price_usd\"])\n",
    "out[\"total_tokens\"]    = coalesce_numeric_from_patterns(ALIASES[\"total_tokens\"])\n",
    "out[\"tokens_for_sale\"] = coalesce_numeric_from_patterns(ALIASES[\"tokens_for_sale\"])\n",
    "\n",
    "# Min/Max investment\n",
    "mininv_raw = coalesce_text_from_patterns(ALIASES[\"min_investment\"])\n",
    "maxinv_raw = coalesce_text_from_patterns(ALIASES[\"max_investment\"])\n",
    "mn, mx  = zip(*mininv_raw.map(extract_min_max))\n",
    "mn2, mx2 = zip(*maxinv_raw.map(extract_min_max))\n",
    "mx_final = pd.Series(mx, index=df.index).where(pd.notna(pd.Series(mx, index=df.index)), pd.Series(mx2, index=df.index))\n",
    "out[\"min_investment_usd\"] = pd.to_numeric(pd.Series(mn, index=df.index), errors=\"coerce\")\n",
    "out[\"max_investment_usd\"] = pd.to_numeric(mx_final, errors=\"coerce\")\n",
    "\n",
    "# Categóricas / flags\n",
    "out[\"industry\"]    = coalesce_text_from_patterns(ALIASES[\"industry\"])\n",
    "out[\"token_type\"]    = coalesce_text_from_patterns(ALIASES[\"token_type\"])\n",
    "out[\"role_of_token\"] = coalesce_text_from_patterns(ALIASES[\"role_of_token\"])\n",
    "out[\"whitelist\"]     = coalesce_bool_from_patterns(ALIASES[\"whitelist\"])\n",
    "out[\"kyc\"]           = coalesce_bool_from_patterns(ALIASES[\"kyc\"])\n",
    "out[\"jurisdiction\"]  = coalesce_text_from_patterns(ALIASES[\"jurisdiction\"])\n",
    "out[\"accepts\"]       = coalesce_text_from_patterns(ALIASES[\"accepts\"])\n",
    "\n",
    "# Señales de ejecución / presencia\n",
    "out[\"has_github\"]        = coalesce_bool_from_patterns(ALIASES[\"has_github\"])\n",
    "out[\"has_telegram\"]      = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "out[\"has_reddit\"]        = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "out[\"website_available\"] = coalesce_bool_from_patterns(ALIASES[\"website_available\"])\n",
    "\n",
    "# Equipo / rating / interés / docs\n",
    "out[\"team_size\"] = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"team_size\"]), errors=\"coerce\")\n",
    "out[\"rating\"]    = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"rating\"]), errors=\"coerce\")\n",
    "out[\"interest\"]  = coalesce_text_from_patterns(ALIASES[\"interest\"])\n",
    "disc = coalesce_text_from_patterns(ALIASES[\"discount_max_pct\"]).astype(str).str.extract(r\"([\\d.]+)\", expand=False)\n",
    "out[\"discount_max_pct\"] = pd.to_numeric(disc, errors=\"coerce\")\n",
    "out[\"roadmap_available\"] = coalesce_bool_from_patterns(ALIASES[\"roadmap_available\"])\n",
    "\n",
    "# Whitepaper: page_count > 0 OR flag explícito\n",
    "wp_count = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"whitepaper_page_count\"]), errors=\"coerce\")\n",
    "wp_flag  = (wp_count > 0).astype(\"Int64\")\n",
    "wp_other = coalesce_bool_from_patterns(ALIASES[\"whitepaper_available\"])\n",
    "out[\"whitepaper_available\"] = wp_flag.where(wp_flag.notna(), wp_other)\n",
    "\n",
    "# Duraciones / IEO / RegTax\n",
    "out[\"ico_length_actual_days\"]  = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"ico_length_actual\"]), errors=\"coerce\")\n",
    "out[\"ico_length_planned_days\"] = pd.to_numeric(coalesce_text_from_patterns(ALIASES[\"ico_length_planned\"]), errors=\"coerce\")\n",
    "out[\"is_ieo\"]           = coalesce_bool_from_patterns(ALIASES[\"ieo\"])\n",
    "out[\"is_tax_regulated\"] = coalesce_bool_from_patterns(ALIASES[\"regtax\"])\n",
    "\n",
    "# Flags derivados (ojo: son post-ICO, NO usarlos como features ex-ante)\n",
    "out[\"hit_softcap\"] = ((out[\"amount_raised_usd\"] >= out[\"goal_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"goal_usd\"].notna()).astype(\"Int64\")\n",
    "out[\"hit_hardcap\"] = ((out[\"amount_raised_usd\"] >= out[\"hard_cap_usd\"]) & out[\"amount_raised_usd\"].notna() & out[\"hard_cap_usd\"].notna()).astype(\"Int64\")\n",
    "\n",
    "# Backfills mínimos para el target\n",
    "if \"ico_successful\" in out.columns and \"hit_softcap\" in out.columns:\n",
    "    mask_empty = out[\"ico_successful\"].isna()\n",
    "    out.loc[mask_empty, \"ico_successful\"] = out.loc[mask_empty, \"hit_softcap\"]\n",
    "\n",
    "# Si falta goal_usd pero hay hardcap, usar hardcap como proxy\n",
    "mask_goal_missing = out[\"goal_usd\"].isna() & out[\"hard_cap_usd\"].notna()\n",
    "out.loc[mask_goal_missing, \"goal_usd\"] = out.loc[mask_goal_missing, \"hard_cap_usd\"]\n",
    "\n",
    "# Orden final y dedupe\n",
    "ordered = [\n",
    "    \"name_std\",\"symbol_std\",\n",
    "    \"ico_start_date\",\"ico_end_date\",\"ico_length_actual_days\",\"ico_length_planned_days\",\n",
    "    \"goal_usd\",\"hard_cap_usd\",\"amount_raised_usd\",\"ico_successful\",\"hit_softcap\",\"hit_hardcap\",\n",
    "    \"token_price_usd\",\"total_tokens\",\"tokens_for_sale\",\"min_investment_usd\",\"max_investment_usd\",\n",
    "    \"industry\",\"token_type\",\"role_of_token\",\"whitelist\",\"kyc\",\"jurisdiction\",\"accepts\",\n",
    "    \"has_github\",\"has_telegram\",\"has_reddit\",\"website_available\",\n",
    "    \"team_size\",\"rating\",\"interest\",\"discount_max_pct\",\"roadmap_available\",\"whitepaper_available\",\n",
    "    \"is_ieo\",\"is_tax_regulated\",\n",
    "]\n",
    "ordered = [c for c in ordered if c in out.columns] + [c for c in out.columns if c not in ordered]\n",
    "out = out[ordered].copy()\n",
    "\n",
    "# Deduplicar por (name_std, symbol_std) conservando la primera ocurrencia con más info (heurística: menos NaN)\n",
    "def _nan_count_row(r): return r.isna().sum()\n",
    "out[\"_nan_cnt\"] = out.apply(_nan_count_row, axis=1)\n",
    "out.sort_values(by=[\"name_std\",\"symbol_std\",\"_nan_cnt\"], ascending=[True, True, True], inplace=True)\n",
    "out = out.drop_duplicates(subset=[\"name_std\",\"symbol_std\"], keep=\"first\").drop(columns=[\"_nan_cnt\"])\n",
    "\n",
    "\n",
    "# ------------------ Reporte canónico -----------------\n",
    "def missing_pct(s): \n",
    "    return round(100*s.isna().mean(), 2)\n",
    "\n",
    "report_all = pd.DataFrame({\n",
    "    \"column\": out.columns,\n",
    "    \"dtype\": [str(out[c].dtype) for c in out.columns],\n",
    "    \"missing_%\": [missing_pct(out[c]) for c in out.columns]\n",
    "}).sort_values([\"missing_%\",\"column\"], ascending=[False, True])\n",
    "\n",
    "print(f'Columnas dataset inicial: {df.columns.tolist()}')\n",
    "print(f'Columnas dataset finaaal: {out.columns.tolist()}')\n",
    "\n",
    "#intersection = list(set(df.columns.tolist()).intersection(set(out.columns.tolist()))\n",
    "diferencia = list(set(df.columns.tolist()) - set((out.columns.tolist())))\n",
    "                  \n",
    "#print(f'Interseccion de columnas: {intersection}')\n",
    "print(f'Diferencia de columnas: {diferencia}')\n",
    "\n",
    "print(f\"[ALL] Filas: {len(out):,}  |  Columnas: {out.shape[1]}\")\n",
    "print(\"\\nTop 20 columnas con más missing (%):\")\n",
    "try:\n",
    "    display(report_all.head(20))\n",
    "except Exception:\n",
    "    print(report_all.head(20).to_string(index=False))\n",
    "\n",
    "\n",
    "# ------------------ Construir EX-ANTE ------------------\n",
    "# Columnas que consideramos POST-ICO (leakage) y se excluyen del feature set ex-ante:\n",
    "LEAKY_COLS = {\n",
    "    \"amount_raised_usd\",        # resultado\n",
    "    \"hit_softcap\", \"hit_hardcap\",\n",
    "    \"ico_length_actual_days\",   # duración real\n",
    "    # 'ico_end_date' podría ser planificada o real según la fuente -> la EXCLUIMOS del ex-ante por prudencia\n",
    "    \"ico_end_date\",\n",
    "    # Derivadas que no guardamos acá (pct_goal_reached, hardcap_ratio, etc.) si existieran\n",
    "}\n",
    "\n",
    "# Mantenemos el target (ico_successful) para entrenamiento/validación, pero no como feature.\n",
    "KEEP_ALWAYS = {\"name_std\",\"symbol_std\",\"ico_successful\"}\n",
    "\n",
    "exante_cols = [c for c in out.columns if c not in LEAKY_COLS]  # removemos leaky\n",
    "out_ex = out[exante_cols].copy()\n",
    "\n",
    "# Reporte ex-ante (y lista de leaky removidas)\n",
    "removed_present = sorted(list(LEAKY_COLS.intersection(set(out.columns))))\n",
    "print(\"\\n[EX-ANTE] Columnas removidas por leakage:\", removed_present)\n",
    "print(f\"[EX-ANTE] Filas: {len(out_ex):,}  |  Columnas: {out_ex.shape[1]}\")\n",
    "\n",
    "report_ex = pd.DataFrame({\n",
    "    \"column\": out_ex.columns,\n",
    "    \"dtype\": [str(out_ex[c].dtype) for c in out_ex.columns],\n",
    "    \"missing_%\": [missing_pct(out_ex[c]) for c in out_ex.columns]\n",
    "}).sort_values([\"missing_%\",\"column\"], ascending=[False, True])\n",
    "\n",
    "try:\n",
    "    display(report_ex.head(20))\n",
    "except Exception:\n",
    "    print(report_ex.head(20).to_string(index=False))\n",
    "\n",
    "\n",
    "# Renombre de columnas para consistencia con el dataset de foundico\n",
    "out.rename(columns={'goal_usd': 'soft_cap', \n",
    "                    'hard_cap_usd': 'hard_cap',\n",
    "                    'hit_softcap': 'hit_soft_cap', \n",
    "                    'hit_hardcap': 'hit_hard_cap', \n",
    "                    'amount_raised_usd': 'amount_raised'}, \n",
    "              inplace=True)\n",
    "out_ex.rename(columns={'goal_usd': 'soft_cap', \n",
    "                    'hard_cap_usd': 'hard_cap', \n",
    "                    'hit_softcap': 'hit_soft_cap', \n",
    "                    'hit_hardcap': 'hit_hard_cap', \n",
    "                    'amount_raised_usd': 'amount_raised'}, \n",
    "              inplace=True)\n",
    "\n",
    "\n",
    "# ------------------ Save --------------------\n",
    "out.to_csv(OUT_ALL, index=False)\n",
    "out_ex.to_csv(OUT_EXANT, index=False)\n",
    "print(f\"\\n✅ Guardados:\\n - Canónico: {OUT_ALL}\\n - Ex-ante:  {OUT_EXANT}\")\n",
    "print(f\"\\nColumnas en el dataset final ex-ante: {out_ex.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96adc1e2-75ac-45e8-881b-85e4af6124f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ico_successful\n",
      "0.0    2072\n",
      "1.0     618\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(out[\"ico_successful\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e03c1-67e9-42fd-b70c-f0c00a5ce81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
