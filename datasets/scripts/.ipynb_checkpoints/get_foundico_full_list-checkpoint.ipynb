{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b007a489-18ce-4d0e-b9ae-7202ad528459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FOUNDI_PUBLIC_KEY=\"5e6fc744cf305a8fea1e5669057c5d11\"\n",
      "env: FOUNDI_PRIVATE_KEY=\"3f824123907803e8b9a402ed7bdb0dd2\"\n"
     ]
    }
   ],
   "source": [
    "# TODO - Eliminar claves antes de commitear!\n",
    "%env FOUNDI_PUBLIC_KEY=\"5e6fc744cf305a8fea1e5669057c5d11\"\n",
    "%env FOUNDI_PRIVATE_KEY=\"3f824123907803e8b9a402ed7bdb0dd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2495c51f-da31-4967-b302-8b7decec56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## FoundICO: dump completo ‚Üí CSV normalizado ‚Üí match offline con nuestro dataset\n",
    "\n",
    "# %%\n",
    "import os, json, time, base64, hmac, hashlib, math, re\n",
    "from typing import Dict, Any, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# === Credenciales ===\n",
    "#FOUNDI_PUBLIC_KEY  = os.getenv(\"FOUNDI_PUBLIC_KEY\")\n",
    "#FOUNDI_PRIVATE_KEY = os.getenv(\"FOUNDI_PRIVATE_KEY\")\n",
    "FOUNDI_PUBLIC_KEY     = '5e6fc744cf305a8fea1e5669057c5d11'\n",
    "FOUNDI_PRIVATE_KEY    = '3f824123907803e8b9a402ed7bdb0dd2'\n",
    "\n",
    "assert FOUNDI_PUBLIC_KEY and FOUNDI_PRIVATE_KEY, \"Faltan FOUNDI_PUBLIC_KEY / FOUNDI_PRIVATE_KEY\"\n",
    "\n",
    "# === Rutas ===\n",
    "FOUN_RAW_JSON = \"../foundico/foundico_catalog.jsonl\"   # todas las p√°ginas, 1 JSON por l√≠nea\n",
    "FOUN_CSV      = \"../foundico/foundico_catalog.csv\"     # CSV normalizado\n",
    "DATASET_IN    = \"../final/ico_union_canonical_v3.csv\"  # tu dataset final (de entrada)\n",
    "DATASET_OUT   = \"../final/ico_union_enriched_foundico.csv\"  # enriquecido con FoundICO\n",
    "\n",
    "# === Par√°metros ===\n",
    "BASE = \"https://foundico.com/api/v1\"\n",
    "PAGE_SIZE = 20           # FoundICO trae 20 por p√°gina\n",
    "MAX_PAGES = 9999         # l√≠mite ‚Äúalto‚Äù; corta solo si la API ya no devuelve data\n",
    "STATUS = \"past\"          # 'past' = finalizadas; tambi√©n hay 'active', 'upcoming'\n",
    "SLEEP = 0.45             # pausa anti rate-limit\n",
    "RESUME = True            # reanudar si ya existe JSONL parcial\n",
    "\n",
    "# === Helpers ===\n",
    "def sign_headers(body: Dict[str, Any]) -> Dict[str, str]:\n",
    "    body = {\"status\": \"past\", \"page\": 1}\n",
    "    payload = json.dumps(body, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "    signature = base64.b64encode(\n",
    "        hmac.new(FOUNDI_PRIVATE_KEY.encode(\"utf-8\"), payload.encode(\"utf-8\"), hashlib.sha256).digest()\n",
    "    ).decode(\"ascii\")\n",
    "    return {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-Foundico-Public-Key\": FOUNDI_PUBLIC_KEY,\n",
    "        \"X-Foundico-Access-Key\": signature\n",
    "    }\n",
    "\n",
    "def normalize_text(s: Optional[str]) -> str:\n",
    "    if s is None or (isinstance(s, float) and np.isnan(s)): return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def sim(a: str, b: str) -> float:\n",
    "    return SequenceMatcher(None, normalize_text(a), normalize_text(b)).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d64940-dee1-47f0-9bdc-8545edcc44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga FoundICO desde la p√°gina 99...\n",
      "pagina 99: 20 items. Total acumulado: 20\n",
      "pagina 100: 20 items. Total acumulado: 40\n",
      "pagina 101: 20 items. Total acumulado: 60\n",
      "pagina 102: 20 items. Total acumulado: 80\n",
      "pagina 103: 20 items. Total acumulado: 100\n",
      "pagina 104: 20 items. Total acumulado: 120\n",
      "pagina 105: 20 items. Total acumulado: 140\n",
      "pagina 106: 20 items. Total acumulado: 160\n",
      "pagina 107: 20 items. Total acumulado: 180\n",
      "pagina 108: 20 items. Total acumulado: 200\n",
      "pagina 109: 20 items. Total acumulado: 220\n",
      "pagina 110: 20 items. Total acumulado: 240\n",
      "pagina 111: 20 items. Total acumulado: 260\n",
      "pagina 112: 20 items. Total acumulado: 280\n",
      "pagina 113: 20 items. Total acumulado: 300\n",
      "pagina 114: 20 items. Total acumulado: 320\n",
      "pagina 115: 20 items. Total acumulado: 340\n",
      "pagina 116: 20 items. Total acumulado: 360\n",
      "pagina 117: 20 items. Total acumulado: 380\n",
      "pagina 118: 20 items. Total acumulado: 400\n",
      "pagina 119: 20 items. Total acumulado: 420\n",
      "pagina 120: 20 items. Total acumulado: 440\n",
      "pagina 121: 20 items. Total acumulado: 460\n",
      "pagina 122: 20 items. Total acumulado: 480\n",
      "pagina 123: 20 items. Total acumulado: 500\n",
      "pagina 124: 20 items. Total acumulado: 520\n",
      "pagina 125: 20 items. Total acumulado: 540\n",
      "pagina 126: 20 items. Total acumulado: 560\n",
      "pagina 127: 20 items. Total acumulado: 580\n",
      "pagina 128: 20 items. Total acumulado: 600\n",
      "pagina 129: 20 items. Total acumulado: 620\n",
      "pagina 130: 20 items. Total acumulado: 640\n",
      "pagina 131: 20 items. Total acumulado: 660\n",
      "pagina 132: 20 items. Total acumulado: 680\n",
      "pagina 133: 20 items. Total acumulado: 700\n",
      "pagina 134: 20 items. Total acumulado: 720\n",
      "pagina 135: 20 items. Total acumulado: 740\n",
      "pagina 136: 20 items. Total acumulado: 760\n",
      "pagina 137: 20 items. Total acumulado: 780\n",
      "pagina 138: 20 items. Total acumulado: 800\n",
      "pagina 139: 20 items. Total acumulado: 820\n",
      "pagina 140: 20 items. Total acumulado: 840\n",
      "pagina 141: 20 items. Total acumulado: 860\n",
      "pagina 142: 20 items. Total acumulado: 880\n",
      "pagina 143: 20 items. Total acumulado: 900\n",
      "pagina 144: 20 items. Total acumulado: 920\n",
      "pagina 145: 20 items. Total acumulado: 940\n",
      "pagina 146: 20 items. Total acumulado: 960\n",
      "pagina 147: 20 items. Total acumulado: 980\n",
      "pagina 148: 20 items. Total acumulado: 1000\n",
      "pagina 149: 20 items. Total acumulado: 1020\n",
      "pagina 150: 20 items. Total acumulado: 1040\n",
      "pagina 151: 20 items. Total acumulado: 1060\n",
      "pagina 152: 20 items. Total acumulado: 1080\n",
      "pagina 153: 20 items. Total acumulado: 1100\n",
      "pagina 154: 20 items. Total acumulado: 1120\n",
      "pagina 155: 20 items. Total acumulado: 1140\n",
      "pagina 156: 20 items. Total acumulado: 1160\n",
      "pagina 157: 20 items. Total acumulado: 1180\n",
      "pagina 158: 20 items. Total acumulado: 1200\n",
      "pagina 159: 20 items. Total acumulado: 1220\n",
      "pagina 160: 20 items. Total acumulado: 1240\n",
      "pagina 161: 20 items. Total acumulado: 1260\n",
      "pagina 162: 20 items. Total acumulado: 1280\n",
      "pagina 163: 20 items. Total acumulado: 1300\n",
      "pagina 164: 20 items. Total acumulado: 1320\n",
      "pagina 165: 20 items. Total acumulado: 1340\n",
      "pagina 166: 20 items. Total acumulado: 1360\n",
      "pagina 167: 20 items. Total acumulado: 1380\n",
      "pagina 168: 20 items. Total acumulado: 1400\n",
      "pagina 169: 20 items. Total acumulado: 1420\n",
      "pagina 170: 20 items. Total acumulado: 1440\n",
      "pagina 171: 20 items. Total acumulado: 1460\n",
      "pagina 172: 20 items. Total acumulado: 1480\n",
      "pagina 173: 20 items. Total acumulado: 1500\n",
      "pagina 174: 20 items. Total acumulado: 1520\n",
      "pagina 175: 20 items. Total acumulado: 1540\n",
      "pagina 176: 20 items. Total acumulado: 1560\n",
      "pagina 177: 20 items. Total acumulado: 1580\n",
      "pagina 178: 20 items. Total acumulado: 1600\n",
      "pagina 179: 20 items. Total acumulado: 1620\n",
      "pagina 180: 20 items. Total acumulado: 1640\n",
      "pagina 181: 20 items. Total acumulado: 1660\n",
      "pagina 182: 20 items. Total acumulado: 1680\n",
      "pagina 183: 6 items. Total acumulado: 1686\n",
      "‚úÖ Dump completo guardado en foundico/foundico_catalog.jsonl ‚Äî items: 1686\n"
     ]
    }
   ],
   "source": [
    "# %% Descargar todo FoundICO (paginado) a JSONL\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "   \n",
    "os.makedirs(os.path.dirname(FOUN_RAW_JSON), exist_ok=True)\n",
    "\n",
    "# detectar √∫ltima p√°gina descargada (para reanudar)\n",
    "start_page = 1\n",
    "if RESUME and os.path.exists(FOUN_RAW_JSON):\n",
    "    # busca la √∫ltima l√≠nea con \"page\"\n",
    "    with open(FOUN_RAW_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        last = None\n",
    "        for line in f:\n",
    "            last = line\n",
    "    if last:\n",
    "        try:\n",
    "            ld = json.loads(last)\n",
    "            if \"page\" in ld:\n",
    "                start_page = int(ld[\"page\"]) + 1\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "print(f\"Descarga FoundICO desde la p√°gina {start_page}...\")\n",
    "\n",
    "total_saved = 0\n",
    "with open(FOUN_RAW_JSON, \"a\", encoding=\"utf-8\") as out:\n",
    "    for page in range(start_page, MAX_PAGES+1):\n",
    "        body = {\"page\": page, \"status\": STATUS}\n",
    "        payload = json.dumps(body, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "\n",
    "        signature = base64.b64encode(\n",
    "            hmac.new(FOUNDI_PRIVATE_KEY.encode(\"utf-8\"), payload.encode(\"utf-8\"), hashlib.sha256).digest()\n",
    "        ).decode(\"ascii\")\n",
    "        \n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Foundico-Public-Key\": FOUNDI_PUBLIC_KEY,\n",
    "            \"X-Foundico-Access-Key\": signature\n",
    "        }\n",
    "        \n",
    "        r = requests.post(\"https://foundico.com/api/v1/icos/\", headers=headers, data=payload, verify=False)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"[WARN] HTTP {r.status_code} en page={page}. Corto.\")\n",
    "            break\n",
    "        #print(r.json())\n",
    "        data = r.json()\n",
    "        arr = (data or {}).get(\"data\") or []\n",
    "        meta = {\n",
    "            \"page\": page,\n",
    "            \"count\": len(arr),\n",
    "            \"data\": arr\n",
    "        }\n",
    "        out.write(json.dumps(meta, ensure_ascii=False) + \"\\n\")\n",
    "        out.flush()\n",
    "        total_saved += len(arr)\n",
    "        print(f\"pagina {page}: {len(arr)} items. Total acumulado: {total_saved}\")\n",
    "        time.sleep(SLEEP)\n",
    "        if len(arr) < PAGE_SIZE:\n",
    "            # √∫ltima p√°gina\n",
    "            break\n",
    "\n",
    "print(f\"‚úÖ Dump completo guardado en {FOUN_RAW_JSON} ‚Äî items: {total_saved}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5afe0cf8-8a4b-4494-a367-8f244df3ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Cat√°logo FoundICO le√≠do: 3,645 ids √∫nicos en 183 p√°ginas (l√≠neas 183).\n",
      "üíæ Checkpoint: 50 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 100 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 150 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 200 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 250 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 300 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 350 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 400 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 450 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 500 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 550 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 600 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 650 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 700 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 750 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 800 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 850 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 900 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 950 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1000 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1050 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1100 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1150 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1200 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1250 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1300 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1350 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1400 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1450 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1500 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1550 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1600 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1650 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1700 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1750 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1800 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1850 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1900 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 1950 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2000 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2050 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2100 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2150 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2200 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2250 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2300 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2350 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2400 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2450 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2500 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2550 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2600 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2650 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2700 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2750 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2800 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2850 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2900 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 2950 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3000 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3050 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3100 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3150 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3200 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3250 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3300 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3350 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3400 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3450 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3500 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3550 filas -> foundico/foundico_details.csv\n",
      "üíæ Checkpoint: 3600 filas -> foundico/foundico_details.csv\n",
      "\n",
      "‚úÖ Terminado. Guardado 3645 filas en foundico/foundico_details.csv en 2976.6s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foundico_id</th>\n",
       "      <th>name</th>\n",
       "      <th>symbol</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>platform</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>whitepaper</th>\n",
       "      <th>github</th>\n",
       "      <th>...</th>\n",
       "      <th>token_type</th>\n",
       "      <th>soft_cap</th>\n",
       "      <th>hard_cap</th>\n",
       "      <th>caps_unit</th>\n",
       "      <th>accepting</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>ico_score</th>\n",
       "      <th>raised</th>\n",
       "      <th>markets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>SONM</td>\n",
       "      <td>SNM</td>\n",
       "      <td>Computing</td>\n",
       "      <td>ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Russia</td>\n",
       "      <td>https://sonm.io/</td>\n",
       "      <td>https://sonm.io/Sonm1.pdf</td>\n",
       "      <td>https://github.com/sonm-io</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.200000e+07</td>\n",
       "      <td>USD</td>\n",
       "      <td>BTC,ETH</td>\n",
       "      <td>2017-06-15 16:59:00</td>\n",
       "      <td>2017-06-17 17:03:00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>42000000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>openANX</td>\n",
       "      <td>OAX</td>\n",
       "      <td>Computing</td>\n",
       "      <td>ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>China</td>\n",
       "      <td>https://www.openanx.org/en/</td>\n",
       "      <td>https://www.openanx.org/en/assets/whitepaper/o...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.875000e+07</td>\n",
       "      <td>USD</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2017-06-22 20:52:00</td>\n",
       "      <td>2017-07-21 20:52:00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>18756937.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>Boul√©</td>\n",
       "      <td>BOU</td>\n",
       "      <td>Governance</td>\n",
       "      <td>Pre-ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>https://www.boule.one</td>\n",
       "      <td>https://www.dropbox.com/s/2x32r12e99xl4wq/boul...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>USD</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2017-08-28 09:08:00</td>\n",
       "      <td>2017-09-24 12:08:00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172</td>\n",
       "      <td>Lampix</td>\n",
       "      <td>PIX</td>\n",
       "      <td>Computing</td>\n",
       "      <td>ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>https://lampix.co</td>\n",
       "      <td>https://lampix.co/whitepaper.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>USD</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2017-08-08 08:08:00</td>\n",
       "      <td>2017-08-19 08:08:00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14200000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>VOTES</td>\n",
       "      <td>VOTES</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Pre-ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Russia</td>\n",
       "      <td>https://votesplatform.com/</td>\n",
       "      <td>https://votesplatform.com/assets/whitepaper/vo...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>USD</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-08-01 17:08:00</td>\n",
       "      <td>2017-08-31 13:08:00</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  foundico_id     name symbol    category     type  platform  \\\n",
       "0         126     SONM    SNM   Computing      ICO  Ethereum   \n",
       "1         132  openANX    OAX   Computing      ICO  Ethereum   \n",
       "2         166    Boul√©    BOU  Governance  Pre-ICO  Ethereum   \n",
       "3         172   Lampix    PIX   Computing      ICO  Ethereum   \n",
       "4         175    VOTES  VOTES   Computing  Pre-ICO  Ethereum   \n",
       "\n",
       "                   location                      website  \\\n",
       "0                    Russia             https://sonm.io/   \n",
       "1                     China  https://www.openanx.org/en/   \n",
       "2                   Estonia        https://www.boule.one   \n",
       "3  United States of America            https://lampix.co   \n",
       "4                    Russia   https://votesplatform.com/   \n",
       "\n",
       "                                          whitepaper  \\\n",
       "0                          https://sonm.io/Sonm1.pdf   \n",
       "1  https://www.openanx.org/en/assets/whitepaper/o...   \n",
       "2  https://www.dropbox.com/s/2x32r12e99xl4wq/boul...   \n",
       "3                   https://lampix.co/whitepaper.pdf   \n",
       "4  https://votesplatform.com/assets/whitepaper/vo...   \n",
       "\n",
       "                       github  ... token_type soft_cap      hard_cap  \\\n",
       "0  https://github.com/sonm-io  ...                 NaN  4.200000e+07   \n",
       "1                        None  ...                 NaN  1.875000e+07   \n",
       "2                        None  ...                 NaN  2.000000e+06   \n",
       "3                        None  ...                 NaN  1.100000e+09   \n",
       "4                        None  ...                 NaN  1.000000e+07   \n",
       "\n",
       "   caps_unit  accepting      start_datetime        end_datetime  ico_score  \\\n",
       "0        USD    BTC,ETH 2017-06-15 16:59:00 2017-06-17 17:03:00        6.7   \n",
       "1        USD        ETH 2017-06-22 20:52:00 2017-07-21 20:52:00        5.7   \n",
       "2        USD        ETH 2017-08-28 09:08:00 2017-09-24 12:08:00        5.6   \n",
       "3        USD        ETH 2017-08-08 08:08:00 2017-08-19 08:08:00        5.1   \n",
       "4        USD       None 2017-08-01 17:08:00 2017-08-31 13:08:00        4.8   \n",
       "\n",
       "       raised  markets  \n",
       "0  42000000.0           \n",
       "1  18756937.0           \n",
       "2         NaN           \n",
       "3  14200000.0           \n",
       "4         NaN           \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nulos por columna (%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raised</th>\n",
       "      <td>71.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>67.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_purchase</th>\n",
       "      <td>66.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>62.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_purchase</th>\n",
       "      <td>48.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_cap</th>\n",
       "      <td>32.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>31.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>10.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_for_sale</th>\n",
       "      <td>7.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_price</th>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_cap</th>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accepting</th>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ico_score</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_datetime</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_datetime</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caps_unit</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_type</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_unit</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foundico_id</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_price_unit</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mvp</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitelist</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kyc</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitepaper</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markets</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  missing_%\n",
       "raised                71.44\n",
       "github                67.85\n",
       "max_purchase          66.31\n",
       "reddit                62.61\n",
       "min_purchase          48.09\n",
       "soft_cap              32.84\n",
       "facebook              31.91\n",
       "twitter               10.75\n",
       "tokens_for_sale        7.82\n",
       "token_price            6.42\n",
       "hard_cap               1.51\n",
       "accepting              0.44\n",
       "symbol                 0.03\n",
       "ico_score              0.00\n",
       "end_datetime           0.00\n",
       "start_datetime         0.00\n",
       "caps_unit              0.00\n",
       "token_type             0.00\n",
       "purchase_unit          0.00\n",
       "foundico_id            0.00\n",
       "token_price_unit       0.00\n",
       "name                   0.00\n",
       "mvp                    0.00\n",
       "whitelist              0.00\n",
       "kyc                    0.00\n",
       "whitepaper             0.00\n",
       "website                0.00\n",
       "location               0.00\n",
       "platform               0.00\n",
       "type                   0.00\n",
       "category               0.00\n",
       "markets                0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.4 s\n",
      "Wall time: 49min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os, re, json, time, hmac, base64, hashlib, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "# ============ CONFIG ============\n",
    "CATALOG_JSONL = \"../foundico/foundico_catalog.jsonl\"   # cada l√≠nea: {\"page\": X, \"count\": Y, \"data\":[{...}, ...]}\n",
    "OUT_CSV       = \"../foundico/foundico_details.csv\"\n",
    "CHECKPOINT_EVERY = 50  # guarda incremental cada N items\n",
    "SLEEP_BETWEEN = 0.35   # seg entre requests\n",
    "RETRIES       = 2\n",
    "TIMEOUT       = 30\n",
    "\n",
    "if not FOUNDI_PUBLIC_KEY or not FOUNDI_PRIVATE_KEY:\n",
    "    print(\"‚ö†Ô∏è  FOUNDI_PUBLIC_KEY / FOUNDI_PRIVATE_KEY no seteadas (env). Pod√©s pegarlas en esta celda si quer√©s.\")\n",
    "\n",
    "BASE = \"https://foundico.com/api/v1\"\n",
    "SESSION = requests.Session()\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request*\")  # silenciar warning SSL (verify=False)\n",
    "\n",
    "# ============ HELPERS ============\n",
    "def sign_headers(payload: str) -> dict:\n",
    "    signature = base64.b64encode(\n",
    "        hmac.new(FOUNDI_PRIVATE_KEY.encode(\"utf-8\"), payload.encode(\"utf-8\"), hashlib.sha256).digest()\n",
    "    ).decode(\"ascii\")\n",
    "    return {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-Foundico-Public-Key\": FOUNDI_PUBLIC_KEY,\n",
    "        \"X-Foundico-Access-Key\": signature,\n",
    "        \"User-Agent\": \"TFM-ICO-Fetcher/1.1\"\n",
    "    }\n",
    "\n",
    "def parse_money(x):\n",
    "    \"\"\"Convierte '42,000,000', '42M', '42000000', 'null' -> float (USD as default si unit=USD).\"\"\"\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower().replace(\",\", \"\")\n",
    "    if s in {\"\", \"null\", \"none\"}:\n",
    "        return np.nan\n",
    "    try:\n",
    "        mult = 1\n",
    "        if s.endswith(\"b\"): mult = 1_000_000_000; s = re.sub(r\"b$\", \"\", s)\n",
    "        elif s.endswith(\"m\"): mult = 1_000_000; s = re.sub(r\"m$\", \"\", s)\n",
    "        elif s.endswith(\"k\"): mult = 1_000; s = re.sub(r\"k$\", \"\", s)\n",
    "        num = re.findall(r\"[\\d.]+\", s)\n",
    "        return float(num[0]) * mult if num else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def parse_dt(s):\n",
    "    \"\"\"FoundICO devuelve 'dd.mm.yyyy HH:MM:SS'. Parse robusto, devuelve iso (UTC naive) o NaT.\"\"\"\n",
    "    if not s: return pd.NaT\n",
    "    s = str(s).strip()\n",
    "    # formato t√≠pico '15.06.2017 16:59:00'\n",
    "    for fmt in (\"%d.%m.%Y %H:%M:%S\", \"%d.%m.%Y\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            return pd.to_datetime(s, format=fmt, errors=\"raise\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback gen√©rico\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def boolify(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"s√≠\",\"passed\",\"available\",\"ok\"}: return 1\n",
    "    if s in {\"0\",\"false\",\"no\",\"n\",\"not passed\",\"unavailable\",\"none\",\"\"}: return 0\n",
    "    return np.nan\n",
    "\n",
    "def list_to_csv(a):\n",
    "    if isinstance(a, list):\n",
    "        return \",\".join([str(x) for x in a])\n",
    "    return a\n",
    "\n",
    "def fetch_foundico_detail(ico_id: str) -> Optional[dict]:\n",
    "    \"\"\"GET detalle por id (v√≠a POST con body json y firma). Maneja reintentos y verify=False.\"\"\"\n",
    "    body = json.dumps({\"id\": str(ico_id)}, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "    headers = sign_headers(body)\n",
    "    for attempt in range(RETRIES + 1):\n",
    "        try:\n",
    "            r = SESSION.post(f\"{BASE}/ico/\", headers=headers, data=body, timeout=TIMEOUT, verify=False)\n",
    "            if r.status_code != 200:\n",
    "                print(f\"[FoundICO] HTTP {r.status_code} id={ico_id} resp={r.text[:160]!r}\")\n",
    "                time.sleep(1.2)\n",
    "                continue\n",
    "            data = r.json()\n",
    "            if data and data.get(\"data\"):\n",
    "                return data[\"data\"]\n",
    "            else:\n",
    "                print(f\"[FoundICO] id={ico_id} sin 'data' v√°lido. Resp={r.text[:160]!r}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[FoundICO] id={ico_id} error: {e}\")\n",
    "        time.sleep(1.0 + 0.5*attempt)  # backoff ligero\n",
    "    return None\n",
    "\n",
    "def flatten_detail(d: dict) -> dict:\n",
    "    \"\"\"Aplana el JSON de detalle en un dict plano con campos √∫tiles (preferir pre-ICO).\"\"\"\n",
    "    main  = d.get(\"main\")  or {}\n",
    "    links = d.get(\"links\") or {}\n",
    "    fin   = d.get(\"finance\") or {}\n",
    "    dates = d.get(\"dates\") or {}\n",
    "\n",
    "    social = (links.get(\"social\") or {}) if isinstance(links.get(\"social\"), dict) else {}\n",
    "\n",
    "    out = {\n",
    "        # Identidad\n",
    "        \"foundico_id\": d.get(\"id\"),\n",
    "        \"name\": main.get(\"name\"),\n",
    "        \"symbol\": fin.get(\"ticker\") or fin.get(\"symbol\"),\n",
    "\n",
    "        # Clasificaci√≥n / contexto (pre-ICO)\n",
    "        \"category\": main.get(\"category\"),\n",
    "        \"type\": main.get(\"type\"),               # \"ICO\", \"IEO\", etc. (pre-ICO)\n",
    "        \"platform\": main.get(\"platform\"),       # e.g. Ethereum (pre-ICO)\n",
    "        \"location\": main.get(\"location\"),       # pa√≠s (pre-ICO)\n",
    "\n",
    "        # Documentaci√≥n / presencia (pre-ICO)\n",
    "        \"website\": links.get(\"website\"),\n",
    "        \"whitepaper\": links.get(\"whitepaper\"),\n",
    "        \"github\": social.get(\"github\"),\n",
    "        \"twitter\": social.get(\"twitter\"),\n",
    "        \"facebook\": social.get(\"facebook\"),\n",
    "        \"reddit\": social.get(\"reddit\"),\n",
    "\n",
    "        # Compliance & reglas (pre-ICO)\n",
    "        \"kyc\": boolify(main.get(\"kyc\") or main.get(\"kyc_passed\")),\n",
    "        \"whitelist\": boolify(main.get(\"whitelist\")),\n",
    "        \"mvp\": boolify(main.get(\"mvp\")),\n",
    "\n",
    "        # Tokenomics (pre-ICO, salvo 'raised')\n",
    "        \"tokens_for_sale\": parse_money(fin.get(\"tokens_for_sale\")),\n",
    "        \"token_price\": parse_money(fin.get(\"token_price\")),\n",
    "        \"token_price_unit\": fin.get(\"token_price_unit\"),\n",
    "        \"min_purchase\": parse_money(fin.get(\"min_purchase\")),\n",
    "        \"max_purchase\": parse_money(fin.get(\"max_purchase\")),\n",
    "        \"purchase_unit\": fin.get(\"purchase_unit\"),\n",
    "        \"token_type\": fin.get(\"token_type\"),\n",
    "        \"soft_cap\": parse_money(fin.get(\"soft_cap\")),\n",
    "        \"hard_cap\": parse_money(fin.get(\"hard_cap\")),\n",
    "        \"caps_unit\": fin.get(\"caps_unit\"),\n",
    "        \"accepting\": list_to_csv(fin.get(\"accepting\")),\n",
    "\n",
    "        # Fechas (ojo con leakage: end puede ser real/efectiva)\n",
    "        \"start_datetime\": parse_dt(dates.get(\"start_datetime\")),\n",
    "        \"end_datetime\": parse_dt(dates.get(\"end_datetime\")),\n",
    "\n",
    "        # Scores y post-ICO potencial\n",
    "        \"ico_score\": (main.get(\"ico_score\") if main.get(\"ico_score\") not in {\"\", None} else np.nan),\n",
    "        \"raised\": parse_money(fin.get(\"raised\")),  # üö® POST-ICO ‚Üí leakage si lo us√°s para t‚ÇÄ\n",
    "        \"markets\": fin.get(\"markets\"),             # üö® normalmente post-ICO (listing)\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# ============ CARGA CATALOGO ============\n",
    "ids = []\n",
    "names = []\n",
    "symbols = []\n",
    "pages, total_lines = 0, 0\n",
    "with open(CATALOG_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        total_lines += 1\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "        except Exception:\n",
    "            continue\n",
    "        arr = (obj or {}).get(\"data\") or []\n",
    "        for it in arr:\n",
    "            # Estructura esperada en el dump: {\"id\": \"...\", \"main\":{...}, \"links\":{...}, \"finance\":{...}}\n",
    "            ids.append(it.get(\"id\"))\n",
    "            nm  = ((it.get(\"main\") or {}).get(\"name\"))\n",
    "            sym = ((it.get(\"finance\") or {}).get(\"ticker\"))\n",
    "            names.append(nm)\n",
    "            symbols.append(sym)\n",
    "        pages += 1\n",
    "\n",
    "cat = pd.DataFrame({\"foundico_id\": ids, \"name_hint\": names, \"symbol_hint\": symbols}).dropna(subset=[\"foundico_id\"]).drop_duplicates(\"foundico_id\")\n",
    "print(f\"üì¶ Cat√°logo FoundICO le√≠do: {len(cat):,} ids √∫nicos en {pages} p√°ginas (l√≠neas {total_lines}).\")\n",
    "\n",
    "# ============ LOOP DETALLE ============\n",
    "rows = []\n",
    "start_ts = time.time()\n",
    "\n",
    "for i, row in cat.iterrows():\n",
    "    ico_id = row[\"foundico_id\"]\n",
    "    detail = fetch_foundico_detail(ico_id)\n",
    "    if detail:\n",
    "        flat = flatten_detail(detail)\n",
    "        rows.append(flat)\n",
    "    else:\n",
    "        rows.append({\"foundico_id\": ico_id, \"error\": \"no_detail\"})\n",
    "\n",
    "    # checkpoint peri√≥dico\n",
    "    if len(rows) % CHECKPOINT_EVERY == 0:\n",
    "        tmp = pd.DataFrame(rows)\n",
    "        tmp.to_csv(OUT_CSV, index=False)\n",
    "        print(f\"üíæ Checkpoint: {len(rows)} filas -> {OUT_CSV}\")\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "elapsed = time.time() - start_ts\n",
    "print(f\"\\n‚úÖ Terminado. Guardado {len(df_out)} filas en {OUT_CSV} en {elapsed:.1f}s.\")\n",
    "\n",
    "# Vista r√°pida\n",
    "display(df_out.head(5))\n",
    "print(\"\\nNulos por columna (%):\")\n",
    "display((df_out.isna().mean()*100).round(2).sort_values(ascending=False).to_frame(\"missing_%\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a6fd21e-bc9a-41f6-8213-8130e4114862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3646, 20)\n",
      "‚úÖ Cat√°logo FoundICO normalizado ‚Üí foundico/foundico_catalog.csv\n"
     ]
    }
   ],
   "source": [
    "# %% Normalizar el cat√°logo a CSV (campos √∫tiles ex-ante)\n",
    "\n",
    "rows: List[Dict[str,Any]] = []\n",
    "with open(FOUN_RAW_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        for item in obj.get(\"data\", []):\n",
    "            main    = item.get(\"main\") or {}\n",
    "            links   = item.get(\"links\") or {}\n",
    "            finance = item.get(\"finance\") or {}\n",
    "            rows.append({\n",
    "                \"foundico_id\": item.get(\"id\"),\n",
    "                \"name\": main.get(\"name\"),\n",
    "                \"ticker\": finance.get(\"ticker\"),\n",
    "                \"status\": main.get(\"status\"),\n",
    "                \"category\": main.get(\"category\"),\n",
    "                \"location\": main.get(\"location\"),\n",
    "                \"kyc\": main.get(\"kyc\"),\n",
    "                \"whitelist\": main.get(\"whitelist\"),\n",
    "                \"ico_score\": main.get(\"ico_score\"),\n",
    "                \"website\": links.get(\"website\"),\n",
    "                \"whitepaper\": links.get(\"whitepaper\"),\n",
    "                \"github\": (links.get(\"github\") or None),\n",
    "                \"telegram\": links.get(\"telegram\"),\n",
    "                \"twitter\": links.get(\"twitter\"),\n",
    "                \"reddit\": links.get(\"reddit\"),\n",
    "                \"token_type\": finance.get(\"token_type\"),\n",
    "                \"tokens_for_sale\": finance.get(\"tokens_for_sale\"),\n",
    "                \"token_price\": finance.get(\"token_price\"),\n",
    "                \"soft_cap\": finance.get(\"soft_cap\"),\n",
    "                \"hard_cap\": finance.get(\"hard_cap\"),\n",
    "            })\n",
    "\n",
    "df_foun = pd.DataFrame(rows)\n",
    "print(df_foun.shape)\n",
    "df_foun.head(3)\n",
    "\n",
    "# Normalizaciones r√°pidas\n",
    "def parse_money_like(x):\n",
    "    if x in [None, \"\", \"None\"]: return np.nan\n",
    "    s = str(x).lower().replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
    "    mult = 1.0\n",
    "    if s.endswith(\"b\"): mult = 1e9; s = s[:-1]\n",
    "    elif s.endswith(\"m\"): mult = 1e6; s = s[:-1]\n",
    "    elif s.endswith(\"k\"): mult = 1e3; s = s[:-1]\n",
    "    nums = re.findall(r\"[\\d.]+\", s)\n",
    "    return float(nums[0]) * mult if nums else np.nan\n",
    "\n",
    "df_foun[\"name_std\"]   = df_foun[\"name\"].map(normalize_text)\n",
    "df_foun[\"symbol_std\"] = df_foun[\"ticker\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "df_foun[\"soft_cap_usd\"] = df_foun[\"soft_cap\"].map(parse_money_like)\n",
    "df_foun[\"hard_cap_usd\"] = df_foun[\"hard_cap\"].map(parse_money_like)\n",
    "df_foun[\"token_price_usd\"] = pd.to_numeric(df_foun[\"token_price\"], errors=\"coerce\")\n",
    "df_foun[\"kyc_flag\"] = df_foun[\"kyc\"].map(lambda x: 1 if str(x).lower() in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"s√≠\"} else (0 if str(x).lower() in {\"0\",\"false\",\"no\",\"n\"} else np.nan))\n",
    "df_foun[\"whitelist_flag\"] = df_foun[\"whitelist\"].map(lambda x: 1 if str(x).lower() in {\"1\",\"true\",\"yes\",\"y\",\"si\",\"s√≠\"} else (0 if str(x).lower() in {\"0\",\"false\",\"no\",\"n\"} else np.nan))\n",
    "df_foun[\"whitepaper_available\"] = df_foun[\"whitepaper\"].notna().astype(\"Int64\")\n",
    "df_foun[\"has_github\"] = df_foun[\"github\"].notna().astype(\"Int64\")\n",
    "\n",
    "cols_out = [\n",
    "    \"foundico_id\",\"name\",\"name_std\",\"ticker\",\"symbol_std\",\"status\",\"category\",\"location\",\n",
    "    \"kyc_flag\",\"whitelist_flag\",\"ico_score\",\"website\",\"whitepaper\",\"github\",\"telegram\",\"twitter\",\"reddit\",\n",
    "    \"token_type\",\"tokens_for_sale\",\"token_price_usd\",\"soft_cap_usd\",\"hard_cap_usd\",\"whitepaper_available\",\"has_github\"\n",
    "]\n",
    "df_foun[cols_out].to_csv(FOUN_CSV, index=False)\n",
    "print(f\"‚úÖ Cat√°logo FoundICO normalizado ‚Üí {FOUN_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82dc955d-e333-4b10-b02b-0b22c96e69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ FoundICO dataset: 3645 filas √ó 32 columnas\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>markets</th>\n",
       "      <td>87.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_type</th>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raised</th>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_purchase</th>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>62.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_purchase</th>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_cap</th>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_for_sale</th>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_price</th>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_cap</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ico_score</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accepting</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitepaper</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_datetime</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_datetime</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 missing_%\n",
       "markets               87.7\n",
       "token_type            75.7\n",
       "raised                71.4\n",
       "github                67.8\n",
       "max_purchase          66.3\n",
       "reddit                62.6\n",
       "min_purchase          48.1\n",
       "soft_cap              32.8\n",
       "facebook              31.9\n",
       "twitter               10.8\n",
       "tokens_for_sale        7.8\n",
       "token_price            6.4\n",
       "hard_cap               1.5\n",
       "ico_score              0.8\n",
       "accepting              0.4\n",
       "type                   0.3\n",
       "whitepaper             0.2\n",
       "symbol                 0.0\n",
       "end_datetime           0.0\n",
       "start_datetime         0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foundico_id</th>\n",
       "      <th>name</th>\n",
       "      <th>symbol</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>platform</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>whitepaper</th>\n",
       "      <th>github</th>\n",
       "      <th>...</th>\n",
       "      <th>token_type</th>\n",
       "      <th>soft_cap</th>\n",
       "      <th>hard_cap</th>\n",
       "      <th>caps_unit</th>\n",
       "      <th>accepting</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>ico_score</th>\n",
       "      <th>raised</th>\n",
       "      <th>markets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2830</td>\n",
       "      <td>IronBlock</td>\n",
       "      <td>ERC</td>\n",
       "      <td>Infrastructure</td>\n",
       "      <td>Pre-ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Russia</td>\n",
       "      <td>https://ironblock.io</td>\n",
       "      <td>https://ironblock.io/media/IronBlock_ru_WP_2.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2017-12-12 00:00:00</td>\n",
       "      <td>2018-01-14 00:00:00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>34235</td>\n",
       "      <td>Intelly</td>\n",
       "      <td>INTL</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>ICO</td>\n",
       "      <td>Other</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https://intelly.tech</td>\n",
       "      <td>https://intelly.tech/wp-content/uploads/2021/1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>BUSD,BNB</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-21 23:59:00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>36280</td>\n",
       "      <td>CACTUS</td>\n",
       "      <td>CACTUS</td>\n",
       "      <td>Finance</td>\n",
       "      <td>ICO</td>\n",
       "      <td>Binance Chain</td>\n",
       "      <td>Canada</td>\n",
       "      <td>https://cactustoken.com/</td>\n",
       "      <td>https://cactustoken.com/cactuspaper</td>\n",
       "      <td>https://github.com/CactusToken</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>BNB</td>\n",
       "      <td>2023-02-18 16:00:00</td>\n",
       "      <td>2023-02-20 16:00:00</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>979</td>\n",
       "      <td>Crowd Coin</td>\n",
       "      <td>CRC</td>\n",
       "      <td>Mining</td>\n",
       "      <td>ICO</td>\n",
       "      <td>Other</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>http://icobazaar.com/crowdcoin</td>\n",
       "      <td>https://icobazaar.com/static/3cce6455fb6c08bc5...</td>\n",
       "      <td>https://github.com/crowdcoin-team</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>BTC,BCC,ETH,XRP,SBD,WAVES,DASH</td>\n",
       "      <td>2017-09-15 05:00:00</td>\n",
       "      <td>2017-12-15 05:00:00</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['http://www.wavesgo.com/tokens/5XWiXK6RbwXsTn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>23638</td>\n",
       "      <td>OneToTwo Pro</td>\n",
       "      <td>OTTP</td>\n",
       "      <td>Gambling</td>\n",
       "      <td>Pre-ICO</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Russia</td>\n",
       "      <td>https://1to2.pro/index.php/en/</td>\n",
       "      <td>https://1to2.pro/docs/ott-whitepaper-en.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91600.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2018-10-20 00:00:00</td>\n",
       "      <td>2019-01-20 00:00:00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      foundico_id          name  symbol        category     type  \\\n",
       "415          2830     IronBlock     ERC  Infrastructure  Pre-ICO   \n",
       "2927        34235       Intelly    INTL     Real Estate      ICO   \n",
       "3194        36280        CACTUS  CACTUS         Finance      ICO   \n",
       "298           979    Crowd Coin     CRC          Mining      ICO   \n",
       "1874        23638  OneToTwo Pro    OTTP        Gambling  Pre-ICO   \n",
       "\n",
       "           platform                  location                         website  \\\n",
       "415        Ethereum                    Russia            https://ironblock.io   \n",
       "2927          Other            United Kingdom            https://intelly.tech   \n",
       "3194  Binance Chain                    Canada        https://cactustoken.com/   \n",
       "298           Other  United States of America  http://icobazaar.com/crowdcoin   \n",
       "1874       Ethereum                    Russia  https://1to2.pro/index.php/en/   \n",
       "\n",
       "                                             whitepaper  \\\n",
       "415   https://ironblock.io/media/IronBlock_ru_WP_2.0...   \n",
       "2927  https://intelly.tech/wp-content/uploads/2021/1...   \n",
       "3194                https://cactustoken.com/cactuspaper   \n",
       "298   https://icobazaar.com/static/3cce6455fb6c08bc5...   \n",
       "1874        https://1to2.pro/docs/ott-whitepaper-en.pdf   \n",
       "\n",
       "                                 github  ... token_type    soft_cap  \\\n",
       "415                                 NaN  ...        NaN         NaN   \n",
       "2927                                NaN  ...        NaN  30000000.0   \n",
       "3194     https://github.com/CactusToken  ...        NaN     15000.0   \n",
       "298   https://github.com/crowdcoin-team  ...        NaN         NaN   \n",
       "1874                                NaN  ...        NaN     91600.0   \n",
       "\n",
       "         hard_cap  caps_unit                       accepting  \\\n",
       "415      500000.0        USD                             ETH   \n",
       "2927  200000000.0        USD                        BUSD,BNB   \n",
       "3194     300000.0        USD                             BNB   \n",
       "298     3750000.0        USD  BTC,BCC,ETH,XRP,SBD,WAVES,DASH   \n",
       "1874     160000.0        USD                             ETH   \n",
       "\n",
       "           start_datetime         end_datetime  ico_score raised  \\\n",
       "415   2017-12-12 00:00:00  2018-01-14 00:00:00        6.8    NaN   \n",
       "2927  2022-01-01 00:00:00  2022-01-21 23:59:00        7.7    NaN   \n",
       "3194  2023-02-18 16:00:00  2023-02-20 16:00:00        4.8    NaN   \n",
       "298   2017-09-15 05:00:00  2017-12-15 05:00:00        5.2    NaN   \n",
       "1874  2018-10-20 00:00:00  2019-01-20 00:00:00        6.8    NaN   \n",
       "\n",
       "                                                markets  \n",
       "415                                                 NaN  \n",
       "2927                                                NaN  \n",
       "3194                                                NaN  \n",
       "298   ['http://www.wavesgo.com/tokens/5XWiXK6RbwXsTn...  \n",
       "1874                                                NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö® Posibles columnas POST-ICO (revisar antes de entrenar):\n",
      "['end_datetime', 'ico_score', 'raised', 'markets']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV de FoundICO\n",
    "foundico_path = \"../foundico/foundico_details.csv\"\n",
    "foundico = pd.read_csv(foundico_path)\n",
    "\n",
    "print(f\"üì¶ FoundICO dataset: {foundico.shape[0]} filas √ó {foundico.shape[1]} columnas\\n\")\n",
    "\n",
    "# Ver columnas y proporci√≥n de nulos\n",
    "nulls = (foundico.isna().mean() * 100).round(1).sort_values(ascending=False)\n",
    "display(nulls.to_frame(\"missing_%\").head(20))\n",
    "\n",
    "# Ejemplos representativos\n",
    "display(foundico.sample(5, random_state=42))\n",
    "\n",
    "# Campos sospechosos de leakage (solo chequeo)\n",
    "leakage_cols = [c for c in foundico.columns if any(x in c.lower() for x in [\"raised\", \"markets\", \"end\", \"score\"])]\n",
    "print(\"\\nüö® Posibles columnas POST-ICO (revisar antes de entrenar):\")\n",
    "print(leakage_cols or \"‚Äî ninguna detectada ‚Äî\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96661da5-7722-479f-8eb5-0f33f84439ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Coincidencias por s√≠mbolo: 1238 / 2690 (46.0%)\n",
      "üîπ Coincidencias por nombre : 625 / 2690 (23.2%)\n",
      "‚úÖ Total tokens en com√∫n: 1125 / 2690 (41.8%)\n",
      "üìÅ Archivo guardado: foundico/matched_foundico_final.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol_std</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>YDY</td>\n",
       "      <td>ydentity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>MBE</td>\n",
       "      <td>mobee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>VIRT</td>\n",
       "      <td>virtuseexchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>SAVE</td>\n",
       "      <td>savetoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>aurora</td>\n",
       "      <td>aurora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Bitpaction</td>\n",
       "      <td>bitpaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>BBX</td>\n",
       "      <td>blockbitsio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>GWF</td>\n",
       "      <td>greenworldfarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>HDC</td>\n",
       "      <td>hdcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>TOS</td>\n",
       "      <td>tos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      symbol_std         name_std\n",
       "2653         YDY         ydentity\n",
       "1625         MBE            mobee\n",
       "2532        VIRT  virtuseexchange\n",
       "2080        SAVE        savetoken\n",
       "177       aurora           aurora\n",
       "308   Bitpaction       bitpaction\n",
       "344          BBX      blockbitsio\n",
       "1150         GWF   greenworldfarm\n",
       "1188         HDC           hdcoin\n",
       "2382         TOS              tos"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ruta del dataset final (el que une CoinGecko + CoinPaprika + CMC)\n",
    "final_path = \"../final/ico_exante_enriched_v1.csv\"\n",
    "final = pd.read_csv(final_path)\n",
    "\n",
    "# Columnas candidatas para matching\n",
    "# En FoundICO usamos 'symbol' y 'name'; en tu dataset final ten√©s 'symbol_std' y 'name_std'\n",
    "foundico['symbol_norm'] = foundico['symbol'].astype(str).str.strip().str.upper()\n",
    "foundico['name_norm'] = foundico['name'].astype(str).str.strip().str.lower()\n",
    "final['symbol_norm'] = final['symbol_std'].astype(str).str.strip().str.upper()\n",
    "final['name_norm'] = final['name_std'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Matching exacto por symbol\n",
    "match_symbol = final[final['symbol_norm'].isin(foundico['symbol_norm'])]\n",
    "match_name = final[final['name_norm'].isin(foundico['name_norm'])]\n",
    "\n",
    "print(f\"üîπ Coincidencias por s√≠mbolo: {len(match_symbol)} / {len(final)} ({len(match_symbol)/len(final)*100:.1f}%)\")\n",
    "print(f\"üîπ Coincidencias por nombre : {len(match_name)} / {len(final)} ({len(match_name)/len(final)*100:.1f}%)\")\n",
    "\n",
    "# Unir ambos m√©todos\n",
    "matched = pd.concat([match_symbol, match_name]).drop_duplicates(subset=['symbol_std'])\n",
    "print(f\"‚úÖ Total tokens en com√∫n: {len(matched)} / {len(final)} ({len(matched)/len(final)*100:.1f}%)\")\n",
    "\n",
    "# Guardar coincidencias para inspecci√≥n manual\n",
    "matched.to_csv(\"foundico/matched_foundico_final.csv\", index=False)\n",
    "print(\"üìÅ Archivo guardado: foundico/matched_foundico_final.csv\")\n",
    "\n",
    "# Ver algunos ejemplos de coincidencias\n",
    "cols_to_show = ['symbol_std', 'name_std']\n",
    "display(matched[cols_to_show].sample(10, random_state=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed8a5c56-a2bd-4240-8f50-b70f1346bf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview uni√≥n con FoundICO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_std</th>\n",
       "      <th>symbol_std</th>\n",
       "      <th>ico_start_date</th>\n",
       "      <th>ico_end_date</th>\n",
       "      <th>ico_length_actual_days</th>\n",
       "      <th>ico_length_planned_days</th>\n",
       "      <th>goal_usd</th>\n",
       "      <th>hard_cap_usd</th>\n",
       "      <th>amount_raised_usd</th>\n",
       "      <th>ico_successful</th>\n",
       "      <th>...</th>\n",
       "      <th>f_has_github</th>\n",
       "      <th>f_website</th>\n",
       "      <th>f_whitepaper</th>\n",
       "      <th>f_github</th>\n",
       "      <th>f_telegram</th>\n",
       "      <th>f_twitter</th>\n",
       "      <th>f_reddit</th>\n",
       "      <th>f_location</th>\n",
       "      <th>f_category</th>\n",
       "      <th>f_ico_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0chain</td>\n",
       "      <td>ZCHN</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0penproductdb</td>\n",
       "      <td>OPDB</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2.750000e+10</td>\n",
       "      <td>2499299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xcert</td>\n",
       "      <td>ZXC</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2409600.0</td>\n",
       "      <td>9.230800e+06</td>\n",
       "      <td>10313710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name_std symbol_std ico_start_date ico_end_date  \\\n",
       "0         0chain       ZCHN     2018-02-17   2018-02-17   \n",
       "1  0penproductdb       OPDB     2018-04-16   2018-06-11   \n",
       "2         0xcert        ZXC     2018-07-04   2018-07-18   \n",
       "\n",
       "   ico_length_actual_days  ico_length_planned_days    goal_usd  hard_cap_usd  \\\n",
       "0                     NaN                      NaN  40000000.0           NaN   \n",
       "1                     NaN                      NaN   1000000.0  2.750000e+10   \n",
       "2                     NaN                      NaN   2409600.0  9.230800e+06   \n",
       "\n",
       "   amount_raised_usd  ico_successful  ...  f_has_github  f_website  \\\n",
       "0         39000000.0             0.0  ...           NaN        NaN   \n",
       "1          2499299.0             1.0  ...           NaN        NaN   \n",
       "2         10313710.0             1.0  ...           0.0        NaN   \n",
       "\n",
       "   f_whitepaper  f_github  f_telegram  f_twitter  f_reddit f_location  \\\n",
       "0           NaN       NaN         NaN        NaN       NaN        NaN   \n",
       "1           NaN       NaN         NaN        NaN       NaN        NaN   \n",
       "2           NaN       NaN         NaN        NaN       NaN        NaN   \n",
       "\n",
       "  f_category  f_ico_score  \n",
       "0        NaN          NaN  \n",
       "1        NaN          NaN  \n",
       "2        NaN          8.9  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Resolver offline: join por symbol_std y fuzzy por name_std\n",
    "\n",
    "df_base = pd.read_csv(DATASET_IN)\n",
    "df_foun = pd.read_csv(FOUN_CSV)\n",
    "\n",
    "# Asegurar claves\n",
    "if \"symbol_std\" not in df_base.columns:\n",
    "    df_base[\"symbol_std\"] = \"\"\n",
    "if \"name_std\" not in df_base.columns:\n",
    "    df_base[\"name_std\"] = df_base.get(\"name_std\", \"\")\n",
    "\n",
    "# 1) Join directo por symbol_std (upper para ambos)\n",
    "df_base[\"symbol_std\"] = df_base[\"symbol_std\"].astype(str).str.upper().str.strip()\n",
    "df_foun[\"symbol_std\"] = df_foun[\"symbol_std\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "j1 = df_base.merge(\n",
    "    df_foun.add_prefix(\"f_\"),\n",
    "    left_on=\"symbol_std\",\n",
    "    right_on=\"f_symbol_std\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\",\"\")\n",
    ")\n",
    "\n",
    "# 2) Para los que NO matchearon por s√≠mbolo, intentamos fuzzy por nombre\n",
    "mask_no_symbol = j1[\"f_foundico_id\"].isna()\n",
    "base_need = j1.loc[mask_no_symbol, [\"name_std\"]].copy()\n",
    "f_name_map = df_foun[[\"name_std\",\"foundico_id\"]].dropna().drop_duplicates()\n",
    "\n",
    "# √≠ndice por nombre exacto (r√°pido) + luego fuzzy si no hay exact\n",
    "name_to_id = dict(zip(f_name_map[\"name_std\"], f_name_map[\"foundico_id\"]))\n",
    "\n",
    "def fuzzy_match_name(nm: str, threshold=0.90):\n",
    "    nm_n = normalize_text(nm)\n",
    "    if not nm_n: return None\n",
    "    # exacto\n",
    "    if nm_n in name_to_id:\n",
    "        return name_to_id[nm_n]\n",
    "    # fuzzy: escanear candidatos cercanos (heur√≠stica simple por prefijo)\n",
    "    # para acelerar, filtramos por primer car√°cter\n",
    "    cand = df_foun[df_foun[\"name_std\"].str.startswith(nm_n[:1])]\n",
    "    if cand.empty:\n",
    "        cand = df_foun\n",
    "    best_id, best_sc = None, 0.0\n",
    "    for _, r in cand.iterrows():\n",
    "        sc = sim(nm_n, r[\"name_std\"])\n",
    "        if sc > best_sc:\n",
    "            best_sc, best_id = sc, r[\"foundico_id\"]\n",
    "        if best_sc >= threshold:\n",
    "            break\n",
    "    return best_id if best_sc >= threshold else None\n",
    "\n",
    "ids = []\n",
    "for nm in base_need[\"name_std\"]:\n",
    "    ids.append(fuzzy_match_name(nm, threshold=0.90))\n",
    "base_need[\"foundico_id\"] = ids\n",
    "\n",
    "# Merge con lo encontrado por nombre\n",
    "j2 = j1.merge(\n",
    "    df_foun.add_prefix(\"f2_\"),\n",
    "    left_on=base_need.index.map(lambda i: base_need.loc[i, \"foundico_id\"]) ,  # valores alineados\n",
    "    right_on=\"f2_foundico_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 3) Coalesce: preferir match por s√≠mbolo (f_*) y si est√° vac√≠o, usar por nombre (f2_*)\n",
    "def coalesce_cols(df, base_col, a, b):\n",
    "    df[base_col] = df[a].where(df[a].notna(), df[b])\n",
    "    return df\n",
    "\n",
    "# Campos a traer de FoundICO\n",
    "fields = [\n",
    "    (\"foundico_id\",      \"f_foundico_id\",      \"f2_foundico_id\"),\n",
    "    (\"f_token_symbol\",   \"f_symbol_std\",       \"f2_symbol_std\"),\n",
    "    (\"f_token_name\",     \"f_name\",             \"f2_name\"),\n",
    "    (\"f_token_type\",     \"f_token_type\",       \"f2_token_type\"),\n",
    "    (\"f_tokens_for_sale\",\"f_tokens_for_sale\",  \"f2_tokens_for_sale\"),\n",
    "    (\"f_token_price_usd\",\"f_token_price_usd\",  \"f2_token_price_usd\"),\n",
    "    (\"f_soft_cap_usd\",   \"f_soft_cap_usd\",     \"f2_soft_cap_usd\"),\n",
    "    (\"f_hard_cap_usd\",   \"f_hard_cap_usd\",     \"f2_hard_cap_usd\"),\n",
    "    (\"f_kyc_flag\",       \"f_kyc_flag\",         \"f2_kyc_flag\"),\n",
    "    (\"f_whitelist_flag\", \"f_whitelist_flag\",   \"f2_whitelist_flag\"),\n",
    "    (\"f_whitepaper_av\",  \"f_whitepaper_available\",\"f2_whitepaper_available\"),\n",
    "    (\"f_has_github\",     \"f_has_github\",       \"f2_has_github\"),\n",
    "    (\"f_website\",        \"f_website\",          \"f2_website\"),\n",
    "    (\"f_whitepaper\",     \"f_whitepaper\",       \"f2_whitepaper\"),\n",
    "    (\"f_github\",         \"f_github\",           \"f2_github\"),\n",
    "    (\"f_telegram\",       \"f_telegram\",         \"f2_telegram\"),\n",
    "    (\"f_twitter\",        \"f_twitter\",          \"f2_twitter\"),\n",
    "    (\"f_reddit\",         \"f_reddit\",           \"f2_reddit\"),\n",
    "    (\"f_location\",       \"f_location\",         \"f2_location\"),\n",
    "    (\"f_category\",       \"f_category\",         \"f2_category\"),\n",
    "    (\"f_ico_score\",      \"f_ico_score\",        \"f2_ico_score\"),\n",
    "]\n",
    "\n",
    "for base_col, a, b in fields:\n",
    "    j2 = coalesce_cols(j2, base_col, a, b)\n",
    "\n",
    "# Limpieza de columnas auxiliares f_ y f2_\n",
    "aux_cols = [c for c in j2.columns if c.startswith(\"f_\") or c.startswith(\"f2_\")]\n",
    "keep_cols = [c for c in j2.columns if c not in aux_cols] + [f[0] for f in fields]\n",
    "j2 = j2[keep_cols]\n",
    "\n",
    "print(\"Preview uni√≥n con FoundICO:\")\n",
    "j2.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c43c494-4d1a-46db-b043-807fdc66b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Guardado enriquecido con FoundICO (offline): ../final/ico_union_enriched_foundico.csv\n",
      "Cobertura no-nula (%) tras FoundICO: {'token_type': 91.94, 'tokens_for_sale': 78.31, 'token_price_usd': 87.63, 'soft_cap_usd': 0.0, 'hard_cap_usd': 77.53, 'kyc': 88.34, 'whitelist': 81.84, 'whitepaper_available': 100.0, 'has_github': 40.6, 'jurisdiction': 92.57, 'rating': 31.13}\n",
      "Match con foundico_id: foundico_id    838\n",
      "foundico_id    838\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %% Completar vac√≠os en el dataset con lo de FoundICO y guardar\n",
    "\n",
    "df = j2.copy()\n",
    "\n",
    "# S√≥lo rellenar donde faltaba (no pisamos lo ya existente)\n",
    "def fill_if_na(dst_col, src_col):\n",
    "    if dst_col not in df.columns:\n",
    "        df[dst_col] = np.nan\n",
    "    df[dst_col] = df[dst_col].where(df[dst_col].notna(), df[src_col])\n",
    "\n",
    "mapping_fill = {\n",
    "    \"token_type\":         \"f_token_type\",\n",
    "    \"tokens_for_sale\":    \"f_tokens_for_sale\",\n",
    "    \"token_price_usd\":    \"f_token_price_usd\",\n",
    "    \"soft_cap_usd\":       \"f_soft_cap_usd\",\n",
    "    \"hard_cap_usd\":       \"f_hard_cap_usd\",\n",
    "    \"kyc\":                \"f_kyc_flag\",\n",
    "    \"whitelist\":          \"f_whitelist_flag\",\n",
    "    \"whitepaper_available\":\"f_whitepaper_av\",\n",
    "    \"has_github\":         \"f_has_github\",\n",
    "    \"jurisdiction\":       \"f_location\",\n",
    "    \"accepts\":            None,   # FoundICO no trae listado fino de divisas aceptadas\n",
    "    \"rating\":             \"f_ico_score\",\n",
    "}\n",
    "\n",
    "for dst, src in mapping_fill.items():\n",
    "    if src:\n",
    "        fill_if_na(dst, src)\n",
    "\n",
    "# Links informativos (no entran al modelo, pero √∫tiles para auditor√≠a)\n",
    "for link_col, src in [(\"homepage\",\"f_website\"), (\"whitepaper_url\",\"f_whitepaper\"),\n",
    "                      (\"github_url\",\"f_github\"), (\"telegram_url\",\"f_telegram\"),\n",
    "                      (\"twitter_url\",\"f_twitter\"), (\"reddit_url\",\"f_reddit\")]:\n",
    "    if link_col not in df.columns:\n",
    "        df[link_col] = np.nan\n",
    "    df[link_col] = df[link_col].where(df[link_col].notna(), df[src])\n",
    "\n",
    "df.to_csv(DATASET_OUT, index=False)\n",
    "print(f\"‚úÖ Guardado enriquecido con FoundICO (offline): {DATASET_OUT}\")\n",
    "\n",
    "# Resumen de cobertura ganada\n",
    "cols_check = [\"token_type\",\"tokens_for_sale\",\"token_price_usd\",\"soft_cap_usd\",\"hard_cap_usd\",\"kyc\",\"whitelist\",\n",
    "              \"whitepaper_available\",\"has_github\",\"jurisdiction\",\"rating\"]\n",
    "cov = {c: round(100*df[c].notna().mean(),2) for c in cols_check if c in df.columns}\n",
    "print(\"Cobertura no-nula (%) tras FoundICO:\", cov)\n",
    "\n",
    "# Cu√°ntos tokens logramos asociar a un foundico_id\n",
    "print(\"Match con foundico_id:\", (df[\"foundico_id\"].notna().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f32e3-654e-4250-8f49-f0a6c138f309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
