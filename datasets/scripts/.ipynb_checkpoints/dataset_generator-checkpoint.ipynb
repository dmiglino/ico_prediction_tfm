{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258e08b0-793c-4b1b-8c1c-85a12ef5deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, time, requests, os, hmac, hashlib, base64, json\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime, timezone, UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e37e0-4fb6-4f12-9e7a-5cef4dc4d2de",
   "metadata": {},
   "source": [
    "#### Limpieza del dataset de Yan Maksi obtenido en Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc28537f-d07d-4ec8-82b4-f3495aadf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CONFIG Y HELPERS --------\n",
    "\n",
    "UTC = timezone.utc\n",
    "\n",
    "dataset_path = \"../raw/ico_yanmaksi_kaggle.csv\"\n",
    "output_path  = \"../processed/kaggle_yanmaksi_clean.csv\"\n",
    "\n",
    "USER_AGENT = \"Mozilla/5.0 (compatible; TFM-ICO/1.2)\"\n",
    "HEADERS    = {\"User-Agent\": USER_AGENT, \"Accept\": \"application/json\"}\n",
    "\n",
    "CMC_MAP_URL = \"https://pro-api.coinmarketcap.com/v1/cryptocurrency/map\"\n",
    "CMC_KEY = os.getenv(\"CMC_API_KEY\") or \"87f241ea-b56c-4a2f-9707-e25b4352ceb6\"\n",
    "SLEEP_CMC = 0.35\n",
    "\n",
    "def parse_money(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).lower().strip().replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        if \"billion\" in s or (\"b\" in s and re.search(r\"\\d\", s)): base = 1_000_000_000\n",
    "        elif \"million\" in s or (\"m\" in s and re.search(r\"\\d\", s)): base = 1_000_000\n",
    "        elif \"k\" in s and re.search(r\"\\d\", s): base = 1_000\n",
    "        else: base = 1\n",
    "        num = re.findall(r\"[\\d.]+\", s)\n",
    "        return float(num[0]) * base if num else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_end_date(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"^(ended|end|finished|finalized)\\s*:?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = s.replace(\"—\", \"-\").replace(\"–\", \"-\")\n",
    "    return s\n",
    "\n",
    "def normalize_text_series(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.lower()\n",
    "         .str.strip()\n",
    "         .str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "def _similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# --- Foundico API ---\n",
    "FD_BASE = \"https://foundico.com/api/v1\"\n",
    "FD_ICOS = f\"{FD_BASE}/icos/\"\n",
    "FOUNDICO_PUBLIC  = os.getenv(\"FOUNDICO_PUBLIC_KEY\") or \"\"\n",
    "FOUNDICO_PRIVATE = os.getenv(\"FOUNDICO_PRIVATE_KEY\") or \"\"\n",
    "def _sign_foundico(private_key: str, payload_json: str) -> str:\n",
    "    mac = hmac.new(private_key.encode(\"utf-8\"), payload_json.encode(\"utf-8\"), hashlib.sha256).digest()\n",
    "    return base64.b64encode(mac).decode(\"utf-8\")\n",
    "\n",
    "def _foundico_search_name(name: str, max_pages: int = 8, sleep: float = 0.4):\n",
    "    if not (FOUNDICO_PUBLIC and FOUNDICO_PRIVATE) or not name:\n",
    "        return None\n",
    "    name_std = re.sub(r\"[^a-z0-9]\", \"\", name.lower())\n",
    "    best = None; best_score = 0.0\n",
    "    for page in range(1, max_pages + 1):\n",
    "        payload = {\"status\": \"past\", \"page\": page}\n",
    "        body = json.dumps(payload, ensure_ascii=False)\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"User-Agent\": USER_AGENT,\n",
    "            \"X-Foundico-Public-Key\": FOUNDICO_PUBLIC,\n",
    "            \"X-Foundico-Access-Key\": _sign_foundico(FOUNDICO_PRIVATE, body),\n",
    "        }\n",
    "        try:\n",
    "            r = requests.post(FD_ICOS, headers=headers, data=body, timeout=25)\n",
    "            if r.status_code != 200:\n",
    "                break\n",
    "            data = r.json() or {}\n",
    "            items = data.get(\"data\") or []\n",
    "            if not items:\n",
    "                break\n",
    "            for item in items:\n",
    "                nm = (item.get(\"main\", {}).get(\"name\") or \"\").strip()\n",
    "                sc = (item.get(\"finance\", {}).get(\"ticker\") or \"\").strip()\n",
    "                score = _similar(name_std, re.sub(r\"[^a-z0-9]\", \"\", nm.lower()))\n",
    "                if score > best_score and sc:\n",
    "                    best_score = score\n",
    "                    best = {\"symbol\": sc, \"source\": \"foundico\"}\n",
    "            time.sleep(sleep)\n",
    "        except Exception:\n",
    "            break\n",
    "    return best if (best and best.get(\"symbol\")) else None\n",
    "    \n",
    "def _cmc_find_symbol_by_name(name: str, api_key: str, pages: int = 4, limit: int = 500):\n",
    "    \"\"\"\n",
    "    Busca por NOMBRE en CMC paginando /v1/cryptocurrency/map y haciendo fuzzy por 'name'.\n",
    "    Devuelve (SYMBOL, 'cmc') o (None, None). 'pages' * 'limit' controla cuánto escaneamos.\n",
    "    \"\"\"\n",
    "    if not api_key or not name:\n",
    "        return None, None\n",
    "    headers = {\"X-CMC_PRO_API_KEY\": api_key, \"Accept\": \"application/json\", \"User-Agent\": USER_AGENT}\n",
    "    name_std = re.sub(r\"[^a-z0-9]\", \"\", str(name).strip().lower())\n",
    "    best_sym, best_score = None, 0.0\n",
    "\n",
    "    start = 1\n",
    "    for _ in range(max(1, pages)):\n",
    "        params = {\n",
    "            \"listing_status\": \"active,inactive,untracked\",\n",
    "            \"aux\": \"name,symbol,slug\",\n",
    "            \"start\": start,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "        try:\n",
    "            r = requests.get(CMC_MAP_URL, headers=headers, params=params, timeout=25)\n",
    "            if r.status_code != 200:\n",
    "                break\n",
    "            data = r.json() or {}\n",
    "            arr = data.get(\"data\") or []\n",
    "            if not arr:\n",
    "                break\n",
    "            for it in arr:\n",
    "                nm = (it.get(\"name\") or \"\").strip()\n",
    "                sym = (it.get(\"symbol\") or \"\").strip()\n",
    "                if not nm or not sym:\n",
    "                    continue\n",
    "                score = SequenceMatcher(None, name_std, re.sub(r\"[^a-z0-9]\", \"\", nm.lower())).ratio()\n",
    "                if score > best_score:\n",
    "                    best_score, best_sym = score, sym\n",
    "            # siguiente página\n",
    "            start += limit\n",
    "            time.sleep(SLEEP_CMC)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "    if best_sym and best_score >= 0.83:\n",
    "        return best_sym.upper(), \"cmc\"\n",
    "    return None, None\n",
    "\n",
    "def resolve_symbol_by_name(name, sleep=0.30):\n",
    "    \"\"\"CoinGecko -> CoinMarketCap -> CoinPaprika -> Foundico. Devuelve (SYMBOL, source) o (None, None).\"\"\"\n",
    "    if not name or str(name).strip() == \"\":\n",
    "        return None, None\n",
    "    name_q = str(name).strip()\n",
    "    name_std = re.sub(r\"[^a-z0-9]\", \"\", name_q.lower())\n",
    "\n",
    "    # 1) CoinGecko\n",
    "    try:\n",
    "        url = f\"https://api.coingecko.com/api/v3/search?query={requests.utils.quote(name_q)}\"\n",
    "        r = requests.get(url, headers=HEADERS, timeout=20)\n",
    "        if r.status_code == 200:\n",
    "            coins = r.json().get(\"coins\", [])\n",
    "            if coins:\n",
    "                best = max(coins, key=lambda c: _similar(name_std, re.sub(r\"[^a-z0-9]\", \"\", str(c.get(\"name\",\"\")).lower())))\n",
    "                sym = (best.get(\"symbol\") or \"\").strip()\n",
    "                if sym:\n",
    "                    time.sleep(sleep)\n",
    "                    print(f\"Symbol {sym} encontrado en CoinGecko para {name_q}\")\n",
    "                    return sym.upper(), \"coingecko\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    # 2) CoinMarketCap (by name, paginado)\n",
    "    try:\n",
    "        sym, src = _cmc_find_symbol_by_name(name_q, CMC_KEY, pages=4, limit=500)\n",
    "        if sym:\n",
    "            time.sleep(sleep)\n",
    "            print(f\"Symbol {sym} encontrado en CoinMarketCap para {name_q}\")\n",
    "            return sym, src\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    time.sleep(sleep)\n",
    "    \n",
    "    # 3) CoinPaprika\n",
    "    try:\n",
    "        url = \"https://api.coinpaprika.com/v1/search\"\n",
    "        params = {\"q\": name_q, \"c\": \"currencies,icos\", \"limit\": 20}\n",
    "        r = requests.get(url, headers=HEADERS, params=params, timeout=20)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json() or {}\n",
    "            cand = (data.get(\"currencies\") or []) + (data.get(\"icos\") or [])\n",
    "            if cand:\n",
    "                best = max(cand, key=lambda c: _similar(name_std, re.sub(r\"[^a-z0-9]\", \"\", str(c.get(\"name\",\"\")).lower())))\n",
    "                sym = (best.get(\"symbol\") or \"\").strip()\n",
    "                if sym:\n",
    "                    time.sleep(sleep)\n",
    "                    print(f\"Symbol {sym} encontrado en CoinPaprika para {name_q}\")\n",
    "                    return sym.upper(), \"coinpaprika\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    # 4) Foundico\n",
    "    try:\n",
    "        res = _foundico_search_name(name_q)\n",
    "        if res and res.get(\"symbol\"):\n",
    "            print(f\"Symbol {res[\"symbol\"]} encontrado en FoundICO para {name_q}\")\n",
    "            return res[\"symbol\"].upper(), \"foundico\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    print(f\"No se encontro Symbol para {name_q}\")\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97f7c016-c498-488e-87c1-9ef12955bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original: 12380 filas, 20 columnas\n",
      "De-dupe: 12380 -> sin idénticos 539 -> por nombre único 539\n",
      "Filtrado final (ICO & ended): de 539 a 200 filas\n",
      "Buscando 'symbol' para 200 tokens.\n",
      "Symbol ACA encontrado en CoinPaprika para Acala Network\n",
      "Symbol BLD encontrado en CoinGecko para Agoric\n",
      "Symbol CARAT encontrado en CoinGecko para Alaska Gold Rush\n",
      "Symbol AMPL encontrado en CoinGecko para Ampleforth\n",
      "Symbol THOL encontrado en CoinGecko para AngelBlock\n",
      "Symbol API3 encontrado en CoinPaprika para API3\n",
      "Symbol APT encontrado en CoinPaprika para Aptos\n",
      "Symbol ARBI encontrado en CoinPaprika para ArbiPad\n",
      "Symbol ARB encontrado en CoinPaprika para Arbitrum\n",
      "Symbol ARCH encontrado en CoinPaprika para Archway\n",
      "Symbol DANA encontrado en CoinPaprika para Ardana\n",
      "Symbol $ARKEN encontrado en CoinGecko para Arken Finance\n",
      "Symbol ARTT encontrado en CoinPaprika para ARTT Network\n",
      "Symbol AURORA encontrado en CoinGecko para Aurora\n",
      "Symbol AURY encontrado en CoinGecko para Aurory\n",
      "Symbol AXL encontrado en CoinGecko para Axelar\n",
      "Symbol BAND encontrado en CoinPaprika para Band Protocol\n",
      "Symbol BDX encontrado en CoinPaprika para Beldex\n",
      "Symbol BEL encontrado en CoinPaprika para Bella Protocol\n",
      "Symbol QI encontrado en CoinPaprika para BENQI\n",
      "Symbol BICO encontrado en CoinPaprika para Biconomy\n",
      "Symbol BIDS encontrado en CoinPaprika para BIDSHOP\n",
      "Symbol BIT encontrado en CoinPaprika para BitDAO\n",
      "Symbol BMEX encontrado en CoinPaprika para BitMEX\n",
      "Symbol BS encontrado en CoinPaprika para Black Stallion\n",
      "No se encontro Symbol para BladeDAO\n",
      "No se encontro Symbol para Blockstack\n",
      "Symbol BLT encontrado en CoinPaprika para Blocto\n",
      "No se encontro Symbol para BlueSale\n",
      "Symbol BTRST encontrado en CoinPaprika para Braintrust\n",
      "Symbol INFRA encontrado en CoinPaprika para Bware Labs\n",
      "Symbol RIA encontrado en CoinPaprika para Calvaria\n",
      "Symbol CO2 encontrado en CoinPaprika para Carbon\n",
      "Symbol CVTX encontrado en CoinPaprika para CarrieVerse\n",
      "Symbol CTSI encontrado en CoinGecko para Cartesi\n",
      "Symbol CASPER encontrado en CoinPaprika para Casper\n",
      "Symbol CELO encontrado en CoinGecko para Celo\n",
      "Symbol CFG encontrado en CoinGecko para Centrifuge\n",
      "Symbol CERE encontrado en CoinGecko para Cere Network\n",
      "Symbol CTK encontrado en CoinPaprika para CertiK\n",
      "Symbol CGPT encontrado en CoinGecko para ChainGPT\n",
      "Symbol CPOOL encontrado en CoinPaprika para Clearpool\n",
      "Symbol CLV encontrado en CoinPaprika para CLV\n",
      "No se encontro Symbol para Cogito Protocol\n",
      "Symbol ZIX encontrado en CoinPaprika para Coinzix\n",
      "Symbol CLY encontrado en CoinPaprika para Colony\n",
      "No se encontro Symbol para Coniun\n",
      "Symbol CONV encontrado en CoinPaprika para Convergence\n",
      "No se encontro Symbol para CowSwap\n",
      "Symbol CRW encontrado en CoinPaprika para Crown\n",
      "Symbol CRGPT encontrado en CoinPaprika para CryptoGPT\n",
      "Symbol CAT encontrado en CoinPaprika para Cyber Arena\n",
      "Symbol CYBER encontrado en CoinPaprika para CyberConnect\n",
      "No se encontro Symbol para dAngel Fund\n",
      "No se encontro Symbol para Deepwaters\n",
      "No se encontro Symbol para Degen Zoo\n",
      "No se encontro Symbol para Delysium\n",
      "No se encontro Symbol para Divergence\n",
      "No se encontro Symbol para Dsync\n",
      "No se encontro Symbol para ECO\n",
      "No se encontro Symbol para Efinity\n",
      "No se encontro Symbol para EGO (Paysenger)\n",
      "No se encontro Symbol para Eldarune\n",
      "No se encontro Symbol para Elixxir\n",
      "No se encontro Symbol para Elrond Network\n",
      "Symbol ELS encontrado en CoinGecko para Ethlas\n",
      "No se encontro Symbol para Exorde\n",
      "No se encontro Symbol para Fei Protocol\n",
      "Symbol FBX encontrado en CoinGecko para Finblox\n",
      "No se encontro Symbol para FitBurn\n",
      "No se encontro Symbol para Flamingo Finance\n",
      "No se encontro Symbol para Flow\n",
      "No se encontro Symbol para Frontier\n",
      "No se encontro Symbol para G4AL\n",
      "No se encontro Symbol para Gearbox Protocol\n",
      "No se encontro Symbol para Gelato\n",
      "No se encontro Symbol para Glory Finance\n",
      "No se encontro Symbol para Gods Unchained\n",
      "No se encontro Symbol para Goldfinch Finance\n",
      "No se encontro Symbol para Goracle\n",
      "No se encontro Symbol para GoSleep\n",
      "No se encontro Symbol para GPT Guru\n",
      "No se encontro Symbol para GuildFi\n",
      "No se encontro Symbol para Guild of Guardians\n",
      "No se encontro Symbol para HALO\n",
      "No se encontro Symbol para handle.fi\n",
      "No se encontro Symbol para Hepton\n",
      "No se encontro Symbol para Honeyland\n",
      "No se encontro Symbol para HoneyWood\n",
      "No se encontro Symbol para HOPR\n",
      "No se encontro Symbol para HydraDX\n",
      "No se encontro Symbol para Hypercycle\n",
      "No se encontro Symbol para HyperGPT\n",
      "No se encontro Symbol para IguVerse\n",
      "No se encontro Symbol para Ikonic\n",
      "No se encontro Symbol para Immutable X\n",
      "No se encontro Symbol para Injective Protocol\n",
      "No se encontro Symbol para InteractWith\n",
      "Symbol IRON encontrado en CoinGecko para Iron Fish\n",
      "Symbol JST encontrado en CoinGecko para JUST\n",
      "No se encontro Symbol para KAIF\n",
      "No se encontro Symbol para Karate Combat\n",
      "No se encontro Symbol para Kine\n",
      "No se encontro Symbol para Konomi Network\n",
      "No se encontro Symbol para KryptAI\n",
      "No se encontro Symbol para LimeWire\n",
      "Symbol LINA encontrado en CoinPaprika para Linear Finance\n",
      "Symbol LITH encontrado en CoinGecko para Lithium\n",
      "Symbol LITT encontrado en CoinGecko para LitLab Games\n",
      "Symbol LMR encontrado en CoinGecko para Lumerin\n",
      "No se encontro Symbol para Manta Network Crowdloan\n",
      "Symbol POND encontrado en CoinGecko para Marlin\n",
      "Symbol MC encontrado en CoinPaprika para Merit Circle\n",
      "No se encontro Symbol para Metaverse Kombat\n",
      "Symbol MINA encontrado en CoinPaprika para Mina Protocol\n",
      "Symbol DAR encontrado en CoinPaprika para Mines Of Dalarnia\n",
      "Symbol MINIMA encontrado en CoinPaprika para Minima\n",
      "Symbol ML encontrado en CoinPaprika para Mintlayer\n",
      "Symbol MZR encontrado en CoinPaprika para Mizar\n",
      "Symbol MONO encontrado en CoinPaprika para MonoX\n",
      "Symbol MOOVY encontrado en CoinPaprika para Moovy\n",
      "No se encontro Symbol para Naviern\n",
      "No se encontro Symbol para Near Protocol\n",
      "No se encontro Symbol para NeoCortexAI\n",
      "Symbol NEON encontrado en CoinGecko para Neon\n",
      "No se encontro Symbol para NFT3\n",
      "Symbol NU encontrado en CoinGecko para NuCypher\n",
      "Symbol NBLU encontrado en CoinGecko para NuriTopia\n",
      "Symbol NYM encontrado en CoinGecko para Nym\n",
      "No se encontro Symbol para Oasis Labs\n",
      "No se encontro Symbol para Oiler Network\n",
      "No se encontro Symbol para OIN Finance\n",
      "No se encontro Symbol para Open Campus\n",
      "No se encontro Symbol para OpenSwap\n",
      "No se encontro Symbol para OpiPets\n",
      "No se encontro Symbol para Orbofi\n",
      "No se encontro Symbol para OtterHome\n",
      "No se encontro Symbol para OVO NFT Platform\n",
      "No se encontro Symbol para Ozone Metaverse\n",
      "No se encontro Symbol para PARMA Fan Token\n",
      "No se encontro Symbol para Perlin\n",
      "No se encontro Symbol para Perpetual Protocol\n",
      "No se encontro Symbol para Pika Protocol\n",
      "No se encontro Symbol para Pine\n",
      "No se encontro Symbol para PlayZap\n",
      "No se encontro Symbol para PodFast\n",
      "No se encontro Symbol para PolyGame\n",
      "No se encontro Symbol para Pomerium\n",
      "No se encontro Symbol para Project Galaxy\n",
      "No se encontro Symbol para pSTAKE\n",
      "No se encontro Symbol para Qredo\n",
      "No se encontro Symbol para Radiant Capital\n",
      "No se encontro Symbol para Radicle\n",
      "No se encontro Symbol para Radix DLT\n",
      "No se encontro Symbol para Razor Network\n",
      "No se encontro Symbol para Reality Metaverse\n",
      "No se encontro Symbol para Reign of Terror\n",
      "Symbol RJV encontrado en CoinGecko para Rejuve.AI\n",
      "Symbol NOTE encontrado en CoinGecko para Republic Note\n",
      "No se encontro Symbol para Re:water\n",
      "No se encontro Symbol para SHELTERZ\n",
      "No se encontro Symbol para Sifchain Finance\n",
      "No se encontro Symbol para SKALE Network\n",
      "No se encontro Symbol para Space ID\n",
      "No se encontro Symbol para Stader Labs\n",
      "No se encontro Symbol para Stafi\n",
      "No se encontro Symbol para Staika\n",
      "No se encontro Symbol para Star Atlas\n",
      "No se encontro Symbol para Starly.io\n",
      "No se encontro Symbol para Stegos\n",
      "No se encontro Symbol para Stella Fantasy\n",
      "Symbol SUI encontrado en CoinGecko para SUI\n",
      "No se encontro Symbol para SuiPad\n",
      "No se encontro Symbol para Swash\n",
      "No se encontro Symbol para Tatsumeeko\n",
      "No se encontro Symbol para Tectum\n",
      "No se encontro Symbol para Tenet\n",
      "No se encontro Symbol para The Graph\n",
      "No se encontro Symbol para The Qwan\n",
      "No se encontro Symbol para The Unfettered\n",
      "No se encontro Symbol para Tidal Finance\n",
      "No se encontro Symbol para Turbos Finance\n",
      "No se encontro Symbol para TypeIT\n",
      "No se encontro Symbol para Ultra\n",
      "No se encontro Symbol para UltrAlpha\n",
      "No se encontro Symbol para UMA\n",
      "No se encontro Symbol para Umee\n",
      "No se encontro Symbol para UniLend\n",
      "No se encontro Symbol para Uno Farm\n",
      "Symbol VEGA encontrado en CoinGecko para Vega Protocol\n",
      "No se encontro Symbol para Voxies Tactics\n",
      "Symbol WAR encontrado en CoinGecko para War Legends\n",
      "Symbol WFI encontrado en CoinGecko para WeFi\n",
      "Symbol WIFI encontrado en CoinGecko para WiFi Map\n",
      "No se encontro Symbol para Wing\n",
      "No se encontro Symbol para Wink\n",
      "No se encontro Symbol para Wistaverse\n",
      "No se encontro Symbol para xDai\n",
      "No se encontro Symbol para Yesports\n",
      "No se encontro Symbol para Your Open Metaverse\n",
      "\n",
      "Filas finales para export: 200\n",
      "ICOs Éxitosas (%): {0: 78.5, 1: 21.5}\n",
      "symbol_resolved_source\n",
      "               129\n",
      "coinpaprika     41\n",
      "coingecko       30\n",
      "Name: count, dtype: int64\n",
      "✅ Dataset limpio guardado en: datasets/processed/kaggle_yanmaksi_clean.csv\n",
      "   (incluye: dedupe previo, filtro ICO+ended y resolución de symbol por nombre con CoinGecko->Paprika->FoundICO)\n",
      "CPU times: total: 8.36 s\n",
      "Wall time: 6min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# -------- 1) CARGA --------\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "print(f\"Dataset original: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "\n",
    "# -------- 2) LIMPIEZA BÁSICA (sin llamadas externas) --------\n",
    "# Montos\n",
    "for col in [\"goal\", \"fundraising_goal\", \"received_money\", \"received_money.1\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(parse_money)\n",
    "\n",
    "goal_col = \"fundraising_goal\" if \"fundraising_goal\" in df.columns else (\"goal\" if \"goal\" in df.columns else None)\n",
    "recv_col = \"received_money\" if \"received_money\" in df.columns else (\"received_money.1\" if \"received_money.1\" in df.columns else None)\n",
    "\n",
    "# Fechas\n",
    "if \"end_date\" in df.columns:\n",
    "    df[\"end_date_clean\"] = df[\"end_date\"].map(clean_end_date)\n",
    "    df[\"end_date_parsed\"] = pd.to_datetime(df[\"end_date_clean\"], format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "else:\n",
    "    df[\"end_date_parsed\"] = pd.NaT\n",
    "\n",
    "if \"start_end_date_coin_sell\" in df.columns and df[\"end_date_parsed\"].isna().any():\n",
    "    need = df[\"end_date_parsed\"].isna()\n",
    "    rng = df.loc[need, \"start_end_date_coin_sell\"].astype(str)\n",
    "    right = rng.str.extract(r\".*[-–—]\\s*(.*)$\")[0].map(clean_end_date)\n",
    "    df.loc[need, \"end_date_parsed\"] = pd.to_datetime(right, format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# Flags\n",
    "today = pd.Timestamp(datetime.now(UTC).date())\n",
    "ended = df[\"end_date_parsed\"].notna() & (df[\"end_date_parsed\"] <= today)\n",
    "\n",
    "signals = []\n",
    "for c in [\"ico_token_price\", \"available_for_token_sale\", \"sold_coins\", \"start_end_date_coin_sell\"]:\n",
    "    signals.append(df[c].notna() if c in df.columns else pd.Series(False, index=df.index))\n",
    "is_ico = np.logical_or.reduce(signals) if signals else pd.Series(False, index=df.index)\n",
    "\n",
    "# Etiqueta\n",
    "if goal_col and recv_col:\n",
    "    df[\"ico_successful\"] = ((df[recv_col] >= df[goal_col]) & df[recv_col].notna() & df[goal_col].notna()).astype(int)\n",
    "else:\n",
    "    df[\"ico_successful\"] = np.nan\n",
    "\n",
    "# -------- 3) NORMALIZAR NAME (sin API) --------\n",
    "ticker_col = \"coin_ticker\" if \"coin_ticker\" in df.columns else None\n",
    "if ticker_col:\n",
    "    # en este dataset, coin_ticker es el NOMBRE, no el símbolo\n",
    "    df[\"name_std\"] = normalize_text_series(df[ticker_col])\n",
    "else:\n",
    "    df[\"name_std\"] = \"\"\n",
    "\n",
    "# -------- 4) DEDUPE (antes de cualquier API) --------\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()  # idénticos\n",
    "after_full = len(df)\n",
    "\n",
    "if \"name_std\" in df.columns:\n",
    "    cols_for_score = [c for c in df.columns if c not in [\"name_std\"]]\n",
    "    score = df[cols_for_score].notna().sum(axis=1)\n",
    "    df[\"_score\"] = score\n",
    "    df[\"_end\"]  = pd.to_datetime(df.get(\"end_date_parsed\"), errors=\"coerce\")\n",
    "    df = df.sort_values(by=[\"name_std\",\"_score\",\"_end\"], ascending=[True, False, False])\n",
    "    df = df.drop_duplicates(subset=[\"name_std\"], keep=\"first\")\n",
    "    df = df.drop(columns=[\"_score\",\"_end\"], errors=\"ignore\")\n",
    "after_name = len(df)\n",
    "print(f\"De-dupe: {before} -> sin idénticos {after_full} -> por nombre único {after_name}\")\n",
    "\n",
    "# -------- 5) FILTRO FINAL (ICO & ENDED) --------\n",
    "keep = (\n",
    "    (df[\"end_date_parsed\"].notna() & (df[\"end_date_parsed\"] <= today))\n",
    "    &\n",
    "    (\n",
    "        (df[\"ico_token_price\"].notna() if \"ico_token_price\" in df.columns else False)\n",
    "        | (df[\"available_for_token_sale\"].notna() if \"available_for_token_sale\" in df.columns else False)\n",
    "        | (df[\"sold_coins\"].notna() if \"sold_coins\" in df.columns else False)\n",
    "        | (df[\"start_end_date_coin_sell\"].notna() if \"start_end_date_coin_sell\" in df.columns else False)\n",
    "    )\n",
    ")\n",
    "df = df.loc[keep].copy()\n",
    "print(f\"Filtrado final (ICO & ended): de {after_name} a {len(df)} filas\")\n",
    "\n",
    "# -------- 6) RESOLVER SYMBOL SOLO PARA ESTAS FILAS ÚNICAS --------\n",
    "unique_names = df[\"coin_ticker\"].astype(str).fillna(\"\").unique().tolist() if \"coin_ticker\" in df.columns else []\n",
    "print(f\"Buscando 'symbol' para {len(unique_names)} tokens.\")\n",
    "cache_sym = {}\n",
    "for name in unique_names:\n",
    "    key = name.strip().lower()\n",
    "    if key and key not in cache_sym:\n",
    "        sym, src = resolve_symbol_by_name(name)\n",
    "        cache_sym[key] = (sym, src)\n",
    "\n",
    "df[\"symbol_resolved\"] = df[\"coin_ticker\"].astype(str).fillna(\"\").str.lower().map(lambda k: (cache_sym.get(k, (None,None))[0] if k else None))\n",
    "df[\"symbol_resolved_source\"] = df[\"coin_ticker\"].astype(str).fillna(\"\").str.lower().map(lambda k: (cache_sym.get(k, (None,None))[1] if k else None))\n",
    "df[\"symbol_resolved\"] = df[\"symbol_resolved\"].fillna(\"\")\n",
    "df[\"symbol_resolved_source\"] = df[\"symbol_resolved_source\"].fillna(\"\")\n",
    "\n",
    "# std del símbolo\n",
    "df[\"symbol_std\"] = normalize_text_series(df[\"symbol_resolved\"])\n",
    "\n",
    "# -------- 7) RESUMEN + EXPORT --------\n",
    "def pct(s):\n",
    "    vc = s.value_counts(normalize=True) * 100\n",
    "    return vc.round(2).to_dict()\n",
    "\n",
    "print(f\"\\nFilas finales para export: {len(df)}\")\n",
    "if \"ico_successful\" in df.columns and df[\"ico_successful\"].notna().any():\n",
    "    print(\"ICOs Éxitosas (%):\", pct(df[\"ico_successful\"]))\n",
    "    \n",
    "if \"symbol_resolved_source\" in df.columns:\n",
    "    print(df['symbol_resolved_source'].value_counts())\n",
    "\n",
    "# df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Dataset limpio guardado en: {output_path}\")\n",
    "print(\"   (incluye: dedupe previo, filtro ICO+ended y resolución de symbol por nombre con CoinGecko->Paprika->FoundICO)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6ef11a-f8ed-4e44-af63-5c877f50fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- REINTENTO: completar symbol SOLO donde sigue faltando --------\n",
      "Antes del reintento:\n",
      "symbol_resolved_source\n",
      "coinpaprika    110\n",
      "coingecko       61\n",
      "<EMPTY>         29\n",
      "Name: count, dtype: int64\n",
      "Buscando 'symbol' para 29 tokens (únicos, solo faltantes).\n",
      "No se encontro Symbol para BladeDAO\n",
      "No se encontro Symbol para Blockstack\n",
      "No se encontro Symbol para BlueSale\n",
      "No se encontro Symbol para Cogito Protocol\n",
      "No se encontro Symbol para Coniun\n",
      "No se encontro Symbol para CowSwap\n",
      "No se encontro Symbol para EGO (Paysenger)\n",
      "No se encontro Symbol para G4AL\n",
      "No se encontro Symbol para Gearbox Protocol\n",
      "No se encontro Symbol para Glory Finance\n",
      "No se encontro Symbol para Goldfinch Finance\n",
      "No se encontro Symbol para Goracle\n",
      "No se encontro Symbol para HydraDX\n",
      "No se encontro Symbol para Ikonic\n",
      "No se encontro Symbol para KryptAI\n",
      "No se encontro Symbol para Manta Network Crowdloan\n",
      "No se encontro Symbol para Oiler Network\n",
      "No se encontro Symbol para PARMA Fan Token\n",
      "No se encontro Symbol para PolyGame\n",
      "No se encontro Symbol para Project Galaxy\n",
      "No se encontro Symbol para Radicle\n",
      "No se encontro Symbol para Radix DLT\n",
      "No se encontro Symbol para Re:water\n",
      "No se encontro Symbol para Stader Labs\n",
      "No se encontro Symbol para Starly.io\n",
      "No se encontro Symbol para Umee\n",
      "No se encontro Symbol para Voxies Tactics\n",
      "No se encontro Symbol para Your Open Metaverse\n",
      "No se encontro Symbol para dAngel Fund\n",
      "\n",
      "Después del reintento:\n",
      "symbol_resolved_source\n",
      "coinpaprika    110\n",
      "coingecko       61\n",
      "<EMPTY>         29\n",
      "Name: count, dtype: int64\n",
      "Se resolvieron 0 nuevos symbols en esta pasada.\n",
      "✅ Dataset actualizado: datasets/processed/kaggle_yanmaksi_clean.csv\n",
      "CPU times: total: 719 ms\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# -------- REINTENTO: completar symbol SOLO donde sigue faltando --------\n",
    "print(\"-------- REINTENTO: completar symbol SOLO donde sigue faltando --------\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = \"datasets/processed/kaggle_yanmaksi_clean.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Asegurar columnas esperadas\n",
    "for col in [\"symbol_resolved\", \"symbol_resolved_source\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"\"\n",
    "\n",
    "# Máscara de \"aún no resuelto\"\n",
    "mask_missing = df[\"symbol_resolved_source\"].fillna(\"\").str.len().eq(0)\n",
    "\n",
    "print(\"Antes del reintento:\")\n",
    "print(df[\"symbol_resolved_source\"].fillna(\"\").replace({\"\": \"<EMPTY>\"}).value_counts().head(10))\n",
    "\n",
    "# Nombres únicos a consultar (solo de los faltantes)\n",
    "if \"coin_ticker\" not in df.columns:\n",
    "    raise ValueError(\"No encuentro la columna 'coin_ticker' (que aquí usamos como NOMBRE).\")\n",
    "\n",
    "names_to_query = (\n",
    "    df.loc[mask_missing, \"coin_ticker\"]\n",
    "      .astype(str).fillna(\"\")\n",
    "      .str.strip()\n",
    ")\n",
    "unique_names = sorted({n for n in names_to_query.tolist() if n})\n",
    "\n",
    "print(f\"Buscando 'symbol' para {len(unique_names)} tokens (únicos, solo faltantes).\")\n",
    "\n",
    "# Resolver en batch con cache\n",
    "cache_sym = {}\n",
    "for name in unique_names:\n",
    "    key = name.lower()\n",
    "    if key not in cache_sym:\n",
    "        sym, src = resolve_symbol_by_name(name)  # CG -> CMC(name) -> Paprika -> Foundico\n",
    "        cache_sym[key] = (sym, src)\n",
    "\n",
    "# Construir series de resultado alineadas al df (SOLO para las filas faltantes)\n",
    "def _sym_mapper(x):\n",
    "    k = str(x).strip().lower()\n",
    "    sym, _ = cache_sym.get(k, (None, None))\n",
    "    return sym if sym else \"\"\n",
    "\n",
    "def _src_mapper(x):\n",
    "    k = str(x).strip().lower()\n",
    "    _, src = cache_sym.get(k, (None, None))\n",
    "    return src if src else \"\"\n",
    "\n",
    "df.loc[mask_missing, \"symbol_resolved\"] = (\n",
    "    df.loc[mask_missing, \"coin_ticker\"].astype(str).map(_sym_mapper)\n",
    ")\n",
    "\n",
    "df.loc[mask_missing, \"symbol_resolved_source\"] = (\n",
    "    df.loc[mask_missing, \"coin_ticker\"].astype(str).map(_src_mapper)\n",
    ")\n",
    "\n",
    "# Normalizar symbol_std (opcional)\n",
    "def normalize_text_series(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.lower()\n",
    "         .str.strip()\n",
    "         .str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "df[\"symbol_std\"] = normalize_text_series(df[\"symbol_resolved\"])\n",
    "\n",
    "# Métrica de cuántos nuevos symbols se resolvieron\n",
    "new_resolved = df.loc[mask_missing, \"symbol_resolved_source\"].replace(\"\", np.nan).notna().sum()\n",
    "print(\"\\nDespués del reintento:\")\n",
    "print(df[\"symbol_resolved_source\"].fillna(\"\").replace({\"\": \"<EMPTY>\"}).value_counts().head(10))\n",
    "print(f\"Se resolvieron {new_resolved} nuevos symbols en esta pasada.\")\n",
    "\n",
    "# Guardar SOBRE el mismo CSV\n",
    "df.to_csv(dataset_path, index=False)\n",
    "print(f\"✅ Dataset actualizado: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7978c01-51a4-44d3-9127-0fefea0ffab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "dataset_path = \"datasets/raw/ico_yanmaksi_kaggle.csv\"\n",
    "output_path = \"datasets/processed/kaggle_yanmaksi_clean.csv\"\n",
    "\n",
    "# --- Cargar dataset ---\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(f\"Dataset original: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def parse_money(x):\n",
    "    \"\"\"Convierte montos tipo '$5M', '1,200,000', '3 million' -> float (USD-asumido).\"\"\"\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).lower().strip()\n",
    "    s = s.replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        if \"billion\" in s: base = 1_000_000_000\n",
    "        elif \"million\" in s: base = 1_000_000\n",
    "        elif \"b\" in s and re.search(r\"\\d\", s): base = 1_000_000_000\n",
    "        elif \"m\" in s and re.search(r\"\\d\", s): base = 1_000_000\n",
    "        elif \"k\" in s and re.search(r\"\\d\", s): base = 1_000\n",
    "        else: base = 1\n",
    "        num = re.findall(r\"[\\d.]+\", s)\n",
    "        return float(num[0]) * base if num else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_end_date(s):\n",
    "    \"\"\"Limpia strings tipo 'Ended: 3 Jun 2023' o 'End: 07/02/2018' y devuelve sólo la fecha.\"\"\"\n",
    "    if pd.isna(s): return np.nan\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"^(ended|end|finished|finalized)\\s*:?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = s.replace(\"—\", \"-\").replace(\"–\", \"-\")\n",
    "    return s\n",
    "\n",
    "def normalize_text(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.lower()\n",
    "         .str.strip()\n",
    "         .str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "# ---------- limpiar montos ----------\n",
    "for col in [\"goal\", \"fundraising_goal\", \"received_money\", \"received_money.1\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(parse_money)\n",
    "\n",
    "goal_col = \"fundraising_goal\" if \"fundraising_goal\" in df.columns else (\"goal\" if \"goal\" in df.columns else None)\n",
    "recv_col = \"received_money\" if \"received_money\" in df.columns else (\"received_money.1\" if \"received_money.1\" in df.columns else None)\n",
    "\n",
    "# ---------- limpiar y parsear fechas ----------\n",
    "if \"end_date\" in df.columns:\n",
    "    df[\"end_date_clean\"] = df[\"end_date\"].map(clean_end_date)\n",
    "    df[\"end_date_parsed\"] = pd.to_datetime(df[\"end_date_clean\"], format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "else:\n",
    "    df[\"end_date_parsed\"] = pd.NaT\n",
    "\n",
    "# Si hay rango \"start_end_date_coin_sell\" (por ejemplo \"Jan 10, 2018 - Feb 12, 2018\"), tomar el extremo derecho\n",
    "if \"start_end_date_coin_sell\" in df.columns and df[\"end_date_parsed\"].isna().any():\n",
    "    need = df[\"end_date_parsed\"].isna()\n",
    "    rng = df.loc[need, \"start_end_date_coin_sell\"].astype(str)\n",
    "    right = rng.str.extract(r\".*[-–—]\\s*(.*)$\")[0].map(clean_end_date)\n",
    "    df.loc[need, \"end_date_parsed\"] = pd.to_datetime(right, format=\"%d %b %Y\", errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# ---------- determinar si la ICO está finalizada por su fecha de \"end_date\" ----------\n",
    "today = pd.Timestamp(datetime.now(UTC).date())\n",
    "ended = df[\"end_date_parsed\"].notna() & (df[\"end_date_parsed\"] <= today)\n",
    "\n",
    "# ---------- heurística: es ICO (si tiene precio/token info) ----------\n",
    "signals = []\n",
    "for c in [\"ico_token_price\", \"available_for_token_sale\", \"sold_coins\", \"start_end_date_coin_sell\"]:\n",
    "    signals.append(df[c].notna() if c in df.columns else pd.Series(False, index=df.index))\n",
    "is_ico = np.logical_or.reduce(signals) if signals else pd.Series(False, index=df.index)\n",
    "\n",
    "# ---------- derivar éxito ----------\n",
    "if goal_col and recv_col:\n",
    "    df[\"ico_successful\"] = ((df[recv_col] >= df[goal_col]) & df[recv_col].notna() & df[goal_col].notna()).astype(int)\n",
    "else:\n",
    "    df[\"ico_successful\"] = np.nan\n",
    "\n",
    "# ---------- normalizaciones de texto ----------\n",
    "ticker_col = \"coin_ticker\" if \"coin_ticker\" in df.columns else None\n",
    "if ticker_col:\n",
    "    df[\"name_std\"] = normalize_text(df[ticker_col])\n",
    "    df[\"symbol_std\"] = normalize_text(df[ticker_col])\n",
    "else:\n",
    "    df[\"name_std\"] = \"\"\n",
    "    df[\"symbol_std\"] = \"\"\n",
    "\n",
    "# ---------- filtro final ----------\n",
    "keep = is_ico & ended\n",
    "df_out = df.loc[keep].copy()\n",
    "\n",
    "# ---------- resumen ----------\n",
    "def pct(s):\n",
    "    vc = s.value_counts(normalize=True) * 100\n",
    "    return vc.round(2).to_dict()\n",
    "\n",
    "print(f\"\\nFilas con evidencia de ICO: {int(is_ico.sum())} / {len(df)}\")\n",
    "print(f\"Filas 'ended' por fecha:     {int(ended.sum())} / {len(df)}\")\n",
    "print(f\"Filas finales (ICO & ended): {len(df_out)}, de un total de {len(df)}\")\n",
    "if df_out[\"ico_successful\"].notna().any():\n",
    "    print(\"ICOs Éxitosas (%):\", pct(df_out[\"ico_successful\"]))\n",
    "\n",
    "# ---------- export ----------\n",
    "# df_out.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Dataset limpio guardado en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b055e-d642-4ecf-9b60-f04929f67095",
   "metadata": {},
   "source": [
    "#### Limpieza del dataset de Vanessa Villanueva obtenido en ICPSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a2f621-a862-45de-8062-c593c236a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original (ICPSR): 2186 filas, 71 columnas\n",
      "\n",
      "Columnas detectadas:\n",
      "  name_col   : name\n",
      "  symbol_col : ticker\n",
      "  succ_col   : ico success\n",
      "  soft_col   : softcap\n",
      "  hard_col   : hardcap\n",
      "  raised_col : amount raised\n",
      "\n",
      "Éxito (%): {0: 61.39, 1: 38.61}\n",
      "\n",
      "Stats raised_usd: {'count': 2183, 'min': 0.0, 'median': 0.0, 'max': 1000000000.0}\n",
      "Stats softcap_usd: {'count': 1417, 'min': 0.0, 'median': 2409600.0, 'max': 60000000008.0}\n",
      "Stats hardcap_usd: {'count': 1811, 'min': 12543.0, 'median': 30000000.0, 'max': 100000000000.0}\n",
      "\n",
      "✅ Guardado: datasets/processed/icpsr_villanueva_clean.csv\n",
      "Filas finales: 2,186\n",
      "CPU times: total: 938 ms\n",
      "Wall time: 982 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Rutas de entrada/salida\n",
    "dataset_path = \"datasets/raw/ICO_VillanuevaVanessa_OpenICPSR.xlsx\"\n",
    "output_path  = \"datasets/processed/icpsr_villanueva_clean.csv\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def parse_money(x):\n",
    "    \"\"\"Convierte '$5M', '1,200,000', '3 million', '0.75B' -> float (asumiendo USD).\"\"\"\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).lower().strip()\n",
    "    s = s.replace(\",\", \"\").replace(\"$\", \"\")\n",
    "    try:\n",
    "        if \"billion\" in s or re.search(r\"\\db\", s): base = 1_000_000_000\n",
    "        elif \"million\" in s or re.search(r\"\\dm\", s): base = 1_000_000\n",
    "        elif re.search(r\"\\dk\", s): base = 1_000\n",
    "        else: base = 1\n",
    "        nums = re.findall(r\"[\\d.]+\", s)\n",
    "        return float(nums[0]) * base if nums else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def normalize_text(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.lower().str.strip()\n",
    "         .str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    "    )\n",
    "    \n",
    "def split_symbol(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.split(' ', 1)\n",
    "    )\n",
    "\n",
    "def first_col(df, candidates):\n",
    "    \"\"\"Devuelve el primer nombre de columna presente en df según una lista de candidatos (lowercase).\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns: \n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# ---------- cargar ----------\n",
    "df = pd.read_excel(dataset_path)\n",
    "print(f\"Dataset original (ICPSR): {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "\n",
    "# normalizar encabezados\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# eliminar columnas 'unnamed' residuales\n",
    "drop_unnamed = [c for c in df.columns if c.startswith(\"unnamed\")]\n",
    "if drop_unnamed:\n",
    "    df = df.drop(columns=drop_unnamed)\n",
    "\n",
    "# columnas clave\n",
    "name_col   = 'name'\n",
    "symbol_col = 'ticker'\n",
    "succ_col   = 'ico success'\n",
    "soft_col   = 'softcap'\n",
    "hard_col   = 'hardcap'\n",
    "raised_col = 'amount raised'\n",
    "\n",
    "# ---------- estandarizar keys de join ----------\n",
    "df[\"name_std\"]   = normalize_text(df[name_col])\n",
    "\n",
    "# -- algunas filas tienen la palabra \"token\" luego del simbolo del token, por eso se elimina. --\n",
    "df[\"symbol_std\"] = df[symbol_col].astype(\"string\").str.split(n=1).str[0]\n",
    "\n",
    "# ---------- parseo de montos (si existen) ----------\n",
    "for col in [soft_col, hard_col, raised_col]:\n",
    "    if col:\n",
    "        df[col + \"_usd\"] = df[col].apply(parse_money)\n",
    "\n",
    "# ---------- etiqueta de éxito ----------\n",
    "if succ_col:\n",
    "    # usar la que trae el dataset (preferido)\n",
    "    df[\"ico_successful\"] = (\n",
    "        pd.to_numeric(df[succ_col], errors=\"coerce\")\n",
    "          .fillna(0).clip(0,1).astype(int)\n",
    "    )\n",
    "else:\n",
    "    # derivar: raised >= soft cap (si ambos existen)\n",
    "    if raised_col and soft_col:\n",
    "        s = pd.to_numeric(df[soft_col + \"_usd\"], errors=\"coerce\")\n",
    "        r = pd.to_numeric(df[raised_col + \"_usd\"], errors=\"coerce\")\n",
    "        df[\"ico_successful\"] = ((r >= s) & r.notna() & s.notna()).astype(int)\n",
    "    else:\n",
    "        df[\"ico_successful\"] = np.nan  # no se puede inferir de forma fiable\n",
    "\n",
    "# ---------- normalización leve de categóricas útiles ----------\n",
    "for cat in [\"industry\",\"platform\",\"country\",\"kyc\",\"ieo\",\"regtax\",\"regulk yc\",\"regulkyc\",\"regulation\",\"jurisdiction\"]:\n",
    "    if cat in df.columns and df[cat].dtype == \"O\":\n",
    "        df[cat] = df[cat].astype(str).str.strip()\n",
    "\n",
    "df[\"industry\"] = df[\"industry\"].replace({0: np.nan,\n",
    "    1:\"Artificial Intelligence\", 2:\"Art\", 3:\"Banking\", 4:\"Big data\",\n",
    "    5:\"Business services\", 6:\"charity\", 7:\"Communication\", 8:\"Cryptocurrency\",\n",
    "    9:\"Education\", 10:\"Electronics\", 11:\"Energy\", 12:\"Enterntainment\",\n",
    "    13:\"Health\", 14:\"Infrastructre\", 15:\"Internet\", 16:\"Investment\",\n",
    "    17:\"Legal\", 18:\"Manufacturing\", 19:\"Media\", 20:\"Platform\",\n",
    "    21:\"real estate\", 22:\"Retail\", 23:\"smart contract\", 24:\"software\",\n",
    "    25:\"sports\", 26:\"Tourism\", 27:\"virtual reality\", 28:\"other\",\n",
    "})\n",
    "\n",
    "df[\"country\"] = df[\"country\"].replace({0: np.nan,\n",
    "    1:\"Singapore\", 2:\"UK\", 3:\"USA\", 4:\"Estonia\", 5:\"Switzerland\", 6:\"Russia\",\n",
    "    7:\"Hong Kong\", 8:\"Germany\", 9:\"Cayman Islands\", 10:\"Australia\",\n",
    "    11:\"Malta\", 12:\"Netherlands\", 13:\"Canada\", 14:\"Gibraltar\",\n",
    "    15:\"United Arab Emirates\", 16:\"Taiwan\", 17:\"British virgin Islands\",\n",
    "    18:\"New Zealand\", 19:\"Belize\",\n",
    "})\n",
    "\n",
    "df[\"platform\"] = df[\"platform\"].replace({0: \"Others\",\n",
    "    1: \"Monero\", 2: \"Nem\", 3: \"Waves\",\n",
    "    4: \"Stellar\", 5: \"Neo\", 6: \"Ethereum\"\n",
    "})\n",
    "\n",
    "# ---------- fechas (opcional; si existieran columnas con 'date') ----------\n",
    "date_cols = [c for c in df.columns if \"date\" in c]\n",
    "for c in date_cols:\n",
    "    df[c + \"_parsed\"] = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# ---------- resumen ----------\n",
    "print(\"\\nColumnas detectadas:\")\n",
    "print(\"  name_col   :\", name_col)\n",
    "print(\"  symbol_col :\", symbol_col)\n",
    "print(\"  succ_col   :\", succ_col)\n",
    "print(\"  soft_col   :\", soft_col)\n",
    "print(\"  hard_col   :\", hard_col)\n",
    "print(\"  raised_col :\", raised_col)\n",
    "\n",
    "if df[\"ico_successful\"].notna().any():\n",
    "    dist = df[\"ico_successful\"].value_counts(normalize=True) * 100\n",
    "    print(\"\\nÉxito (%):\", dist.round(2).to_dict())\n",
    "\n",
    "# sanity check de montos\n",
    "def quick_stats(series):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    return {\"count\": int(s.notna().sum()),\n",
    "            \"min\": float(np.nanmin(s)) if s.notna().any() else None,\n",
    "            \"median\": float(np.nanmedian(s)) if s.notna().any() else None,\n",
    "            \"max\": float(np.nanmax(s)) if s.notna().any() else None}\n",
    "\n",
    "if raised_col:\n",
    "    print(\"\\nStats raised_usd:\", quick_stats(df[raised_col + \"_usd\"]))\n",
    "if soft_col:\n",
    "    print(\"Stats softcap_usd:\", quick_stats(df[soft_col + \"_usd\"]))\n",
    "if hard_col:\n",
    "    print(\"Stats hardcap_usd:\", quick_stats(df[hard_col + \"_usd\"]))\n",
    "\n",
    "# ---------- export ----------\n",
    "df_out = df.copy()\n",
    "df_out.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Guardado: {output_path}\")\n",
    "print(f\"Filas finales: {len(df_out):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb14bc1-f3d1-448c-bcc5-9001e0abe6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original (Zenodo): 306 filas, 126 columnas\n",
      "\n",
      "Distribución original de ico_successful:\n",
      "ico_successful\n",
      "1    300\n",
      "0      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Media de recaudación por etiqueta:\n",
      "ico_successful\n",
      "0    0.000000\n",
      "1    0.036667\n",
      "Name: independent custodian for ico funds_usd, dtype: float64\n",
      "\n",
      "✅ Guardado: datasets/processed/zenodo_fahlenbrach_clean.csv\n",
      "Filas finales: 306\n",
      "CPU times: total: 1.59 s\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# === Preprocesado Fahlenbrach (Zenodo) ===\n",
    "import pandas as pd, numpy as np, re\n",
    "from datetime import datetime\n",
    "\n",
    "PATH_ZENODO = \"datasets/raw/ICO_Fahlenbrach_Zenodo.xlsx\"\n",
    "OUT_ZENODO  = \"datasets/processed/zenodo_fahlenbrach_clean.csv\"\n",
    "\n",
    "def normalize_text(s):\n",
    "    return s.astype(str).str.lower().str.strip().str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
    "\n",
    "def parse_money(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).lower().replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
    "    try:\n",
    "        if \"b\" in s: base = 1_000_000_000\n",
    "        elif \"m\" in s: base = 1_000_000\n",
    "        elif \"k\" in s: base = 1_000\n",
    "        else: base = 1\n",
    "        nums = re.findall(r\"[\\d.]+\", s)\n",
    "        return float(nums[0]) * base if nums else np.nan\n",
    "    except: \n",
    "        return np.nan\n",
    "\n",
    "df = pd.read_excel(PATH_ZENODO)\n",
    "print(f\"Dataset original (Zenodo): {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Columnas clave\n",
    "name_col   = \"name_other\"\n",
    "symbol_col = \"ticker_symbol_cmc\"\n",
    "succ_col   = \"ico_successful\"\n",
    "soft_col   = \"soft_cap\"\n",
    "hard_col   = \"hard_cap\"\n",
    "raised_col = \"independent custodian for ico funds\"\n",
    "\n",
    "df[\"name_std\"]   = normalize_text(df[name_col]) if name_col else \"\"\n",
    "df[\"symbol_std\"] = normalize_text(df[symbol_col]) if symbol_col else \"\"\n",
    "\n",
    "# convertir montos a numéricos si existen\n",
    "for col in [soft_col, hard_col, raised_col]:\n",
    "    if col: df[col + \"_usd\"] = df[col].apply(parse_money)\n",
    "\n",
    "# detectar éxito\n",
    "if succ_col:\n",
    "    df[\"ico_successful\"] = pd.to_numeric(df[succ_col], errors=\"coerce\")\n",
    "    print(\"\\nDistribución original de ico_successful:\")\n",
    "    print(df[\"ico_successful\"].value_counts(dropna=False))\n",
    "    # Validación cruzada simple\n",
    "    if raised_col and \"percentage\" not in raised_col:\n",
    "        mean_success = df.groupby(\"ico_successful\")[raised_col + \"_usd\"].mean()\n",
    "        print(\"\\nMedia de recaudación por etiqueta:\")\n",
    "        print(mean_success)\n",
    "else:\n",
    "    # derivar: éxito si raised >= soft cap\n",
    "    if raised_col and soft_col:\n",
    "        r = pd.to_numeric(df[raised_col + \"_usd\"], errors=\"coerce\")\n",
    "        s = pd.to_numeric(df[soft_col + \"_usd\"], errors=\"coerce\")\n",
    "        df[\"ico_successful\"] = ((r >= s) & r.notna() & s.notna()).astype(int)\n",
    "    else:\n",
    "        df[\"ico_successful\"] = np.nan\n",
    "\n",
    "# normalizar la etiqueta: asegurar que 1 = éxito\n",
    "if df.groupby(\"ico_successful\").mean(numeric_only=True)[raised_col + \"_usd\"].idxmax() == 0:\n",
    "    df[\"ico_successful\"] = 1 - df[\"ico_successful\"]  # invertir codificación\n",
    "\n",
    "# exportar limpio\n",
    "df.to_csv(OUT_ZENODO, index=False)\n",
    "print(f\"\\n✅ Guardado: {OUT_ZENODO}\")\n",
    "print(f\"Filas finales: {len(df):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8171498-3107-44e6-8bce-7b61bf8815ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
