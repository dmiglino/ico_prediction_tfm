{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa8480e-805f-456c-b5d6-5c42faa47717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.7.2.\n",
      "Bundle cargado. Todo listo para entrenar los modelos avanzados\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import sklearn\n",
    "\n",
    "print('scikit-learn version: {}.'.format(sklearn.__version__))\n",
    "\n",
    "bundle = joblib.load(\"../datasets/artifacts/ico_preproc_bundle_v2.pk1\")\n",
    "\n",
    "X_train_prep = bundle.X_train_prep   # numpy array listo para modelar\n",
    "X_test_prep  = bundle.X_test_prep\n",
    "y_train      = bundle.y_train\n",
    "y_test       = bundle.y_test\n",
    "\n",
    "feat_names   = bundle.feature_names   # nombres alineados a X_*_prep\n",
    "preproc      = bundle.preprocessor    # ColumnTransformer ya fit\n",
    "cat_cols     = bundle.categorical_cols\n",
    "num_cols     = bundle.numeric_cols\n",
    "bin_cols     = bundle.binary_cols\n",
    "\n",
    "# Reconstituir preprocesador con las mismas listas\n",
    "def build_preprocessor(cats, nums, bins):\n",
    "    cat_pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),  # usa sparse=False si tu sklearn es <1.2\n",
    "    ])\n",
    "    num_pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "    bin_pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    ])\n",
    "    transformers = []\n",
    "    if nums: transformers.append((\"num\", num_pipe, nums))\n",
    "    if bins: transformers.append((\"bin\", bin_pipe, bins))\n",
    "    if cats: transformers.append((\"cat\", cat_pipe, cats))\n",
    "    return ColumnTransformer(transformers, remainder=\"drop\")\n",
    "\n",
    "print(\"Bundle cargado. Todo listo para entrenar los modelos avanzados\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2586c86-23fa-46aa-b86c-2b09a77eabe0",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "###### https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af1f582-960e-4225-8dd7-f254ae056574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RandomForest (balanced_subsample) ===\n",
      "Accuracy: 0.764  |  ROC-AUC: 0.828  |  PR-AUC: 0.713\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.779     0.892     0.832       751\n",
      "           1      0.720     0.523     0.606       398\n",
      "\n",
      "    accuracy                          0.764      1149\n",
      "   macro avg      0.749     0.707     0.719      1149\n",
      "weighted avg      0.759     0.764     0.753      1149\n",
      "\n",
      "Confusion Matrix:\n",
      "[[670  81]\n",
      " [190 208]]\n",
      "\n",
      "Best params LR: {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 300}\n",
      "CPU times: total: 2.25 s\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=22)]: Using backend ThreadingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=22)]: Done 156 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=22)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=22)]: Using backend ThreadingBackend with 22 concurrent workers.\n",
      "[Parallel(n_jobs=22)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=22)]: Done 156 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=22)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pre = build_preprocessor(bundle.categorical_cols, bundle.numeric_cols, bundle.binary_cols)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", rf)\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"clf__n_estimators\": [300, 600],\n",
    "    \"clf__max_depth\": [None, 10, 20],\n",
    "    \"clf__min_samples_leaf\": [1, 3, 5],\n",
    "    \"clf__max_features\": [\"sqrt\", 0.5],\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    pipe_rf, param_grid_rf, scoring=\"roc_auc\", cv=5, n_jobs=-1, verbose=3\n",
    ")\n",
    "gs_rf.fit(bundle.X_train, bundle.y_train)\n",
    "\n",
    "y_pred = gs_rf.predict(bundle.X_test)\n",
    "y_proba = gs_rf.predict_proba(bundle.X_test)[:,1]\n",
    "\n",
    "print(\"=== RandomForest (balanced_subsample) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}  |  ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}  |  PR-AUC: {average_precision_score(y_test, y_proba):.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nBest params LR:\", gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78abbc-d5c3-40a7-8747-f27f1ef5293d",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23047882-b6b3-4b70-88e7-928d8cee9627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "=== XGBoost (GridSearchCV) ===\n",
      "Accuracy: 0.766  |  ROC-AUC: 0.819  |  PR-AUC: 0.720\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.817     0.827     0.822       751\n",
      "           1      0.666     0.651     0.658       398\n",
      "\n",
      "    accuracy                          0.766      1149\n",
      "   macro avg      0.741     0.739     0.740      1149\n",
      "weighted avg      0.765     0.766     0.765      1149\n",
      "\n",
      "Confusion Matrix:\n",
      "[[621 130]\n",
      " [139 259]]\n",
      "\n",
      "Best params XGB: {'clf__colsample_bytree': 0.6, 'clf__learning_rate': 0.03, 'clf__max_depth': 8, 'clf__n_estimators': 300, 'clf__reg_alpha': 0.0, 'clf__reg_lambda': 0.0, 'clf__subsample': 0.8}\n",
      "CPU times: total: 14.3 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "pre = build_preprocessor(bundle.categorical_cols, bundle.numeric_cols, bundle.binary_cols)\n",
    "\n",
    "# Desbalance (neg/pos)\n",
    "pos = (bundle.y_train == 1).sum()\n",
    "neg = (bundle.y_train == 0).sum()\n",
    "spw = float(neg) / float(pos) if pos > 0 else 1.0\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=spw,\n",
    "    random_state=42,\n",
    "    #device=\"cuda\",\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", xgb)\n",
    "])\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"clf__n_estimators\": [300, 600],\n",
    "    \"clf__max_depth\": [4, 6, 8],\n",
    "    \"clf__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"clf__subsample\": [0.8, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.6, 0.9, 1.0],\n",
    "    \"clf__reg_lambda\": [0.0, 1.0],\n",
    "    \"clf__reg_alpha\": [0.0, 0.5],\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(\n",
    "    pipe_xgb, param_grid_xgb, scoring=\"roc_auc\", cv=5, n_jobs=-1, verbose=1\n",
    ")\n",
    "gs_xgb.fit(bundle.X_train, bundle.y_train)\n",
    "\n",
    "y_pred  = gs_xgb.predict(bundle.X_test)\n",
    "y_proba = gs_xgb.predict_proba(bundle.X_test)[:, 1]\n",
    "\n",
    "print(\"=== XGBoost (GridSearchCV) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(bundle.y_test, y_pred):.3f}  |  ROC-AUC: {roc_auc_score(bundle.y_test, y_proba):.3f}  |  PR-AUC: {average_precision_score(bundle.y_test, y_proba):.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(bundle.y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(bundle.y_test, y_pred))\n",
    "print(\"\\nBest params XGB:\", gs_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd44be5-ffee-40bc-9c98-705dec849377",
   "metadata": {},
   "source": [
    "### LightBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe599519-de7b-4fa7-a2b7-2ea547b5aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "\n",
    "pre = build_preprocessor(bundle.categorical_cols, bundle.numeric_cols, bundle.binary_cols)\n",
    "\n",
    "pos = (bundle.y_train == 1).sum()\n",
    "neg = (bundle.y_train == 0).sum()\n",
    "spw = float(neg) / float(pos) if pos > 0 else 1.0\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=-1,               # -1 = sin límite\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary\",\n",
    "    class_weight=None,          # usamos scale_pos_weight\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=spw,\n",
    "    #device=\"gpu\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "pipe_lgbm = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", lgbm)\n",
    "])\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    \"clf__n_estimators\": [200, 400, 600],\n",
    "    \"clf__num_leaves\": [31, 63],\n",
    "    \"clf__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"clf__subsample\": [0.8, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.6, 0.9, 1.0],\n",
    "    \"clf__reg_lambda\": [0.0, 1.0],\n",
    "    \"clf__reg_alpha\": [0.0, 0.5],\n",
    "    \"clf__max_depth\": [-1, 10, 20],\n",
    "}\n",
    "\n",
    "gs_lgbm = GridSearchCV(\n",
    "    pipe_lgbm, param_grid_lgbm, scoring=\"roc_auc\", cv=5, n_jobs=-1, verbose=1\n",
    ")\n",
    "gs_lgbm.fit(bundle.X_train, bundle.y_train)\n",
    "\n",
    "y_pred  = gs_lgbm.predict(bundle.X_test)\n",
    "y_proba = gs_lgbm.predict_proba(bundle.X_test)[:, 1]\n",
    "\n",
    "print(\"=== LightGBM (GridSearchCV) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(bundle.y_test, y_pred):.3f}  |  ROC-AUC: {roc_auc_score(bundle.y_test, y_proba):.3f}  |  PR-AUC: {average_precision_score(bundle.y_test, y_proba):.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(bundle.y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(bundle.y_test, y_pred))\n",
    "print(\"\\nBest params LGBM:\", gs_lgbm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411471ab-6f48-4eaf-b758-51c720e8f550",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ac03b7-6c24-4075-be7a-3814b2f0e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 810 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n810 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n    _check_train_params(params)\n  File \"_catboost.pyx\", line 6601, in _catboost._check_train_params\n  File \"_catboost.pyx\", line 6623, in _catboost._check_train_params\n_catboost.CatBoostError: catboost/private/libs/options/catboost_options.cpp:794: Error: default bootstrap type (bayesian) doesn't support 'subsample' option\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:46\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1605\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1028\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m   1026\u001b[0m     )\n\u001b[1;32m-> 1028\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    499\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 810 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n810 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\dmigl\\anaconda3\\Lib\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n    _check_train_params(params)\n  File \"_catboost.pyx\", line 6601, in _catboost._check_train_params\n  File \"_catboost.pyx\", line 6623, in _catboost._check_train_params\n_catboost.CatBoostError: catboost/private/libs/options/catboost_options.cpp:794: Error: default bootstrap type (bayesian) doesn't support 'subsample' option\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "\n",
    "pre = build_preprocessor(bundle.categorical_cols, bundle.numeric_cols, bundle.binary_cols)\n",
    "\n",
    "pos = (bundle.y_train == 1).sum()\n",
    "neg = (bundle.y_train == 0).sum()\n",
    "spw = float(neg) / float(pos) if pos > 0 else 1.0\n",
    "\n",
    "catb = CatBoostClassifier(\n",
    "    iterations=600,\n",
    "    depth=6,\n",
    "    learning_rate=0.05,\n",
    "    l2_leaf_reg=3.0,\n",
    "    subsample=0.9,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    class_weights=None,       # usamos scale_pos_weight\n",
    "    scale_pos_weight=spw,\n",
    "    random_seed=42,\n",
    "    verbose=False,            # silenciado para GridSearchCV\n",
    "    task_type=\"GPU\",\n",
    ")\n",
    "\n",
    "pipe_catb = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", catb)\n",
    "])\n",
    "\n",
    "param_grid_catb = {\n",
    "    \"clf__iterations\": [400, 600, 800],\n",
    "    \"clf__depth\": [4, 6, 8],\n",
    "    \"clf__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"clf__l2_leaf_reg\": [1.0, 3.0, 5.0],\n",
    "    \"clf__subsample\": [0.8, 1.0],\n",
    "}\n",
    "\n",
    "gs_catb = GridSearchCV(\n",
    "    pipe_catb, param_grid_catb, scoring=\"roc_auc\", cv=5, n_jobs=-1, verbose=2\n",
    ")\n",
    "gs_catb.fit(bundle.X_train, bundle.y_train)\n",
    "\n",
    "y_pred  = gs_catb.predict(bundle.X_test)\n",
    "# CatBoost devuelve 2D para predict_proba\n",
    "y_proba = gs_catb.predict_proba(bundle.X_test)[:, 1]\n",
    "\n",
    "print(\"=== CatBoost (GridSearchCV) ===\")\n",
    "print(f\"Accuracy: {accuracy_score(bundle.y_test, y_pred):.3f}  |  ROC-AUC: {roc_auc_score(bundle.y_test, y_proba):.3f}  |  PR-AUC: {average_precision_score(bundle.y_test, y_proba):.3f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(bundle.y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(bundle.y_test, y_pred))\n",
    "print(\"\\nBest params CAT:\", gs_catb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7a5bf-3b01-4e07-b4d5-4b3ac43229dd",
   "metadata": {},
   "source": [
    "Tabla comparativa de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1d3d4-bb71-4987-8305-652d6753ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Recolectar los modelos entrenados disponibles automáticamente\n",
    "candidatos = {\n",
    "    \"Logistic\": \"gs_lr\",\n",
    "    \"RandomForest\": \"gs_rf\",\n",
    "    \"XGBoost\": \"gs_xgb\",\n",
    "    \"LightGBM\": \"gs_lgbm\",\n",
    "    \"CatBoost\": \"gs_catb\",\n",
    "}\n",
    "modelos = {}\n",
    "for name, var in candidatos.items():\n",
    "    if var in globals() and eval(var) is not None:\n",
    "        modelos[name] = eval(var)\n",
    "\n",
    "if not modelos:\n",
    "    raise RuntimeError(\"No encontré objetos GridSearchCV (p.ej. gs_lr, gs_rf, gs_xgb...). Ejecútalos antes o cárgalos.\")\n",
    "\n",
    "# Helper para métricas\n",
    "def eval_model(nombre, gs, X, y):\n",
    "    est = gs.best_estimator_\n",
    "    y_pred  = est.predict(X)\n",
    "    # algunos estimadores no tienen predict_proba para ciertas configuraciones:\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        y_proba = est.predict_proba(X)[:, 1]\n",
    "    elif hasattr(est, \"decision_function\"):\n",
    "        # normalizamos a [0,1] aprox para métricas PR/ROC si no hay proba\n",
    "        dec = est.decision_function(X)\n",
    "        dec_min, dec_max = dec.min(), dec.max()\n",
    "        y_proba = (dec - dec_min) / (dec_max - dec_min + 1e-9)\n",
    "    else:\n",
    "        # fallback: usar predicción dura como probabilidad (menos informativa)\n",
    "        y_proba = y_pred.astype(float)\n",
    "\n",
    "    return {\n",
    "        \"model\": nombre,\n",
    "        \"accuracy\": accuracy_score(y, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y, y_proba),\n",
    "        \"pr_auc\": average_precision_score(y, y_proba),\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_proba\": y_proba,\n",
    "        \"best_params\": gs.best_params_,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "per_model_outputs = {}\n",
    "for name, gs in modelos.items():\n",
    "    res = eval_model(name, gs, bundle.X_test, bundle.y_test)\n",
    "    rows.append({k: res[k] for k in [\"model\",\"accuracy\",\"roc_auc\",\"pr_auc\"]})\n",
    "    per_model_outputs[name] = res  # guardamos para las curvas\n",
    "\n",
    "df_cmp = pd.DataFrame(rows).sort_values(\"roc_auc\", ascending=False).reset_index(drop=True)\n",
    "display(df_cmp.style.format({\"accuracy\": \"{:.3f}\", \"roc_auc\": \"{:.3f}\", \"pr_auc\": \"{:.3f}\"}))\n",
    "\n",
    "# (Opcional) Mostrar mejores hiperparámetros\n",
    "for name, gs in modelos.items():\n",
    "    print(f\"[{name}] best params:\", gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b1efc-2d00-4d96-8fd0-e728b76a2f4f",
   "metadata": {},
   "source": [
    "Gráficas comparativas (barras + ROC + PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febbd9b-4669-48b8-a565-e29017d2bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# --- Barras comparativas de métricas ---\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(df_cmp[\"model\"], df_cmp[\"roc_auc\"], alpha=0.8)\n",
    "plt.title(\"Comparativa ROC-AUC\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis=\"y\", alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(df_cmp[\"model\"], df_cmp[\"pr_auc\"], alpha=0.8)\n",
    "plt.title(\"Comparativa PR-AUC\")\n",
    "plt.ylabel(\"PR-AUC\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis=\"y\", alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "# --- Curvas ROC comparativas ---\n",
    "plt.figure(figsize=(7, 6))\n",
    "for name, res in per_model_outputs.items():\n",
    "    fpr, tpr, _ = roc_curve(bundle.y_test, res[\"y_proba\"])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc_score(bundle.y_test, res['y_proba']):.3f})\")\n",
    "plt.plot([0,1],[0,1],\"--\", alpha=0.5)\n",
    "plt.title(\"Curvas ROC comparativas\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "# --- Curvas Precision-Recall comparativas ---\n",
    "plt.figure(figsize=(7, 6))\n",
    "for name, res in per_model_outputs.items():\n",
    "    prec, rec, _ = precision_recall_curve(bundle.y_test, res[\"y_proba\"])\n",
    "    ap = average_precision_score(bundle.y_test, res[\"y_proba\"])\n",
    "    plt.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\")\n",
    "plt.title(\"Curvas Precision-Recall comparativas\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1a99a-e546-46d7-a562-2c274d68a57c",
   "metadata": {},
   "source": [
    "Importancias de características para modelos de árboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae7ed7-427f-4567-9ced-b73d0b4e7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importances(gs, topn=20, title=\"Importancias\"):\n",
    "    # Paso 1: obtener el clasificador y las importancias\n",
    "    est = gs.best_estimator_.named_steps.get(\"clf\", None)\n",
    "    if est is None or not hasattr(est, \"feature_importances_\"):\n",
    "        print(\"Este modelo no expone feature_importances_.\")\n",
    "        return\n",
    "\n",
    "    importances = est.feature_importances_\n",
    "\n",
    "    # Paso 2: obtener nombres de features tras el preprocesamiento\n",
    "    pre = gs.best_estimator_.named_steps.get(\"pre\", None)\n",
    "    if pre is not None and hasattr(pre, \"get_feature_names_out\"):\n",
    "        feat_names = pre.get_feature_names_out()\n",
    "    else:\n",
    "        # fallback por si acaso\n",
    "        feat_names = np.array([f\"f{i}\" for i in range(len(importances))])\n",
    "\n",
    "    # Paso 3: armar DF ordenado y plot\n",
    "    df_imp = pd.DataFrame({\"feature\": feat_names, \"importance\": importances})\n",
    "    df_imp = df_imp.sort_values(\"importance\", ascending=False).head(topn)\n",
    "    plt.figure(figsize=(8, max(4, topn*0.35)))\n",
    "    plt.barh(df_imp[\"feature\"][::-1], df_imp[\"importance\"][::-1])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Intentar para cada uno de los árboles presentes\n",
    "for name in [\"RandomForest\", \"XGBoost\", \"LightGBM\", \"CatBoost\"]:\n",
    "    if name in modelos:\n",
    "        plot_feature_importances(modelos[name], topn=20, title=f\"Importancias - {name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
